{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHH2jZvhzb2szltu30RNU7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YahyaEryani/quantum-model/blob/main/notebooks/03_HGB_Training_and_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training, Tuning, and Evaluation\n",
        "\n",
        " In this notebook, we will train an histogram gradient boosted classifier model on the Higgs boson dataset we have preprocessed in the `01_data_exploration` notebook. We will perform the model training and tuning process to obtain the best model with the highest accuracy possible."
      ],
      "metadata": {
        "id": "rCCacfQOdovS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries\n",
        "In this section, we will import the necessary libraries and packages that will be used throughout the notebook."
      ],
      "metadata": {
        "id": "80xGfi4qeX_R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qtnhwOT2btA4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data\n",
        "\n",
        "This code cell loads the training, validation, and test datasets that were saved in pickle format to the local directory."
      ],
      "metadata": {
        "id": "ypcKz82Rezcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive in Colab\n",
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load data from Google Drive\n",
        "train_path = '/content/drive/MyDrive/Higgs_dataset/processed/training_data.pkl'\n",
        "val_path   = '/content/drive/MyDrive/Higgs_dataset/processed/validation_data.pkl'\n",
        "test_path  = '/content/drive/MyDrive/Higgs_dataset/processed/testing_data.pkl'\n",
        "\n",
        "train_data = pd.read_pickle(train_path)\n",
        "val_data = pd.read_pickle(val_path)\n",
        "test_data = pd.read_pickle(test_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U5KGIile0KZ",
        "outputId": "4af4a8bf-804e-4634-addb-c4a40ba586a9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the data for training\n",
        "This code separates the features and class labels from the train, validation, and test datasets."
      ],
      "metadata": {
        "id": "xzlLL4XtuAhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and labels\n",
        "y_train = train_data['class_label']\n",
        "X_train = train_data.drop('class_label', axis=1)\n",
        "y_val = val_data['class_label']\n",
        "X_val = val_data.drop('class_label', axis=1)\n",
        "y_test = test_data['class_label']\n",
        "X_test = test_data.drop('class_label', axis=1)\n"
      ],
      "metadata": {
        "id": "pLL8bBeUuBFs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train the Histogram Gradient Boosting Classifier model\n",
        "This code sets the hyperparameters for a Histogram Gradient Boosting Classifier model, including the maximum depth of trees, learning rate, maximum number of leaf nodes, and loss function. It then trains the Histogram Gradient Boosting Classifier model using early stopping and a specified number of iterations."
      ],
      "metadata": {
        "id": "C1-zcJsAgAUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the hyperparameters for the Histogram Gradient Boosting Classifier model\n",
        "hist_gradient_boosting = HistGradientBoostingClassifier(\n",
        "    loss='binary_crossentropy',\n",
        "    learning_rate=0.1,\n",
        "    max_iter=100,\n",
        "    max_leaf_nodes=31,\n",
        "    max_depth=None,\n",
        "    min_samples_leaf=20,\n",
        "    l2_regularization=0.0,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "hist_gradient_boosting.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the validation set (optional)\n",
        "y_val_pred = hist_gradient_boosting.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYuEodJigA0C",
        "outputId": "24c2d831-46b5-4e6f-d9fb-3c8226c136d3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/ensemble/_hist_gradient_boosting/gradient_boosting.py:1998: FutureWarning: The loss 'binary_crossentropy' was deprecated in v1.1 and will be removed in version 1.3. Use 'log_loss' which is equivalent.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Accuracy: 73.05%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "4yvrPk6PwUkB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make predictions on the test data and evaluate the model performance\n",
        "This code uses the Histogram Gradient Boosting Classifier model that was previously trained to make predictions on the test data."
      ],
      "metadata": {
        "id": "js36VHnOw_UQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = hist_gradient_boosting.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZJ8xaVcwVGO",
        "outputId": "741827c6-f43d-4762-a700-873636cddba4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 73.01%\n"
          ]
        }
      ]
    }
  ]
}