{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T3aPf3ScyB25"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive in Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load data from Google Drive\n",
        "train_path = '/content/drive/MyDrive/Colab Notebooks/training_data_drpped_column.pkl'\n",
        "val_path   = '/content/drive/MyDrive/Colab Notebooks/validation_data_drpped_column.pkl'\n",
        "test_path  = '/content/drive/MyDrive/Colab Notebooks/testing_data_drpped_column.pkl'\n",
        "train_data =pd.read_pickle(train_path)\n",
        "val_data = pd.read_pickle(val_path)\n",
        "test_data = pd.read_pickle(test_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_wwMu0NyEUj",
        "outputId": "f384c904-6133-4155-b229-04b1e446e564"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ufyncxRhaCMv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and labels\n",
        "train_labels = train_data['class_label']\n",
        "train_features = train_data.drop('class_label', axis=1)\n",
        "val_labels = val_data['class_label']\n",
        "val_features = val_data.drop('class_label', axis=1)\n",
        "test_labels = test_data['class_label']\n",
        "test_features = test_data.drop('class_label', axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "8NPjn62iyJnf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize the data\n",
        "# # Normalize the feature columns\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(train_features)\n",
        "train_features=scaler.transform(train_features)\n",
        "val_features=scaler.transform(val_features)\n",
        "test_features=scaler.transform(test_features)"
      ],
      "metadata": {
        "id": "OF0Go8Nahnt8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from sklearn.metrics import accuracy_score, precision_score,recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score"
      ],
      "metadata": {
        "id": "Qsih9HlDyM8P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=17, activation='relu'))\n",
        "# model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "# model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "bpYVvbNmyQMw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "vpTzgINSySzq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_features, train_labels, epochs=10, batch_size=32, validation_data=(val_features, val_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVKmphZoyWW_",
        "outputId": "1cdbbcf0-727e-4714-a0b6-6e955d2c964a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "13117/13117 [==============================] - 51s 4ms/step - loss: 0.5958 - accuracy: 0.6828 - val_loss: 0.5669 - val_accuracy: 0.7120\n",
            "Epoch 2/10\n",
            "13117/13117 [==============================] - 43s 3ms/step - loss: 0.5784 - accuracy: 0.6974 - val_loss: 0.5608 - val_accuracy: 0.7172\n",
            "Epoch 3/10\n",
            "13117/13117 [==============================] - 36s 3ms/step - loss: 0.5748 - accuracy: 0.7002 - val_loss: 0.5566 - val_accuracy: 0.7174\n",
            "Epoch 4/10\n",
            "13117/13117 [==============================] - 34s 3ms/step - loss: 0.5720 - accuracy: 0.7030 - val_loss: 0.5537 - val_accuracy: 0.7212\n",
            "Epoch 5/10\n",
            "13117/13117 [==============================] - 35s 3ms/step - loss: 0.5704 - accuracy: 0.7034 - val_loss: 0.5522 - val_accuracy: 0.7213\n",
            "Epoch 6/10\n",
            "13117/13117 [==============================] - 36s 3ms/step - loss: 0.5693 - accuracy: 0.7046 - val_loss: 0.5547 - val_accuracy: 0.7188\n",
            "Epoch 7/10\n",
            "13117/13117 [==============================] - 35s 3ms/step - loss: 0.5684 - accuracy: 0.7050 - val_loss: 0.5504 - val_accuracy: 0.7236\n",
            "Epoch 8/10\n",
            "13117/13117 [==============================] - 36s 3ms/step - loss: 0.5676 - accuracy: 0.7053 - val_loss: 0.5514 - val_accuracy: 0.7219\n",
            "Epoch 9/10\n",
            "13117/13117 [==============================] - 37s 3ms/step - loss: 0.5676 - accuracy: 0.7051 - val_loss: 0.5500 - val_accuracy: 0.7200\n",
            "Epoch 10/10\n",
            "13117/13117 [==============================] - 37s 3ms/step - loss: 0.5666 - accuracy: 0.7065 - val_loss: 0.5497 - val_accuracy: 0.7212\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f762c412f40>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_features, test_labels)\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "test_pred = model.predict(test_features)\n",
        "test_pred_binary = (test_pred >= 0.5).astype(int)\n",
        "test_auc = roc_auc_score(test_labels, test_pred)\n",
        "test_f1 = f1_score(test_labels, test_pred_binary)\n",
        "\n",
        "print(f\"Test AUC: {test_auc:.4f}\")\n",
        "print(f\"Test F1 score: {test_f1:.4f}\")\n",
        "# Calculate the accuracy of the model on the test data\n",
        "# accuracy = accuracy_score(y_test, test_preds)\n",
        "# auc = roc_auc_score(y_test, test_preds)\n",
        "# accuracy = accuracy_score(y_test, test_preds)\n",
        "# precision = precision_score(y_test, test_preds)\n",
        "# recall = recall_score(y_test, test_preds)\n",
        "# f1 = f1_score(y_test, test_preds)\n",
        "# print(\"Test AUC score: {:.4f}\".format(auc))\n",
        "# print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "# print('Precision:', precision)\n",
        "# print('Recall:', recall)\n",
        "# print('F1 Score:', f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGsfQsskjKNe",
        "outputId": "3f2f0411-ba22-4986-fbe4-5cc2cfcc9f64"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2813/2813 [==============================] - 4s 2ms/step - loss: 0.5484 - accuracy: 0.7225\n",
            "Test loss: 0.5484\n",
            "Test accuracy: 0.7225\n",
            "2813/2813 [==============================] - 4s 1ms/step\n",
            "Test AUC: 0.7969\n",
            "Test F1 score: 0.7504\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Normalize the input data\n",
        "scaler = StandardScaler()\n",
        "train_features = scaler.fit_transform(train_features)\n",
        "val_features = scaler.transform(val_features)\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_dim=17, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_features, train_labels, epochs=100, batch_size=32, validation_data=(val_features, val_labels))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZndfAzeYaxCR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d6da258-1156-4ea8-d0c3-c2466ac6e49c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "13117/13117 [==============================] - 72s 5ms/step - loss: 0.5622 - accuracy: 0.7111 - val_loss: 0.5338 - val_accuracy: 0.7287\n",
            "Epoch 2/100\n",
            "13117/13117 [==============================] - 49s 4ms/step - loss: 0.5315 - accuracy: 0.7301 - val_loss: 0.5206 - val_accuracy: 0.7376\n",
            "Epoch 3/100\n",
            "13117/13117 [==============================] - 47s 4ms/step - loss: 0.5242 - accuracy: 0.7340 - val_loss: 0.5180 - val_accuracy: 0.7379\n",
            "Epoch 4/100\n",
            "13117/13117 [==============================] - 46s 3ms/step - loss: 0.5190 - accuracy: 0.7378 - val_loss: 0.5131 - val_accuracy: 0.7407\n",
            "Epoch 5/100\n",
            "13117/13117 [==============================] - 47s 4ms/step - loss: 0.5156 - accuracy: 0.7402 - val_loss: 0.5102 - val_accuracy: 0.7442\n",
            "Epoch 6/100\n",
            "13117/13117 [==============================] - 45s 3ms/step - loss: 0.5129 - accuracy: 0.7417 - val_loss: 0.5113 - val_accuracy: 0.7440\n",
            "Epoch 7/100\n",
            "13117/13117 [==============================] - 48s 4ms/step - loss: 0.5111 - accuracy: 0.7433 - val_loss: 0.5079 - val_accuracy: 0.7444\n",
            "Epoch 8/100\n",
            "13117/13117 [==============================] - 47s 4ms/step - loss: 0.5092 - accuracy: 0.7447 - val_loss: 0.5057 - val_accuracy: 0.7467\n",
            "Epoch 9/100\n",
            "13117/13117 [==============================] - 45s 3ms/step - loss: 0.5071 - accuracy: 0.7462 - val_loss: 0.5078 - val_accuracy: 0.7460\n",
            "Epoch 10/100\n",
            "13117/13117 [==============================] - 46s 4ms/step - loss: 0.5060 - accuracy: 0.7467 - val_loss: 0.5083 - val_accuracy: 0.7441\n",
            "Epoch 11/100\n",
            "13117/13117 [==============================] - 47s 4ms/step - loss: 0.5046 - accuracy: 0.7471 - val_loss: 0.5059 - val_accuracy: 0.7456\n",
            "Epoch 12/100\n",
            "13117/13117 [==============================] - 45s 3ms/step - loss: 0.5034 - accuracy: 0.7485 - val_loss: 0.5082 - val_accuracy: 0.7461\n",
            "Epoch 13/100\n",
            "13117/13117 [==============================] - 45s 3ms/step - loss: 0.5021 - accuracy: 0.7481 - val_loss: 0.5058 - val_accuracy: 0.7460\n",
            "Epoch 14/100\n",
            "13117/13117 [==============================] - 45s 3ms/step - loss: 0.5013 - accuracy: 0.7487 - val_loss: 0.5046 - val_accuracy: 0.7469\n",
            "Epoch 15/100\n",
            "13117/13117 [==============================] - 44s 3ms/step - loss: 0.5000 - accuracy: 0.7500 - val_loss: 0.5046 - val_accuracy: 0.7473\n",
            "Epoch 16/100\n",
            "13117/13117 [==============================] - 46s 4ms/step - loss: 0.4993 - accuracy: 0.7502 - val_loss: 0.5037 - val_accuracy: 0.7464\n",
            "Epoch 17/100\n",
            "13117/13117 [==============================] - 47s 4ms/step - loss: 0.4983 - accuracy: 0.7512 - val_loss: 0.5058 - val_accuracy: 0.7466\n",
            "Epoch 18/100\n",
            "13117/13117 [==============================] - 47s 4ms/step - loss: 0.4970 - accuracy: 0.7518 - val_loss: 0.5044 - val_accuracy: 0.7475\n",
            "Epoch 19/100\n",
            "13117/13117 [==============================] - 45s 3ms/step - loss: 0.4963 - accuracy: 0.7529 - val_loss: 0.5038 - val_accuracy: 0.7470\n",
            "Epoch 20/100\n",
            "13117/13117 [==============================] - 46s 4ms/step - loss: 0.4958 - accuracy: 0.7528 - val_loss: 0.5052 - val_accuracy: 0.7459\n",
            "Epoch 21/100\n",
            "13117/13117 [==============================] - 47s 4ms/step - loss: 0.4946 - accuracy: 0.7538 - val_loss: 0.5036 - val_accuracy: 0.7473\n",
            "Epoch 22/100\n",
            "13117/13117 [==============================] - 47s 4ms/step - loss: 0.4939 - accuracy: 0.7543 - val_loss: 0.5040 - val_accuracy: 0.7474\n",
            "Epoch 23/100\n",
            "13117/13117 [==============================] - 47s 4ms/step - loss: 0.4936 - accuracy: 0.7543 - val_loss: 0.5026 - val_accuracy: 0.7478\n",
            "Epoch 24/100\n",
            "13117/13117 [==============================] - 46s 3ms/step - loss: 0.4929 - accuracy: 0.7548 - val_loss: 0.5033 - val_accuracy: 0.7470\n",
            "Epoch 25/100\n",
            "13117/13117 [==============================] - 45s 3ms/step - loss: 0.4922 - accuracy: 0.7554 - val_loss: 0.5027 - val_accuracy: 0.7471\n",
            "Epoch 26/100\n",
            "13117/13117 [==============================] - 46s 4ms/step - loss: 0.4914 - accuracy: 0.7554 - val_loss: 0.5036 - val_accuracy: 0.7471\n",
            "Epoch 27/100\n",
            "13117/13117 [==============================] - 46s 4ms/step - loss: 0.4908 - accuracy: 0.7560 - val_loss: 0.5048 - val_accuracy: 0.7471\n",
            "Epoch 28/100\n",
            "13117/13117 [==============================] - 45s 3ms/step - loss: 0.4901 - accuracy: 0.7567 - val_loss: 0.5047 - val_accuracy: 0.7468\n",
            "Epoch 29/100\n",
            "13117/13117 [==============================] - 46s 4ms/step - loss: 0.4894 - accuracy: 0.7565 - val_loss: 0.5039 - val_accuracy: 0.7481\n",
            "Epoch 30/100\n",
            "13117/13117 [==============================] - 47s 4ms/step - loss: 0.4892 - accuracy: 0.7570 - val_loss: 0.5043 - val_accuracy: 0.7476\n",
            "Epoch 31/100\n",
            "13117/13117 [==============================] - 46s 3ms/step - loss: 0.4881 - accuracy: 0.7581 - val_loss: 0.5055 - val_accuracy: 0.7465\n",
            "Epoch 32/100\n",
            "13117/13117 [==============================] - 46s 4ms/step - loss: 0.4873 - accuracy: 0.7583 - val_loss: 0.5037 - val_accuracy: 0.7473\n",
            "Epoch 33/100\n",
            "13117/13117 [==============================] - 46s 4ms/step - loss: 0.4872 - accuracy: 0.7587 - val_loss: 0.5073 - val_accuracy: 0.7471\n",
            "Epoch 34/100\n",
            "13117/13117 [==============================] - 47s 4ms/step - loss: 0.4865 - accuracy: 0.7586 - val_loss: 0.5068 - val_accuracy: 0.7464\n",
            "Epoch 35/100\n",
            "13117/13117 [==============================] - 45s 3ms/step - loss: 0.4861 - accuracy: 0.7597 - val_loss: 0.5053 - val_accuracy: 0.7460\n",
            "Epoch 36/100\n",
            "13117/13117 [==============================] - 47s 4ms/step - loss: 0.4858 - accuracy: 0.7597 - val_loss: 0.5064 - val_accuracy: 0.7479\n",
            "Epoch 37/100\n",
            "13117/13117 [==============================] - 48s 4ms/step - loss: 0.4851 - accuracy: 0.7595 - val_loss: 0.5046 - val_accuracy: 0.7456\n",
            "Epoch 38/100\n",
            "13117/13117 [==============================] - 49s 4ms/step - loss: 0.4849 - accuracy: 0.7599 - val_loss: 0.5044 - val_accuracy: 0.7468\n",
            "Epoch 39/100\n",
            "13117/13117 [==============================] - 49s 4ms/step - loss: 0.4844 - accuracy: 0.7602 - val_loss: 0.5059 - val_accuracy: 0.7470\n",
            "Epoch 40/100\n",
            "13117/13117 [==============================] - 47s 4ms/step - loss: 0.4842 - accuracy: 0.7601 - val_loss: 0.5056 - val_accuracy: 0.7463\n",
            "Epoch 41/100\n",
            "13117/13117 [==============================] - 48s 4ms/step - loss: 0.4834 - accuracy: 0.7609 - val_loss: 0.5041 - val_accuracy: 0.7473\n",
            "Epoch 42/100\n",
            "13117/13117 [==============================] - 48s 4ms/step - loss: 0.4831 - accuracy: 0.7605 - val_loss: 0.5054 - val_accuracy: 0.7482\n",
            "Epoch 43/100\n",
            "13117/13117 [==============================] - 48s 4ms/step - loss: 0.4828 - accuracy: 0.7617 - val_loss: 0.5043 - val_accuracy: 0.7465\n",
            "Epoch 44/100\n",
            "13117/13117 [==============================] - 47s 4ms/step - loss: 0.4821 - accuracy: 0.7613 - val_loss: 0.5055 - val_accuracy: 0.7465\n",
            "Epoch 45/100\n",
            "13117/13117 [==============================] - 47s 4ms/step - loss: 0.4820 - accuracy: 0.7616 - val_loss: 0.5063 - val_accuracy: 0.7454\n",
            "Epoch 46/100\n",
            "13117/13117 [==============================] - 48s 4ms/step - loss: 0.4813 - accuracy: 0.7622 - val_loss: 0.5051 - val_accuracy: 0.7463\n",
            "Epoch 47/100\n",
            "13117/13117 [==============================] - 50s 4ms/step - loss: 0.4809 - accuracy: 0.7624 - val_loss: 0.5053 - val_accuracy: 0.7468\n",
            "Epoch 48/100\n",
            "13117/13117 [==============================] - 48s 4ms/step - loss: 0.4806 - accuracy: 0.7634 - val_loss: 0.5075 - val_accuracy: 0.7464\n",
            "Epoch 49/100\n",
            "13117/13117 [==============================] - 46s 4ms/step - loss: 0.4800 - accuracy: 0.7634 - val_loss: 0.5077 - val_accuracy: 0.7463\n",
            "Epoch 50/100\n",
            "13117/13117 [==============================] - 48s 4ms/step - loss: 0.4798 - accuracy: 0.7633 - val_loss: 0.5075 - val_accuracy: 0.7460\n",
            "Epoch 51/100\n",
            "13117/13117 [==============================] - 46s 4ms/step - loss: 0.4792 - accuracy: 0.7641 - val_loss: 0.5065 - val_accuracy: 0.7467\n",
            "Epoch 52/100\n",
            "13117/13117 [==============================] - 46s 4ms/step - loss: 0.4790 - accuracy: 0.7640 - val_loss: 0.5064 - val_accuracy: 0.7465\n",
            "Epoch 53/100\n",
            "13117/13117 [==============================] - 47s 4ms/step - loss: 0.4789 - accuracy: 0.7638 - val_loss: 0.5069 - val_accuracy: 0.7461\n",
            "Epoch 54/100\n",
            "13117/13117 [==============================] - 47s 4ms/step - loss: 0.4779 - accuracy: 0.7644 - val_loss: 0.5079 - val_accuracy: 0.7457\n",
            "Epoch 55/100\n",
            "13117/13117 [==============================] - 48s 4ms/step - loss: 0.4782 - accuracy: 0.7648 - val_loss: 0.5077 - val_accuracy: 0.7467\n",
            "Epoch 56/100\n",
            "13117/13117 [==============================] - 48s 4ms/step - loss: 0.4776 - accuracy: 0.7649 - val_loss: 0.5092 - val_accuracy: 0.7471\n",
            "Epoch 57/100\n",
            "13117/13117 [==============================] - 49s 4ms/step - loss: 0.4772 - accuracy: 0.7650 - val_loss: 0.5088 - val_accuracy: 0.7459\n",
            "Epoch 58/100\n",
            "13117/13117 [==============================] - 49s 4ms/step - loss: 0.4773 - accuracy: 0.7648 - val_loss: 0.5062 - val_accuracy: 0.7462\n",
            "Epoch 59/100\n",
            "13117/13117 [==============================] - 50s 4ms/step - loss: 0.4769 - accuracy: 0.7649 - val_loss: 0.5073 - val_accuracy: 0.7472\n",
            "Epoch 60/100\n",
            "13117/13117 [==============================] - 49s 4ms/step - loss: 0.4769 - accuracy: 0.7651 - val_loss: 0.5075 - val_accuracy: 0.7462\n",
            "Epoch 61/100\n",
            "13117/13117 [==============================] - 49s 4ms/step - loss: 0.4760 - accuracy: 0.7659 - val_loss: 0.5080 - val_accuracy: 0.7466\n",
            "Epoch 62/100\n",
            "13117/13117 [==============================] - 49s 4ms/step - loss: 0.4754 - accuracy: 0.7663 - val_loss: 0.5080 - val_accuracy: 0.7458\n",
            "Epoch 63/100\n",
            "13117/13117 [==============================] - 49s 4ms/step - loss: 0.4762 - accuracy: 0.7653 - val_loss: 0.5080 - val_accuracy: 0.7457\n",
            "Epoch 64/100\n",
            "13117/13117 [==============================] - 47s 4ms/step - loss: 0.4750 - accuracy: 0.7663 - val_loss: 0.5093 - val_accuracy: 0.7458\n",
            "Epoch 65/100\n",
            "13117/13117 [==============================] - 49s 4ms/step - loss: 0.4748 - accuracy: 0.7665 - val_loss: 0.5102 - val_accuracy: 0.7444\n",
            "Epoch 66/100\n",
            "13117/13117 [==============================] - 46s 4ms/step - loss: 0.4745 - accuracy: 0.7668 - val_loss: 0.5077 - val_accuracy: 0.7464\n",
            "Epoch 67/100\n",
            "13117/13117 [==============================] - 48s 4ms/step - loss: 0.4742 - accuracy: 0.7671 - val_loss: 0.5070 - val_accuracy: 0.7459\n",
            "Epoch 68/100\n",
            "13117/13117 [==============================] - 46s 3ms/step - loss: 0.4743 - accuracy: 0.7670 - val_loss: 0.5108 - val_accuracy: 0.7451\n",
            "Epoch 69/100\n",
            "13117/13117 [==============================] - 45s 3ms/step - loss: 0.4740 - accuracy: 0.7677 - val_loss: 0.5104 - val_accuracy: 0.7458\n",
            "Epoch 70/100\n",
            "13117/13117 [==============================] - 44s 3ms/step - loss: 0.4738 - accuracy: 0.7671 - val_loss: 0.5105 - val_accuracy: 0.7449\n",
            "Epoch 71/100\n",
            "13117/13117 [==============================] - 46s 3ms/step - loss: 0.4734 - accuracy: 0.7672 - val_loss: 0.5090 - val_accuracy: 0.7459\n",
            "Epoch 72/100\n",
            "13117/13117 [==============================] - 47s 4ms/step - loss: 0.4730 - accuracy: 0.7677 - val_loss: 0.5081 - val_accuracy: 0.7459\n",
            "Epoch 73/100\n",
            "13117/13117 [==============================] - 47s 4ms/step - loss: 0.4732 - accuracy: 0.7678 - val_loss: 0.5089 - val_accuracy: 0.7461\n",
            "Epoch 74/100\n",
            "13117/13117 [==============================] - 45s 3ms/step - loss: 0.4725 - accuracy: 0.7679 - val_loss: 0.5101 - val_accuracy: 0.7443\n",
            "Epoch 75/100\n",
            "13117/13117 [==============================] - 45s 3ms/step - loss: 0.4719 - accuracy: 0.7682 - val_loss: 0.5130 - val_accuracy: 0.7448\n",
            "Epoch 76/100\n",
            "13117/13117 [==============================] - 46s 4ms/step - loss: 0.4719 - accuracy: 0.7683 - val_loss: 0.5135 - val_accuracy: 0.7447\n",
            "Epoch 77/100\n",
            "13117/13117 [==============================] - 46s 3ms/step - loss: 0.4714 - accuracy: 0.7691 - val_loss: 0.5145 - val_accuracy: 0.7453\n",
            "Epoch 78/100\n",
            "13117/13117 [==============================] - 49s 4ms/step - loss: 0.4713 - accuracy: 0.7694 - val_loss: 0.5120 - val_accuracy: 0.7448\n",
            "Epoch 79/100\n",
            "13117/13117 [==============================] - 50s 4ms/step - loss: 0.4715 - accuracy: 0.7684 - val_loss: 0.5099 - val_accuracy: 0.7440\n",
            "Epoch 80/100\n",
            "13117/13117 [==============================] - 46s 4ms/step - loss: 0.4712 - accuracy: 0.7694 - val_loss: 0.5112 - val_accuracy: 0.7451\n",
            "Epoch 81/100\n",
            "13117/13117 [==============================] - 46s 4ms/step - loss: 0.4709 - accuracy: 0.7693 - val_loss: 0.5106 - val_accuracy: 0.7447\n",
            "Epoch 82/100\n",
            "13117/13117 [==============================] - 47s 4ms/step - loss: 0.4710 - accuracy: 0.7690 - val_loss: 0.5088 - val_accuracy: 0.7446\n",
            "Epoch 83/100\n",
            "13117/13117 [==============================] - 48s 4ms/step - loss: 0.4701 - accuracy: 0.7691 - val_loss: 0.5094 - val_accuracy: 0.7452\n",
            "Epoch 84/100\n",
            "13117/13117 [==============================] - 48s 4ms/step - loss: 0.4701 - accuracy: 0.7693 - val_loss: 0.5113 - val_accuracy: 0.7429\n",
            "Epoch 85/100\n",
            "13117/13117 [==============================] - 46s 4ms/step - loss: 0.4694 - accuracy: 0.7703 - val_loss: 0.5118 - val_accuracy: 0.7442\n",
            "Epoch 86/100\n",
            "13117/13117 [==============================] - 47s 4ms/step - loss: 0.4694 - accuracy: 0.7697 - val_loss: 0.5121 - val_accuracy: 0.7437\n",
            "Epoch 87/100\n",
            "13117/13117 [==============================] - 48s 4ms/step - loss: 0.4689 - accuracy: 0.7705 - val_loss: 0.5122 - val_accuracy: 0.7448\n",
            "Epoch 88/100\n",
            "13117/13117 [==============================] - 48s 4ms/step - loss: 0.4693 - accuracy: 0.7699 - val_loss: 0.5099 - val_accuracy: 0.7443\n",
            "Epoch 89/100\n",
            "13117/13117 [==============================] - 48s 4ms/step - loss: 0.4688 - accuracy: 0.7713 - val_loss: 0.5144 - val_accuracy: 0.7440\n",
            "Epoch 90/100\n",
            "13117/13117 [==============================] - 47s 4ms/step - loss: 0.4687 - accuracy: 0.7706 - val_loss: 0.5140 - val_accuracy: 0.7430\n",
            "Epoch 91/100\n",
            "13117/13117 [==============================] - 47s 4ms/step - loss: 0.4687 - accuracy: 0.7699 - val_loss: 0.5163 - val_accuracy: 0.7428\n",
            "Epoch 92/100\n",
            "13117/13117 [==============================] - 49s 4ms/step - loss: 0.4684 - accuracy: 0.7704 - val_loss: 0.5129 - val_accuracy: 0.7441\n",
            "Epoch 93/100\n",
            "13117/13117 [==============================] - 48s 4ms/step - loss: 0.4684 - accuracy: 0.7699 - val_loss: 0.5115 - val_accuracy: 0.7440\n",
            "Epoch 94/100\n",
            "13117/13117 [==============================] - 49s 4ms/step - loss: 0.4681 - accuracy: 0.7707 - val_loss: 0.5130 - val_accuracy: 0.7437\n",
            "Epoch 95/100\n",
            "13117/13117 [==============================] - 48s 4ms/step - loss: 0.4681 - accuracy: 0.7706 - val_loss: 0.5118 - val_accuracy: 0.7435\n",
            "Epoch 96/100\n",
            "13117/13117 [==============================] - 48s 4ms/step - loss: 0.4676 - accuracy: 0.7706 - val_loss: 0.5182 - val_accuracy: 0.7445\n",
            "Epoch 97/100\n",
            "13117/13117 [==============================] - 46s 3ms/step - loss: 0.4671 - accuracy: 0.7711 - val_loss: 0.5121 - val_accuracy: 0.7446\n",
            "Epoch 98/100\n",
            "13117/13117 [==============================] - 48s 4ms/step - loss: 0.4672 - accuracy: 0.7714 - val_loss: 0.5154 - val_accuracy: 0.7451\n",
            "Epoch 99/100\n",
            "13117/13117 [==============================] - 47s 4ms/step - loss: 0.4672 - accuracy: 0.7707 - val_loss: 0.5115 - val_accuracy: 0.7437\n",
            "Epoch 100/100\n",
            "13117/13117 [==============================] - 47s 4ms/step - loss: 0.4669 - accuracy: 0.7718 - val_loss: 0.5111 - val_accuracy: 0.7442\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f761ef74a90>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_features, test_labels)\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "test_pred = model.predict(test_features)\n",
        "test_pred_binary = (test_pred >= 0.5).astype(int)\n",
        "test_auc = roc_auc_score(test_labels, test_pred)\n",
        "test_f1 = f1_score(test_labels, test_pred_binary)\n",
        "\n",
        "print(f\"Test AUC: {test_auc:.4f}\")\n",
        "print(f\"Test F1 score: {test_f1:.4f}\")"
      ],
      "metadata": {
        "id": "l7Ywr7een6Ji",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e01e2c8-360e-44e4-f543-4e737f99b4f5"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.5119 - accuracy: 0.7422\n",
            "Test loss: 0.5119\n",
            "Test accuracy: 0.7422\n",
            "2813/2813 [==============================] - 4s 1ms/step\n",
            "Test AUC: 0.8251\n",
            "Test F1 score: 0.7527\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, we have used the StandardScaler from the scikit-learn library to normalize the input data. We have added more hidden layers and increased the number of neurons in the hidden layers. We have also added a dropout layer and an L2 regularization to prevent overfitting. Finally, we have monitored the performance of the model on the validation set."
      ],
      "metadata": {
        "id": "_KxmenQPbgUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Normalize the input data\n",
        "scaler = StandardScaler()\n",
        "train_features = scaler.fit_transform(train_features)\n",
        "val_features = scaler.transform(val_features)\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_dim=17, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Early stopping callback\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_features, train_labels, epochs=50, batch_size=32, validation_data=(val_features, val_labels), callbacks=[es])\n",
        "\n"
      ],
      "metadata": {
        "id": "6V8Q8wOAyl60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b5e1eb2-6dc1-434e-989c-a7cb33248ec8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "13117/13117 [==============================] - 115s 8ms/step - loss: 0.5886 - accuracy: 0.6958 - val_loss: 0.5365 - val_accuracy: 0.7299\n",
            "Epoch 2/50\n",
            "13117/13117 [==============================] - 113s 9ms/step - loss: 0.5518 - accuracy: 0.7156 - val_loss: 0.5261 - val_accuracy: 0.7347\n",
            "Epoch 3/50\n",
            "13117/13117 [==============================] - 116s 9ms/step - loss: 0.5449 - accuracy: 0.7205 - val_loss: 0.5217 - val_accuracy: 0.7366\n",
            "Epoch 4/50\n",
            "13117/13117 [==============================] - 115s 9ms/step - loss: 0.5407 - accuracy: 0.7237 - val_loss: 0.5192 - val_accuracy: 0.7390\n",
            "Epoch 5/50\n",
            "13117/13117 [==============================] - 126s 10ms/step - loss: 0.5377 - accuracy: 0.7251 - val_loss: 0.5163 - val_accuracy: 0.7408\n",
            "Epoch 6/50\n",
            "13117/13117 [==============================] - 118s 9ms/step - loss: 0.5354 - accuracy: 0.7267 - val_loss: 0.5169 - val_accuracy: 0.7410\n",
            "Epoch 7/50\n",
            "13117/13117 [==============================] - 118s 9ms/step - loss: 0.5335 - accuracy: 0.7275 - val_loss: 0.5124 - val_accuracy: 0.7433\n",
            "Epoch 8/50\n",
            "13117/13117 [==============================] - 117s 9ms/step - loss: 0.5319 - accuracy: 0.7291 - val_loss: 0.5124 - val_accuracy: 0.7431\n",
            "Epoch 9/50\n",
            "13117/13117 [==============================] - 121s 9ms/step - loss: 0.5307 - accuracy: 0.7292 - val_loss: 0.5144 - val_accuracy: 0.7439\n",
            "Epoch 10/50\n",
            "13117/13117 [==============================] - 124s 9ms/step - loss: 0.5298 - accuracy: 0.7303 - val_loss: 0.5114 - val_accuracy: 0.7445\n",
            "Epoch 11/50\n",
            "13117/13117 [==============================] - 115s 9ms/step - loss: 0.5285 - accuracy: 0.7317 - val_loss: 0.5094 - val_accuracy: 0.7446\n",
            "Epoch 12/50\n",
            "13117/13117 [==============================] - 112s 9ms/step - loss: 0.5273 - accuracy: 0.7323 - val_loss: 0.5081 - val_accuracy: 0.7461\n",
            "Epoch 13/50\n",
            "13117/13117 [==============================] - 114s 9ms/step - loss: 0.5273 - accuracy: 0.7323 - val_loss: 0.5081 - val_accuracy: 0.7462\n",
            "Epoch 14/50\n",
            "13117/13117 [==============================] - 119s 9ms/step - loss: 0.5259 - accuracy: 0.7329 - val_loss: 0.5103 - val_accuracy: 0.7456\n",
            "Epoch 15/50\n",
            "13117/13117 [==============================] - 124s 9ms/step - loss: 0.5250 - accuracy: 0.7330 - val_loss: 0.5069 - val_accuracy: 0.7475\n",
            "Epoch 16/50\n",
            "13117/13117 [==============================] - 122s 9ms/step - loss: 0.5242 - accuracy: 0.7339 - val_loss: 0.5103 - val_accuracy: 0.7454\n",
            "Epoch 17/50\n",
            "13117/13117 [==============================] - 120s 9ms/step - loss: 0.5240 - accuracy: 0.7343 - val_loss: 0.5069 - val_accuracy: 0.7479\n",
            "Epoch 18/50\n",
            "13117/13117 [==============================] - 119s 9ms/step - loss: 0.5236 - accuracy: 0.7341 - val_loss: 0.5053 - val_accuracy: 0.7472\n",
            "Epoch 19/50\n",
            "13117/13117 [==============================] - 115s 9ms/step - loss: 0.5231 - accuracy: 0.7355 - val_loss: 0.5057 - val_accuracy: 0.7475\n",
            "Epoch 20/50\n",
            "13117/13117 [==============================] - 114s 9ms/step - loss: 0.5227 - accuracy: 0.7350 - val_loss: 0.5067 - val_accuracy: 0.7467\n",
            "Epoch 21/50\n",
            "13117/13117 [==============================] - 122s 9ms/step - loss: 0.5220 - accuracy: 0.7351 - val_loss: 0.5038 - val_accuracy: 0.7483\n",
            "Epoch 22/50\n",
            "13117/13117 [==============================] - 115s 9ms/step - loss: 0.5216 - accuracy: 0.7354 - val_loss: 0.5057 - val_accuracy: 0.7472\n",
            "Epoch 23/50\n",
            "13117/13117 [==============================] - 114s 9ms/step - loss: 0.5211 - accuracy: 0.7359 - val_loss: 0.5035 - val_accuracy: 0.7486\n",
            "Epoch 24/50\n",
            "13117/13117 [==============================] - 116s 9ms/step - loss: 0.5209 - accuracy: 0.7362 - val_loss: 0.5046 - val_accuracy: 0.7471\n",
            "Epoch 25/50\n",
            "13117/13117 [==============================] - 116s 9ms/step - loss: 0.5207 - accuracy: 0.7368 - val_loss: 0.5045 - val_accuracy: 0.7486\n",
            "Epoch 26/50\n",
            "13117/13117 [==============================] - 114s 9ms/step - loss: 0.5202 - accuracy: 0.7368 - val_loss: 0.5028 - val_accuracy: 0.7490\n",
            "Epoch 27/50\n",
            "13117/13117 [==============================] - 118s 9ms/step - loss: 0.5195 - accuracy: 0.7370 - val_loss: 0.5039 - val_accuracy: 0.7483\n",
            "Epoch 28/50\n",
            "13117/13117 [==============================] - 116s 9ms/step - loss: 0.5197 - accuracy: 0.7369 - val_loss: 0.5064 - val_accuracy: 0.7483\n",
            "Epoch 29/50\n",
            "13117/13117 [==============================] - 121s 9ms/step - loss: 0.5195 - accuracy: 0.7373 - val_loss: 0.5041 - val_accuracy: 0.7491\n",
            "Epoch 30/50\n",
            "13117/13117 [==============================] - 118s 9ms/step - loss: 0.5191 - accuracy: 0.7367 - val_loss: 0.5030 - val_accuracy: 0.7496\n",
            "Epoch 31/50\n",
            "13117/13117 [==============================] - 116s 9ms/step - loss: 0.5190 - accuracy: 0.7372 - val_loss: 0.5032 - val_accuracy: 0.7488\n",
            "Epoch 31: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_features, test_labels)\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "test_pred = model.predict(test_features)\n",
        "test_pred_binary = (test_pred >= 0.5).astype(int)\n",
        "test_auc = roc_auc_score(test_labels, test_pred)\n",
        "test_f1 = f1_score(test_labels, test_pred_binary)\n",
        "\n",
        "print(f\"Test AUC: {test_auc:.4f}\")\n",
        "print(f\"Test F1 score: {test_f1:.4f}\")"
      ],
      "metadata": {
        "id": "t18ZGkCMn4y0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6914f36-e8d1-457f-fae3-c92e8a52acaf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2813/2813 [==============================] - 6s 2ms/step - loss: 0.5036 - accuracy: 0.7472\n",
            "Test loss: 0.5036\n",
            "Test accuracy: 0.7472\n",
            "2813/2813 [==============================] - 6s 2ms/step\n",
            "Test AUC: 0.8312\n",
            "Test F1 score: 0.7642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Normalize the input data\n",
        "scaler = StandardScaler()\n",
        "train_features = scaler.fit_transform(train_features)\n",
        "val_features = scaler.transform(val_features)\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_dim=17, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Early stopping callback\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_features, train_labels, epochs=20, batch_size=32, validation_data=(val_features, val_labels), callbacks=[es])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cza44Lcyje95",
        "outputId": "095cf201-070c-4670-e07f-de604fc87ff6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "13117/13117 [==============================] - 120s 9ms/step - loss: 0.5867 - accuracy: 0.6954 - val_loss: 0.5417 - val_accuracy: 0.7240\n",
            "Epoch 2/20\n",
            "13117/13117 [==============================] - 114s 9ms/step - loss: 0.5521 - accuracy: 0.7157 - val_loss: 0.5303 - val_accuracy: 0.7335\n",
            "Epoch 3/20\n",
            "13117/13117 [==============================] - 113s 9ms/step - loss: 0.5449 - accuracy: 0.7206 - val_loss: 0.5234 - val_accuracy: 0.7366\n",
            "Epoch 4/20\n",
            "13117/13117 [==============================] - 111s 8ms/step - loss: 0.5401 - accuracy: 0.7234 - val_loss: 0.5183 - val_accuracy: 0.7403\n",
            "Epoch 5/20\n",
            "13117/13117 [==============================] - 113s 9ms/step - loss: 0.5374 - accuracy: 0.7255 - val_loss: 0.5207 - val_accuracy: 0.7406\n",
            "Epoch 6/20\n",
            "13117/13117 [==============================] - 116s 9ms/step - loss: 0.5349 - accuracy: 0.7268 - val_loss: 0.5140 - val_accuracy: 0.7430\n",
            "Epoch 7/20\n",
            "13117/13117 [==============================] - 117s 9ms/step - loss: 0.5330 - accuracy: 0.7280 - val_loss: 0.5116 - val_accuracy: 0.7425\n",
            "Epoch 8/20\n",
            "13117/13117 [==============================] - 119s 9ms/step - loss: 0.5322 - accuracy: 0.7284 - val_loss: 0.5128 - val_accuracy: 0.7430\n",
            "Epoch 9/20\n",
            "13117/13117 [==============================] - 113s 9ms/step - loss: 0.5308 - accuracy: 0.7297 - val_loss: 0.5112 - val_accuracy: 0.7435\n",
            "Epoch 10/20\n",
            "13117/13117 [==============================] - 112s 9ms/step - loss: 0.5292 - accuracy: 0.7311 - val_loss: 0.5089 - val_accuracy: 0.7452\n",
            "Epoch 11/20\n",
            "13117/13117 [==============================] - 114s 9ms/step - loss: 0.5282 - accuracy: 0.7309 - val_loss: 0.5111 - val_accuracy: 0.7444\n",
            "Epoch 12/20\n",
            "13117/13117 [==============================] - 112s 9ms/step - loss: 0.5277 - accuracy: 0.7321 - val_loss: 0.5073 - val_accuracy: 0.7452\n",
            "Epoch 13/20\n",
            "13117/13117 [==============================] - 110s 8ms/step - loss: 0.5265 - accuracy: 0.7323 - val_loss: 0.5077 - val_accuracy: 0.7441\n",
            "Epoch 14/20\n",
            "13117/13117 [==============================] - 112s 9ms/step - loss: 0.5263 - accuracy: 0.7333 - val_loss: 0.5099 - val_accuracy: 0.7438\n",
            "Epoch 15/20\n",
            "13117/13117 [==============================] - 113s 9ms/step - loss: 0.5254 - accuracy: 0.7332 - val_loss: 0.5077 - val_accuracy: 0.7464\n",
            "Epoch 16/20\n",
            "13117/13117 [==============================] - 113s 9ms/step - loss: 0.5248 - accuracy: 0.7331 - val_loss: 0.5061 - val_accuracy: 0.7468\n",
            "Epoch 17/20\n",
            "13117/13117 [==============================] - 117s 9ms/step - loss: 0.5242 - accuracy: 0.7334 - val_loss: 0.5074 - val_accuracy: 0.7451\n",
            "Epoch 18/20\n",
            "13117/13117 [==============================] - 113s 9ms/step - loss: 0.5232 - accuracy: 0.7346 - val_loss: 0.5058 - val_accuracy: 0.7463\n",
            "Epoch 19/20\n",
            "13117/13117 [==============================] - 117s 9ms/step - loss: 0.5232 - accuracy: 0.7342 - val_loss: 0.5069 - val_accuracy: 0.7472\n",
            "Epoch 20/20\n",
            "13117/13117 [==============================] - 117s 9ms/step - loss: 0.5224 - accuracy: 0.7352 - val_loss: 0.5051 - val_accuracy: 0.7486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_features, test_labels)\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "test_pred = model.predict(test_features)\n",
        "test_pred_binary = (test_pred >= 0.5).astype(int)\n",
        "test_auc = roc_auc_score(test_labels, test_pred)\n",
        "test_f1 = f1_score(test_labels, test_pred_binary)\n",
        "\n",
        "print(f\"Test AUC: {test_auc:.4f}\")\n",
        "print(f\"Test F1 score: {test_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hkHBVXXjhR9",
        "outputId": "8af76898-a549-433d-c231-62135f0f4471"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2813/2813 [==============================] - 6s 2ms/step - loss: 0.5050 - accuracy: 0.7465\n",
            "Test loss: 0.5050\n",
            "Test accuracy: 0.7465\n",
            "2813/2813 [==============================] - 6s 2ms/step\n",
            "Test AUC: 0.8301\n",
            "Test F1 score: 0.7603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Normalize the input data\n",
        "scaler = StandardScaler()\n",
        "train_features = scaler.fit_transform(train_features)\n",
        "val_features = scaler.transform(val_features)\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_dim=17, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization()) #it normalize the batch\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))#it penalizes the parameter of the model which are baise and weight\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Early stopping callback\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_features, train_labels, epochs=100, batch_size=64, validation_data=(val_features, val_labels), callbacks=[es])\n",
        "\n"
      ],
      "metadata": {
        "id": "7eS7lP8UPB0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c976fc3-104b-4299-c107-68e5dce86a07"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "6559/6559 [==============================] - 79s 12ms/step - loss: 0.5922 - accuracy: 0.6975 - val_loss: 0.5344 - val_accuracy: 0.7291\n",
            "Epoch 2/100\n",
            "6559/6559 [==============================] - 75s 11ms/step - loss: 0.5476 - accuracy: 0.7194 - val_loss: 0.5259 - val_accuracy: 0.7342\n",
            "Epoch 3/100\n",
            "6559/6559 [==============================] - 78s 12ms/step - loss: 0.5398 - accuracy: 0.7244 - val_loss: 0.5208 - val_accuracy: 0.7368\n",
            "Epoch 4/100\n",
            "6559/6559 [==============================] - 76s 12ms/step - loss: 0.5354 - accuracy: 0.7273 - val_loss: 0.5172 - val_accuracy: 0.7414\n",
            "Epoch 5/100\n",
            "6559/6559 [==============================] - 77s 12ms/step - loss: 0.5317 - accuracy: 0.7291 - val_loss: 0.5149 - val_accuracy: 0.7402\n",
            "Epoch 6/100\n",
            "6559/6559 [==============================] - 76s 12ms/step - loss: 0.5295 - accuracy: 0.7308 - val_loss: 0.5149 - val_accuracy: 0.7421\n",
            "Epoch 7/100\n",
            "6559/6559 [==============================] - 78s 12ms/step - loss: 0.5273 - accuracy: 0.7318 - val_loss: 0.5087 - val_accuracy: 0.7439\n",
            "Epoch 8/100\n",
            "6559/6559 [==============================] - 77s 12ms/step - loss: 0.5250 - accuracy: 0.7338 - val_loss: 0.5101 - val_accuracy: 0.7444\n",
            "Epoch 9/100\n",
            "6559/6559 [==============================] - 79s 12ms/step - loss: 0.5241 - accuracy: 0.7342 - val_loss: 0.5078 - val_accuracy: 0.7447\n",
            "Epoch 10/100\n",
            "6559/6559 [==============================] - 77s 12ms/step - loss: 0.5229 - accuracy: 0.7350 - val_loss: 0.5071 - val_accuracy: 0.7452\n",
            "Epoch 11/100\n",
            "6559/6559 [==============================] - 79s 12ms/step - loss: 0.5218 - accuracy: 0.7357 - val_loss: 0.5067 - val_accuracy: 0.7462\n",
            "Epoch 12/100\n",
            "6559/6559 [==============================] - 77s 12ms/step - loss: 0.5204 - accuracy: 0.7366 - val_loss: 0.5053 - val_accuracy: 0.7462\n",
            "Epoch 13/100\n",
            "6559/6559 [==============================] - 79s 12ms/step - loss: 0.5203 - accuracy: 0.7372 - val_loss: 0.5061 - val_accuracy: 0.7449\n",
            "Epoch 14/100\n",
            "6559/6559 [==============================] - 78s 12ms/step - loss: 0.5192 - accuracy: 0.7374 - val_loss: 0.5049 - val_accuracy: 0.7477\n",
            "Epoch 15/100\n",
            "6559/6559 [==============================] - 78s 12ms/step - loss: 0.5183 - accuracy: 0.7375 - val_loss: 0.5031 - val_accuracy: 0.7471\n",
            "Epoch 16/100\n",
            "6559/6559 [==============================] - 79s 12ms/step - loss: 0.5177 - accuracy: 0.7384 - val_loss: 0.5026 - val_accuracy: 0.7480\n",
            "Epoch 17/100\n",
            "6559/6559 [==============================] - 78s 12ms/step - loss: 0.5172 - accuracy: 0.7389 - val_loss: 0.5028 - val_accuracy: 0.7484\n",
            "Epoch 18/100\n",
            "6559/6559 [==============================] - 78s 12ms/step - loss: 0.5163 - accuracy: 0.7390 - val_loss: 0.5039 - val_accuracy: 0.7489\n",
            "Epoch 19/100\n",
            "6559/6559 [==============================] - 79s 12ms/step - loss: 0.5164 - accuracy: 0.7388 - val_loss: 0.5020 - val_accuracy: 0.7495\n",
            "Epoch 20/100\n",
            "6559/6559 [==============================] - 77s 12ms/step - loss: 0.5152 - accuracy: 0.7403 - val_loss: 0.5023 - val_accuracy: 0.7485\n",
            "Epoch 21/100\n",
            "6559/6559 [==============================] - 78s 12ms/step - loss: 0.5153 - accuracy: 0.7397 - val_loss: 0.5031 - val_accuracy: 0.7473\n",
            "Epoch 22/100\n",
            "6559/6559 [==============================] - 80s 12ms/step - loss: 0.5150 - accuracy: 0.7398 - val_loss: 0.5022 - val_accuracy: 0.7494\n",
            "Epoch 23/100\n",
            "6559/6559 [==============================] - 78s 12ms/step - loss: 0.5145 - accuracy: 0.7400 - val_loss: 0.5036 - val_accuracy: 0.7492\n",
            "Epoch 24/100\n",
            "6559/6559 [==============================] - 78s 12ms/step - loss: 0.5137 - accuracy: 0.7410 - val_loss: 0.5009 - val_accuracy: 0.7496\n",
            "Epoch 25/100\n",
            "6559/6559 [==============================] - 79s 12ms/step - loss: 0.5139 - accuracy: 0.7404 - val_loss: 0.5020 - val_accuracy: 0.7486\n",
            "Epoch 26/100\n",
            "6559/6559 [==============================] - 78s 12ms/step - loss: 0.5130 - accuracy: 0.7409 - val_loss: 0.5016 - val_accuracy: 0.7500\n",
            "Epoch 27/100\n",
            "6559/6559 [==============================] - 77s 12ms/step - loss: 0.5126 - accuracy: 0.7417 - val_loss: 0.5002 - val_accuracy: 0.7511\n",
            "Epoch 28/100\n",
            "6559/6559 [==============================] - 79s 12ms/step - loss: 0.5130 - accuracy: 0.7413 - val_loss: 0.5008 - val_accuracy: 0.7502\n",
            "Epoch 29/100\n",
            "6559/6559 [==============================] - 79s 12ms/step - loss: 0.5116 - accuracy: 0.7421 - val_loss: 0.5033 - val_accuracy: 0.7491\n",
            "Epoch 30/100\n",
            "6559/6559 [==============================] - 78s 12ms/step - loss: 0.5123 - accuracy: 0.7426 - val_loss: 0.5007 - val_accuracy: 0.7501\n",
            "Epoch 31/100\n",
            "6559/6559 [==============================] - 79s 12ms/step - loss: 0.5115 - accuracy: 0.7424 - val_loss: 0.5005 - val_accuracy: 0.7498\n",
            "Epoch 32/100\n",
            "6559/6559 [==============================] - 78s 12ms/step - loss: 0.5111 - accuracy: 0.7427 - val_loss: 0.5003 - val_accuracy: 0.7500\n",
            "Epoch 32: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_features, test_labels)\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "test_pred = model.predict(test_features)\n",
        "test_pred_binary = (test_pred >= 0.5).astype(int)\n",
        "test_auc = roc_auc_score(test_labels, test_pred)\n",
        "test_f1 = f1_score(test_labels, test_pred_binary)\n",
        "\n",
        "print(f\"Test AUC: {test_auc:.4f}\")\n",
        "print(f\"Test F1 score: {test_f1:.4f}\")"
      ],
      "metadata": {
        "id": "MfEJm-ybn3PV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdd755ba-7eda-4460-ee3f-a1be21cbdac1"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2813/2813 [==============================] - 7s 3ms/step - loss: 0.5010 - accuracy: 0.7479\n",
            "Test loss: 0.5010\n",
            "Test accuracy: 0.7479\n",
            "2813/2813 [==============================] - 8s 3ms/step\n",
            "Test AUC: 0.8322\n",
            "Test F1 score: 0.7642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Normalize the input data\n",
        "scaler = StandardScaler()\n",
        "train_features = scaler.fit_transform(train_features)\n",
        "val_features = scaler.transform(val_features)\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_dim=17, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Early stopping callback\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_features, train_labels, epochs=100, batch_size=128, validation_data=(val_features, val_labels), callbacks=[es])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "uTjor0x2GQCM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c848d5be-1211-45db-bf1a-0378fc309d36"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3280/3280 [==============================] - 55s 16ms/step - loss: 0.6977 - accuracy: 0.6031 - val_loss: 0.6338 - val_accuracy: 0.6729\n",
            "Epoch 2/100\n",
            "3280/3280 [==============================] - 50s 15ms/step - loss: 0.6422 - accuracy: 0.6605 - val_loss: 0.6004 - val_accuracy: 0.6976\n",
            "Epoch 3/100\n",
            "3280/3280 [==============================] - 51s 16ms/step - loss: 0.6120 - accuracy: 0.6832 - val_loss: 0.5767 - val_accuracy: 0.7089\n",
            "Epoch 4/100\n",
            "3280/3280 [==============================] - 50s 15ms/step - loss: 0.5927 - accuracy: 0.6946 - val_loss: 0.5633 - val_accuracy: 0.7164\n",
            "Epoch 5/100\n",
            "3280/3280 [==============================] - 50s 15ms/step - loss: 0.5799 - accuracy: 0.7015 - val_loss: 0.5525 - val_accuracy: 0.7219\n",
            "Epoch 6/100\n",
            "3280/3280 [==============================] - 53s 16ms/step - loss: 0.5711 - accuracy: 0.7058 - val_loss: 0.5449 - val_accuracy: 0.7260\n",
            "Epoch 7/100\n",
            "3280/3280 [==============================] - 55s 17ms/step - loss: 0.5642 - accuracy: 0.7100 - val_loss: 0.5396 - val_accuracy: 0.7298\n",
            "Epoch 8/100\n",
            "3280/3280 [==============================] - 51s 15ms/step - loss: 0.5587 - accuracy: 0.7130 - val_loss: 0.5355 - val_accuracy: 0.7315\n",
            "Epoch 9/100\n",
            "3280/3280 [==============================] - 53s 16ms/step - loss: 0.5548 - accuracy: 0.7162 - val_loss: 0.5321 - val_accuracy: 0.7323\n",
            "Epoch 10/100\n",
            "3280/3280 [==============================] - 50s 15ms/step - loss: 0.5517 - accuracy: 0.7172 - val_loss: 0.5298 - val_accuracy: 0.7325\n",
            "Epoch 11/100\n",
            "3280/3280 [==============================] - 53s 16ms/step - loss: 0.5494 - accuracy: 0.7189 - val_loss: 0.5274 - val_accuracy: 0.7346\n",
            "Epoch 12/100\n",
            "3280/3280 [==============================] - 50s 15ms/step - loss: 0.5471 - accuracy: 0.7207 - val_loss: 0.5275 - val_accuracy: 0.7338\n",
            "Epoch 13/100\n",
            "3280/3280 [==============================] - 53s 16ms/step - loss: 0.5446 - accuracy: 0.7210 - val_loss: 0.5245 - val_accuracy: 0.7357\n",
            "Epoch 14/100\n",
            "3280/3280 [==============================] - 50s 15ms/step - loss: 0.5432 - accuracy: 0.7226 - val_loss: 0.5225 - val_accuracy: 0.7368\n",
            "Epoch 15/100\n",
            "3280/3280 [==============================] - 54s 16ms/step - loss: 0.5420 - accuracy: 0.7231 - val_loss: 0.5209 - val_accuracy: 0.7382\n",
            "Epoch 16/100\n",
            "3280/3280 [==============================] - 49s 15ms/step - loss: 0.5410 - accuracy: 0.7232 - val_loss: 0.5213 - val_accuracy: 0.7380\n",
            "Epoch 17/100\n",
            "3280/3280 [==============================] - 53s 16ms/step - loss: 0.5390 - accuracy: 0.7246 - val_loss: 0.5192 - val_accuracy: 0.7393\n",
            "Epoch 18/100\n",
            "3280/3280 [==============================] - 50s 15ms/step - loss: 0.5380 - accuracy: 0.7256 - val_loss: 0.5180 - val_accuracy: 0.7392\n",
            "Epoch 19/100\n",
            "3280/3280 [==============================] - 53s 16ms/step - loss: 0.5371 - accuracy: 0.7260 - val_loss: 0.5174 - val_accuracy: 0.7402\n",
            "Epoch 20/100\n",
            "3280/3280 [==============================] - 50s 15ms/step - loss: 0.5364 - accuracy: 0.7263 - val_loss: 0.5166 - val_accuracy: 0.7413\n",
            "Epoch 21/100\n",
            "3280/3280 [==============================] - 53s 16ms/step - loss: 0.5354 - accuracy: 0.7269 - val_loss: 0.5159 - val_accuracy: 0.7410\n",
            "Epoch 22/100\n",
            "3280/3280 [==============================] - 50s 15ms/step - loss: 0.5342 - accuracy: 0.7276 - val_loss: 0.5148 - val_accuracy: 0.7417\n",
            "Epoch 23/100\n",
            "3280/3280 [==============================] - 53s 16ms/step - loss: 0.5340 - accuracy: 0.7274 - val_loss: 0.5142 - val_accuracy: 0.7415\n",
            "Epoch 24/100\n",
            "3280/3280 [==============================] - 50s 15ms/step - loss: 0.5333 - accuracy: 0.7279 - val_loss: 0.5135 - val_accuracy: 0.7420\n",
            "Epoch 25/100\n",
            "3280/3280 [==============================] - 53s 16ms/step - loss: 0.5321 - accuracy: 0.7289 - val_loss: 0.5127 - val_accuracy: 0.7418\n",
            "Epoch 26/100\n",
            "3280/3280 [==============================] - 50s 15ms/step - loss: 0.5316 - accuracy: 0.7288 - val_loss: 0.5129 - val_accuracy: 0.7427\n",
            "Epoch 27/100\n",
            "3280/3280 [==============================] - 52s 16ms/step - loss: 0.5308 - accuracy: 0.7297 - val_loss: 0.5119 - val_accuracy: 0.7430\n",
            "Epoch 28/100\n",
            "3280/3280 [==============================] - 50s 15ms/step - loss: 0.5300 - accuracy: 0.7306 - val_loss: 0.5117 - val_accuracy: 0.7435\n",
            "Epoch 29/100\n",
            "3280/3280 [==============================] - 54s 16ms/step - loss: 0.5301 - accuracy: 0.7307 - val_loss: 0.5112 - val_accuracy: 0.7433\n",
            "Epoch 30/100\n",
            "3280/3280 [==============================] - 51s 16ms/step - loss: 0.5292 - accuracy: 0.7307 - val_loss: 0.5112 - val_accuracy: 0.7433\n",
            "Epoch 31/100\n",
            "3280/3280 [==============================] - 54s 17ms/step - loss: 0.5290 - accuracy: 0.7309 - val_loss: 0.5101 - val_accuracy: 0.7434\n",
            "Epoch 32/100\n",
            "3280/3280 [==============================] - 50s 15ms/step - loss: 0.5278 - accuracy: 0.7317 - val_loss: 0.5102 - val_accuracy: 0.7444\n",
            "Epoch 33/100\n",
            "3280/3280 [==============================] - 52s 16ms/step - loss: 0.5281 - accuracy: 0.7316 - val_loss: 0.5093 - val_accuracy: 0.7445\n",
            "Epoch 34/100\n",
            "3280/3280 [==============================] - 50s 15ms/step - loss: 0.5280 - accuracy: 0.7320 - val_loss: 0.5091 - val_accuracy: 0.7455\n",
            "Epoch 35/100\n",
            "3280/3280 [==============================] - 54s 17ms/step - loss: 0.5269 - accuracy: 0.7326 - val_loss: 0.5091 - val_accuracy: 0.7452\n",
            "Epoch 36/100\n",
            "3280/3280 [==============================] - 50s 15ms/step - loss: 0.5266 - accuracy: 0.7333 - val_loss: 0.5085 - val_accuracy: 0.7451\n",
            "Epoch 37/100\n",
            "3280/3280 [==============================] - 53s 16ms/step - loss: 0.5260 - accuracy: 0.7324 - val_loss: 0.5079 - val_accuracy: 0.7459\n",
            "Epoch 38/100\n",
            "3280/3280 [==============================] - 50s 15ms/step - loss: 0.5259 - accuracy: 0.7327 - val_loss: 0.5087 - val_accuracy: 0.7450\n",
            "Epoch 39/100\n",
            "3280/3280 [==============================] - 53s 16ms/step - loss: 0.5256 - accuracy: 0.7335 - val_loss: 0.5075 - val_accuracy: 0.7457\n",
            "Epoch 40/100\n",
            "3280/3280 [==============================] - 50s 15ms/step - loss: 0.5253 - accuracy: 0.7334 - val_loss: 0.5090 - val_accuracy: 0.7455\n",
            "Epoch 41/100\n",
            "3280/3280 [==============================] - 53s 16ms/step - loss: 0.5247 - accuracy: 0.7333 - val_loss: 0.5071 - val_accuracy: 0.7456\n",
            "Epoch 42/100\n",
            "3280/3280 [==============================] - 50s 15ms/step - loss: 0.5244 - accuracy: 0.7332 - val_loss: 0.5071 - val_accuracy: 0.7470\n",
            "Epoch 43/100\n",
            "3280/3280 [==============================] - 54s 17ms/step - loss: 0.5240 - accuracy: 0.7342 - val_loss: 0.5074 - val_accuracy: 0.7460\n",
            "Epoch 44/100\n",
            "3280/3280 [==============================] - 51s 15ms/step - loss: 0.5242 - accuracy: 0.7343 - val_loss: 0.5065 - val_accuracy: 0.7469\n",
            "Epoch 45/100\n",
            "3280/3280 [==============================] - 54s 16ms/step - loss: 0.5236 - accuracy: 0.7355 - val_loss: 0.5072 - val_accuracy: 0.7456\n",
            "Epoch 46/100\n",
            "3280/3280 [==============================] - 50s 15ms/step - loss: 0.5231 - accuracy: 0.7350 - val_loss: 0.5065 - val_accuracy: 0.7471\n",
            "Epoch 47/100\n",
            "3280/3280 [==============================] - 52s 16ms/step - loss: 0.5230 - accuracy: 0.7356 - val_loss: 0.5067 - val_accuracy: 0.7463\n",
            "Epoch 48/100\n",
            "3280/3280 [==============================] - 51s 16ms/step - loss: 0.5227 - accuracy: 0.7348 - val_loss: 0.5064 - val_accuracy: 0.7463\n",
            "Epoch 49/100\n",
            "3280/3280 [==============================] - 52s 16ms/step - loss: 0.5227 - accuracy: 0.7358 - val_loss: 0.5057 - val_accuracy: 0.7468\n",
            "Epoch 50/100\n",
            "3280/3280 [==============================] - 51s 16ms/step - loss: 0.5221 - accuracy: 0.7356 - val_loss: 0.5058 - val_accuracy: 0.7467\n",
            "Epoch 51/100\n",
            "3280/3280 [==============================] - 52s 16ms/step - loss: 0.5217 - accuracy: 0.7359 - val_loss: 0.5042 - val_accuracy: 0.7478\n",
            "Epoch 52/100\n",
            "3280/3280 [==============================] - 50s 15ms/step - loss: 0.5218 - accuracy: 0.7362 - val_loss: 0.5044 - val_accuracy: 0.7478\n",
            "Epoch 53/100\n",
            "3280/3280 [==============================] - 53s 16ms/step - loss: 0.5214 - accuracy: 0.7362 - val_loss: 0.5049 - val_accuracy: 0.7478\n",
            "Epoch 54/100\n",
            "3280/3280 [==============================] - 50s 15ms/step - loss: 0.5213 - accuracy: 0.7364 - val_loss: 0.5051 - val_accuracy: 0.7471\n",
            "Epoch 55/100\n",
            "3280/3280 [==============================] - 53s 16ms/step - loss: 0.5209 - accuracy: 0.7360 - val_loss: 0.5064 - val_accuracy: 0.7465\n",
            "Epoch 56/100\n",
            "3280/3280 [==============================] - 52s 16ms/step - loss: 0.5208 - accuracy: 0.7363 - val_loss: 0.5052 - val_accuracy: 0.7477\n",
            "Epoch 56: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_features, test_labels)\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "test_pred = model.predict(test_features)\n",
        "test_pred_binary = (test_pred >= 0.5).astype(int)\n",
        "test_auc = roc_auc_score(test_labels, test_pred)\n",
        "test_f1 = f1_score(test_labels, test_pred_binary)\n",
        "\n",
        "print(f\"Test AUC: {test_auc:.4f}\")\n",
        "print(f\"Test F1 score: {test_f1:.4f}\")"
      ],
      "metadata": {
        "id": "ifzZ4ZlXn1m_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8deeb01a-d32e-4b4a-bdc2-c4f22b4c840a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2813/2813 [==============================] - 9s 3ms/step - loss: 0.5064 - accuracy: 0.7450\n",
            "Test loss: 0.5064\n",
            "Test accuracy: 0.7450\n",
            "2813/2813 [==============================] - 7s 2ms/step\n",
            "Test AUC: 0.8283\n",
            "Test F1 score: 0.7597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "from tensorflow.keras.initializers import GlorotUniform\n",
        "\n",
        "# Define a learning rate schedule\n",
        "def lr_schedule(epoch):\n",
        "    if epoch < 10:\n",
        "        return 0.001\n",
        "    else:\n",
        "        return 0.001 * np.exp(0.1 * (10 - epoch))\n",
        "\n",
        "# Normalize the input data\n",
        "scaler = StandardScaler()\n",
        "train_features = scaler.fit_transform(train_features)\n",
        "val_features = scaler.transform(val_features)\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_dim=17, activation='relu', kernel_initializer=GlorotUniform()))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(512, activation='relu', kernel_initializer=GlorotUniform()))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu', kernel_initializer=GlorotUniform()))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(128, activation='relu', kernel_initializer=GlorotUniform()))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu', kernel_initializer=GlorotUniform()))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Learning rate schedule callback\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "# Early stopping callback\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_features, train_labels, epochs=50, batch_size=128, validation_data=(val_features, val_labels), callbacks=[lr_scheduler, es])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_features, test_labels)\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "test_pred = model.predict(test_features)\n",
        "test_pred_binary = (test_pred >= 0.5).astype(int)\n",
        "test_auc = roc_auc_score(test_labels, test_pred)\n",
        "test_f1 = f1_score(test_labels, test_pred_binary)\n",
        "\n",
        "print(f\"Test AUC: {test_auc:.4f}\")\n",
        "print(f\"Test F1 score: {test_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_NF2zhUyp-G",
        "outputId": "a7ef1311-7d76-431d-9b01-ccfb780c0ef5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "3280/3280 [==============================] - 117s 35ms/step - loss: 0.5755 - accuracy: 0.6969 - val_loss: 0.5324 - val_accuracy: 0.7289 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "3280/3280 [==============================] - 110s 34ms/step - loss: 0.5427 - accuracy: 0.7217 - val_loss: 0.5250 - val_accuracy: 0.7316 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "3280/3280 [==============================] - 112s 34ms/step - loss: 0.5345 - accuracy: 0.7278 - val_loss: 0.5176 - val_accuracy: 0.7390 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "3280/3280 [==============================] - 110s 33ms/step - loss: 0.5295 - accuracy: 0.7308 - val_loss: 0.5144 - val_accuracy: 0.7421 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "3280/3280 [==============================] - 112s 34ms/step - loss: 0.5255 - accuracy: 0.7336 - val_loss: 0.5106 - val_accuracy: 0.7438 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "3280/3280 [==============================] - 119s 36ms/step - loss: 0.5223 - accuracy: 0.7357 - val_loss: 0.5085 - val_accuracy: 0.7467 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "3280/3280 [==============================] - 118s 36ms/step - loss: 0.5198 - accuracy: 0.7375 - val_loss: 0.5084 - val_accuracy: 0.7453 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "3280/3280 [==============================] - 112s 34ms/step - loss: 0.5168 - accuracy: 0.7392 - val_loss: 0.5055 - val_accuracy: 0.7463 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "3280/3280 [==============================] - 111s 34ms/step - loss: 0.5152 - accuracy: 0.7399 - val_loss: 0.5039 - val_accuracy: 0.7478 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "3280/3280 [==============================] - 116s 35ms/step - loss: 0.5138 - accuracy: 0.7412 - val_loss: 0.5031 - val_accuracy: 0.7480 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "3280/3280 [==============================] - 116s 35ms/step - loss: 0.5123 - accuracy: 0.7426 - val_loss: 0.5021 - val_accuracy: 0.7487 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "3280/3280 [==============================] - 115s 35ms/step - loss: 0.5101 - accuracy: 0.7429 - val_loss: 0.5016 - val_accuracy: 0.7493 - lr: 9.0484e-04\n",
            "Epoch 13/50\n",
            "3280/3280 [==============================] - 111s 34ms/step - loss: 0.5081 - accuracy: 0.7449 - val_loss: 0.5001 - val_accuracy: 0.7498 - lr: 8.1873e-04\n",
            "Epoch 14/50\n",
            "3280/3280 [==============================] - 110s 34ms/step - loss: 0.5064 - accuracy: 0.7453 - val_loss: 0.4986 - val_accuracy: 0.7507 - lr: 7.4082e-04\n",
            "Epoch 15/50\n",
            "3280/3280 [==============================] - 111s 34ms/step - loss: 0.5042 - accuracy: 0.7468 - val_loss: 0.4971 - val_accuracy: 0.7515 - lr: 6.7032e-04\n",
            "Epoch 16/50\n",
            "3280/3280 [==============================] - 112s 34ms/step - loss: 0.5024 - accuracy: 0.7477 - val_loss: 0.4974 - val_accuracy: 0.7512 - lr: 6.0653e-04\n",
            "Epoch 17/50\n",
            "3280/3280 [==============================] - 117s 36ms/step - loss: 0.5011 - accuracy: 0.7490 - val_loss: 0.4977 - val_accuracy: 0.7520 - lr: 5.4881e-04\n",
            "Epoch 18/50\n",
            "3280/3280 [==============================] - 112s 34ms/step - loss: 0.5003 - accuracy: 0.7500 - val_loss: 0.4970 - val_accuracy: 0.7516 - lr: 4.9659e-04\n",
            "Epoch 19/50\n",
            "3280/3280 [==============================] - 111s 34ms/step - loss: 0.4993 - accuracy: 0.7504 - val_loss: 0.4957 - val_accuracy: 0.7515 - lr: 4.4933e-04\n",
            "Epoch 20/50\n",
            "3280/3280 [==============================] - 111s 34ms/step - loss: 0.4973 - accuracy: 0.7509 - val_loss: 0.4963 - val_accuracy: 0.7516 - lr: 4.0657e-04\n",
            "Epoch 21/50\n",
            "3280/3280 [==============================] - 112s 34ms/step - loss: 0.4963 - accuracy: 0.7522 - val_loss: 0.4958 - val_accuracy: 0.7514 - lr: 3.6788e-04\n",
            "Epoch 22/50\n",
            "3280/3280 [==============================] - 115s 35ms/step - loss: 0.4946 - accuracy: 0.7533 - val_loss: 0.4949 - val_accuracy: 0.7524 - lr: 3.3287e-04\n",
            "Epoch 23/50\n",
            "3280/3280 [==============================] - 110s 34ms/step - loss: 0.4944 - accuracy: 0.7532 - val_loss: 0.4950 - val_accuracy: 0.7527 - lr: 3.0119e-04\n",
            "Epoch 24/50\n",
            "3280/3280 [==============================] - 115s 35ms/step - loss: 0.4928 - accuracy: 0.7543 - val_loss: 0.4945 - val_accuracy: 0.7524 - lr: 2.7253e-04\n",
            "Epoch 25/50\n",
            "3280/3280 [==============================] - 115s 35ms/step - loss: 0.4924 - accuracy: 0.7548 - val_loss: 0.4943 - val_accuracy: 0.7522 - lr: 2.4660e-04\n",
            "Epoch 26/50\n",
            "3280/3280 [==============================] - 116s 35ms/step - loss: 0.4916 - accuracy: 0.7550 - val_loss: 0.4947 - val_accuracy: 0.7516 - lr: 2.2313e-04\n",
            "Epoch 27/50\n",
            "3280/3280 [==============================] - 117s 36ms/step - loss: 0.4904 - accuracy: 0.7557 - val_loss: 0.4943 - val_accuracy: 0.7523 - lr: 2.0190e-04\n",
            "Epoch 28/50\n",
            "3280/3280 [==============================] - 111s 34ms/step - loss: 0.4899 - accuracy: 0.7558 - val_loss: 0.4944 - val_accuracy: 0.7521 - lr: 1.8268e-04\n",
            "Epoch 29/50\n",
            "3280/3280 [==============================] - 110s 34ms/step - loss: 0.4898 - accuracy: 0.7559 - val_loss: 0.4941 - val_accuracy: 0.7524 - lr: 1.6530e-04\n",
            "Epoch 30/50\n",
            "3280/3280 [==============================] - 111s 34ms/step - loss: 0.4891 - accuracy: 0.7565 - val_loss: 0.4940 - val_accuracy: 0.7530 - lr: 1.4957e-04\n",
            "Epoch 31/50\n",
            "3280/3280 [==============================] - 111s 34ms/step - loss: 0.4887 - accuracy: 0.7564 - val_loss: 0.4940 - val_accuracy: 0.7529 - lr: 1.3534e-04\n",
            "Epoch 32/50\n",
            "3280/3280 [==============================] - 111s 34ms/step - loss: 0.4881 - accuracy: 0.7574 - val_loss: 0.4938 - val_accuracy: 0.7532 - lr: 1.2246e-04\n",
            "Epoch 33/50\n",
            "3280/3280 [==============================] - 112s 34ms/step - loss: 0.4878 - accuracy: 0.7573 - val_loss: 0.4938 - val_accuracy: 0.7529 - lr: 1.1080e-04\n",
            "Epoch 34/50\n",
            "3280/3280 [==============================] - 120s 36ms/step - loss: 0.4874 - accuracy: 0.7578 - val_loss: 0.4942 - val_accuracy: 0.7524 - lr: 1.0026e-04\n",
            "Epoch 35/50\n",
            "3280/3280 [==============================] - 117s 36ms/step - loss: 0.4870 - accuracy: 0.7575 - val_loss: 0.4943 - val_accuracy: 0.7531 - lr: 9.0718e-05\n",
            "Epoch 36/50\n",
            "3280/3280 [==============================] - 120s 36ms/step - loss: 0.4853 - accuracy: 0.7587 - val_loss: 0.4943 - val_accuracy: 0.7523 - lr: 8.2085e-05\n",
            "Epoch 37/50\n",
            "3280/3280 [==============================] - 122s 37ms/step - loss: 0.4866 - accuracy: 0.7586 - val_loss: 0.4941 - val_accuracy: 0.7519 - lr: 7.4274e-05\n",
            "Epoch 38/50\n",
            "3280/3280 [==============================] - 120s 36ms/step - loss: 0.4856 - accuracy: 0.7584 - val_loss: 0.4941 - val_accuracy: 0.7524 - lr: 6.7206e-05\n",
            "Epoch 39/50\n",
            "3280/3280 [==============================] - 118s 36ms/step - loss: 0.4858 - accuracy: 0.7591 - val_loss: 0.4944 - val_accuracy: 0.7522 - lr: 6.0810e-05\n",
            "Epoch 40/50\n",
            "3280/3280 [==============================] - 116s 35ms/step - loss: 0.4851 - accuracy: 0.7588 - val_loss: 0.4941 - val_accuracy: 0.7526 - lr: 5.5023e-05\n",
            "Epoch 41/50\n",
            "3280/3280 [==============================] - 119s 36ms/step - loss: 0.4853 - accuracy: 0.7588 - val_loss: 0.4940 - val_accuracy: 0.7529 - lr: 4.9787e-05\n",
            "Epoch 42/50\n",
            "3280/3280 [==============================] - 115s 35ms/step - loss: 0.4850 - accuracy: 0.7593 - val_loss: 0.4943 - val_accuracy: 0.7531 - lr: 4.5049e-05\n",
            "Epoch 42: early stopping\n",
            "2813/2813 [==============================] - 13s 5ms/step - loss: 0.4943 - accuracy: 0.7525\n",
            "Test loss: 0.4943\n",
            "Test accuracy: 0.7525\n",
            "2813/2813 [==============================] - 13s 4ms/step\n",
            "Test AUC: 0.8369\n",
            "Test F1 score: 0.7679\n"
          ]
        }
      ]
    }
  ]
}