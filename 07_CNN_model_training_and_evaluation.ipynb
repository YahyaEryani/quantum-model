{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO7ecYRW6k0tTqXzVaciWj5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YahyaEryani/quantum-model/blob/main/07_CNN_model_training_and_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "T3aPf3ScyB25"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive in Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load data from Google Drive\n",
        "train_path = '/content/drive/MyDrive/Colab Notebooks/train.pkl'\n",
        "val_path   = '/content/drive/MyDrive/Colab Notebooks/validation.pkl'\n",
        "test_path  = '/content/drive/MyDrive/Colab Notebooks/test.pkl'\n",
        "train_data =pd.read_pickle(train_path)\n",
        "val_data = pd.read_pickle(val_path)\n",
        "test_data = pd.read_pickle(test_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_wwMu0NyEUj",
        "outputId": "1ea40737-9ffe-411a-c21a-271162fcd5e7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ufyncxRhaCMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and labels\n",
        "train_labels = train_data['class_label']\n",
        "train_features = train_data.drop('class_label', axis=1)\n",
        "val_labels = val_data['class_label']\n",
        "val_features = val_data.drop('class_label', axis=1)\n",
        "test_labels = test_data['class_label']\n",
        "test_features = test_data.drop('class_label', axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "8NPjn62iyJnf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization"
      ],
      "metadata": {
        "id": "Qsih9HlDyM8P"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=28, activation='relu'))\n",
        "# model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "# model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "bpYVvbNmyQMw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "vpTzgINSySzq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_features, train_labels, epochs=10, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVKmphZoyWW_",
        "outputId": "bf3626b7-62c3-45e1-af64-e280331182a2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.5952 - accuracy: 0.6793\n",
            "Epoch 2/10\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.5758 - accuracy: 0.6976\n",
            "Epoch 3/10\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.5651 - accuracy: 0.7064\n",
            "Epoch 4/10\n",
            "11250/11250 [==============================] - 45s 4ms/step - loss: 0.5575 - accuracy: 0.7116\n",
            "Epoch 5/10\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.5517 - accuracy: 0.7154\n",
            "Epoch 6/10\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.5465 - accuracy: 0.7199\n",
            "Epoch 7/10\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.5421 - accuracy: 0.7233\n",
            "Epoch 8/10\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.5382 - accuracy: 0.7262\n",
            "Epoch 9/10\n",
            "11250/11250 [==============================] - 44s 4ms/step - loss: 0.5356 - accuracy: 0.7281\n",
            "Epoch 10/10\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.5325 - accuracy: 0.7302\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faa98040d00>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_features, train_labels, epochs=20, batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlpHh3uz03Xy",
        "outputId": "3cfa8308-9c90-4ee0-f5a0-89a07001e222"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.5302 - accuracy: 0.7320\n",
            "Epoch 2/20\n",
            "11250/11250 [==============================] - 44s 4ms/step - loss: 0.5278 - accuracy: 0.7329\n",
            "Epoch 3/20\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.5261 - accuracy: 0.7339\n",
            "Epoch 4/20\n",
            "11250/11250 [==============================] - 44s 4ms/step - loss: 0.5239 - accuracy: 0.7357\n",
            "Epoch 5/20\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.5223 - accuracy: 0.7367\n",
            "Epoch 6/20\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.5213 - accuracy: 0.7370\n",
            "Epoch 7/20\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.5190 - accuracy: 0.7385\n",
            "Epoch 8/20\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.5175 - accuracy: 0.7402\n",
            "Epoch 9/20\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.5177 - accuracy: 0.7401\n",
            "Epoch 10/20\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.5160 - accuracy: 0.7412\n",
            "Epoch 11/20\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.5148 - accuracy: 0.7420\n",
            "Epoch 12/20\n",
            "11250/11250 [==============================] - 41s 4ms/step - loss: 0.5145 - accuracy: 0.7420\n",
            "Epoch 13/20\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.5123 - accuracy: 0.7426\n",
            "Epoch 14/20\n",
            "11250/11250 [==============================] - 44s 4ms/step - loss: 0.5116 - accuracy: 0.7443\n",
            "Epoch 15/20\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.5113 - accuracy: 0.7446\n",
            "Epoch 16/20\n",
            "11250/11250 [==============================] - 44s 4ms/step - loss: 0.5105 - accuracy: 0.7448\n",
            "Epoch 17/20\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.5095 - accuracy: 0.7456\n",
            "Epoch 18/20\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.5087 - accuracy: 0.7459\n",
            "Epoch 19/20\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.5081 - accuracy: 0.7467\n",
            "Epoch 20/20\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.5068 - accuracy: 0.7472\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faa96f65d30>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_features, train_labels, epochs=100, batch_size=32, validation_data=(val_features, val_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz0XOWEnBgoO",
        "outputId": "67e4c9c0-53f5-4196-a16e-f26526c9383c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.5064 - accuracy: 0.7479\n",
            "Epoch 2/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.5052 - accuracy: 0.7484\n",
            "Epoch 3/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.5052 - accuracy: 0.7490\n",
            "Epoch 4/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.5048 - accuracy: 0.7488\n",
            "Epoch 5/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.5036 - accuracy: 0.7488\n",
            "Epoch 6/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.5037 - accuracy: 0.7494\n",
            "Epoch 7/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.5030 - accuracy: 0.7497\n",
            "Epoch 8/100\n",
            "11250/11250 [==============================] - 44s 4ms/step - loss: 0.5018 - accuracy: 0.7499\n",
            "Epoch 9/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.5019 - accuracy: 0.7510\n",
            "Epoch 10/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.5011 - accuracy: 0.7513\n",
            "Epoch 11/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.5007 - accuracy: 0.7514\n",
            "Epoch 12/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.5004 - accuracy: 0.7514\n",
            "Epoch 13/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4998 - accuracy: 0.7518\n",
            "Epoch 14/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4994 - accuracy: 0.7521\n",
            "Epoch 15/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4983 - accuracy: 0.7530\n",
            "Epoch 16/100\n",
            "11250/11250 [==============================] - 44s 4ms/step - loss: 0.4984 - accuracy: 0.7531\n",
            "Epoch 17/100\n",
            "11250/11250 [==============================] - 44s 4ms/step - loss: 0.4981 - accuracy: 0.7533\n",
            "Epoch 18/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4975 - accuracy: 0.7541\n",
            "Epoch 19/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4980 - accuracy: 0.7531\n",
            "Epoch 20/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4969 - accuracy: 0.7545\n",
            "Epoch 21/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4963 - accuracy: 0.7546\n",
            "Epoch 22/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4957 - accuracy: 0.7551\n",
            "Epoch 23/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4950 - accuracy: 0.7553\n",
            "Epoch 24/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4946 - accuracy: 0.7558\n",
            "Epoch 25/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4945 - accuracy: 0.7555\n",
            "Epoch 26/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4947 - accuracy: 0.7555\n",
            "Epoch 27/100\n",
            "11250/11250 [==============================] - 44s 4ms/step - loss: 0.4942 - accuracy: 0.7560\n",
            "Epoch 28/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4944 - accuracy: 0.7555\n",
            "Epoch 29/100\n",
            "11250/11250 [==============================] - 41s 4ms/step - loss: 0.4936 - accuracy: 0.7563\n",
            "Epoch 30/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4930 - accuracy: 0.7567\n",
            "Epoch 31/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4926 - accuracy: 0.7569\n",
            "Epoch 32/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4927 - accuracy: 0.7567\n",
            "Epoch 33/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4923 - accuracy: 0.7570\n",
            "Epoch 34/100\n",
            "11250/11250 [==============================] - 41s 4ms/step - loss: 0.4917 - accuracy: 0.7573\n",
            "Epoch 35/100\n",
            "11250/11250 [==============================] - 40s 4ms/step - loss: 0.4914 - accuracy: 0.7579\n",
            "Epoch 36/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4918 - accuracy: 0.7572\n",
            "Epoch 37/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4910 - accuracy: 0.7587\n",
            "Epoch 38/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4906 - accuracy: 0.7580\n",
            "Epoch 39/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4906 - accuracy: 0.7585\n",
            "Epoch 40/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4906 - accuracy: 0.7582\n",
            "Epoch 41/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4896 - accuracy: 0.7585\n",
            "Epoch 42/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4894 - accuracy: 0.7589\n",
            "Epoch 43/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4888 - accuracy: 0.7590\n",
            "Epoch 44/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4890 - accuracy: 0.7591\n",
            "Epoch 45/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4894 - accuracy: 0.7588\n",
            "Epoch 46/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4890 - accuracy: 0.7593\n",
            "Epoch 47/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4886 - accuracy: 0.7597\n",
            "Epoch 48/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4882 - accuracy: 0.7595\n",
            "Epoch 49/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4882 - accuracy: 0.7594\n",
            "Epoch 50/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4880 - accuracy: 0.7603\n",
            "Epoch 51/100\n",
            "11250/11250 [==============================] - 41s 4ms/step - loss: 0.4879 - accuracy: 0.7605\n",
            "Epoch 52/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4873 - accuracy: 0.7600\n",
            "Epoch 53/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4879 - accuracy: 0.7601\n",
            "Epoch 54/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4875 - accuracy: 0.7604\n",
            "Epoch 55/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4870 - accuracy: 0.7599\n",
            "Epoch 56/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4869 - accuracy: 0.7609\n",
            "Epoch 57/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4863 - accuracy: 0.7606\n",
            "Epoch 58/100\n",
            "11250/11250 [==============================] - 41s 4ms/step - loss: 0.4855 - accuracy: 0.7614\n",
            "Epoch 59/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4856 - accuracy: 0.7618\n",
            "Epoch 60/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4855 - accuracy: 0.7618\n",
            "Epoch 61/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4852 - accuracy: 0.7609\n",
            "Epoch 62/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4856 - accuracy: 0.7614\n",
            "Epoch 63/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4848 - accuracy: 0.7620\n",
            "Epoch 64/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4850 - accuracy: 0.7622\n",
            "Epoch 65/100\n",
            "11250/11250 [==============================] - 41s 4ms/step - loss: 0.4845 - accuracy: 0.7628\n",
            "Epoch 66/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4853 - accuracy: 0.7620\n",
            "Epoch 67/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4846 - accuracy: 0.7619\n",
            "Epoch 68/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4842 - accuracy: 0.7626\n",
            "Epoch 69/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4832 - accuracy: 0.7631\n",
            "Epoch 70/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4835 - accuracy: 0.7629\n",
            "Epoch 71/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4839 - accuracy: 0.7632\n",
            "Epoch 72/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4836 - accuracy: 0.7633\n",
            "Epoch 73/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4829 - accuracy: 0.7631\n",
            "Epoch 74/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4829 - accuracy: 0.7633\n",
            "Epoch 75/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4827 - accuracy: 0.7634\n",
            "Epoch 76/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4826 - accuracy: 0.7625\n",
            "Epoch 77/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4826 - accuracy: 0.7635\n",
            "Epoch 78/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4821 - accuracy: 0.7631\n",
            "Epoch 79/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4830 - accuracy: 0.7628\n",
            "Epoch 80/100\n",
            "11250/11250 [==============================] - 44s 4ms/step - loss: 0.4821 - accuracy: 0.7634\n",
            "Epoch 81/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4820 - accuracy: 0.7639\n",
            "Epoch 82/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4817 - accuracy: 0.7643\n",
            "Epoch 83/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4819 - accuracy: 0.7645\n",
            "Epoch 84/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4814 - accuracy: 0.7639\n",
            "Epoch 85/100\n",
            "11250/11250 [==============================] - 42s 4ms/step - loss: 0.4816 - accuracy: 0.7637\n",
            "Epoch 86/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4807 - accuracy: 0.7647\n",
            "Epoch 87/100\n",
            "11250/11250 [==============================] - 44s 4ms/step - loss: 0.4812 - accuracy: 0.7645\n",
            "Epoch 88/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4809 - accuracy: 0.7649\n",
            "Epoch 89/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4814 - accuracy: 0.7650\n",
            "Epoch 90/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4803 - accuracy: 0.7646\n",
            "Epoch 91/100\n",
            "11250/11250 [==============================] - 44s 4ms/step - loss: 0.4810 - accuracy: 0.7640\n",
            "Epoch 92/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4802 - accuracy: 0.7657\n",
            "Epoch 93/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4801 - accuracy: 0.7655\n",
            "Epoch 94/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4801 - accuracy: 0.7659\n",
            "Epoch 95/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4800 - accuracy: 0.7652\n",
            "Epoch 96/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4801 - accuracy: 0.7656\n",
            "Epoch 97/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4798 - accuracy: 0.7659\n",
            "Epoch 98/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4798 - accuracy: 0.7661\n",
            "Epoch 99/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4790 - accuracy: 0.7654\n",
            "Epoch 100/100\n",
            "11250/11250 [==============================] - 43s 4ms/step - loss: 0.4789 - accuracy: 0.7660\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faa97e7b2e0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Normalize the input data\n",
        "scaler = StandardScaler()\n",
        "train_features = scaler.fit_transform(train_features)\n",
        "val_features = scaler.transform(val_features)\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_dim=28, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_features, train_labels, epochs=100, batch_size=32, validation_data=(val_features, val_labels))\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_features, test_labels)\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZndfAzeYaxCR",
        "outputId": "2e04548e-60b4-4241-f5d2-a63a7a02eff7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "11250/11250 [==============================] - 34s 3ms/step - loss: 0.5795 - accuracy: 0.6982 - val_loss: 0.5451 - val_accuracy: 0.7204\n",
            "Epoch 2/100\n",
            "11250/11250 [==============================] - 39s 3ms/step - loss: 0.5401 - accuracy: 0.7250 - val_loss: 0.5324 - val_accuracy: 0.7304\n",
            "Epoch 3/100\n",
            "11250/11250 [==============================] - 34s 3ms/step - loss: 0.5283 - accuracy: 0.7331 - val_loss: 0.5281 - val_accuracy: 0.7349\n",
            "Epoch 4/100\n",
            "11250/11250 [==============================] - 38s 3ms/step - loss: 0.5212 - accuracy: 0.7372 - val_loss: 0.5221 - val_accuracy: 0.7367\n",
            "Epoch 5/100\n",
            "11250/11250 [==============================] - 32s 3ms/step - loss: 0.5154 - accuracy: 0.7409 - val_loss: 0.5166 - val_accuracy: 0.7391\n",
            "Epoch 6/100\n",
            "11250/11250 [==============================] - 34s 3ms/step - loss: 0.5112 - accuracy: 0.7437 - val_loss: 0.5120 - val_accuracy: 0.7424\n",
            "Epoch 7/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.5075 - accuracy: 0.7459 - val_loss: 0.5103 - val_accuracy: 0.7440\n",
            "Epoch 8/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.5047 - accuracy: 0.7479 - val_loss: 0.5109 - val_accuracy: 0.7445\n",
            "Epoch 9/100\n",
            "11250/11250 [==============================] - 39s 3ms/step - loss: 0.5022 - accuracy: 0.7491 - val_loss: 0.5113 - val_accuracy: 0.7427\n",
            "Epoch 10/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.4995 - accuracy: 0.7507 - val_loss: 0.5076 - val_accuracy: 0.7454\n",
            "Epoch 11/100\n",
            "11250/11250 [==============================] - 39s 3ms/step - loss: 0.4971 - accuracy: 0.7526 - val_loss: 0.5090 - val_accuracy: 0.7448\n",
            "Epoch 12/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.4952 - accuracy: 0.7538 - val_loss: 0.5073 - val_accuracy: 0.7447\n",
            "Epoch 13/100\n",
            "11250/11250 [==============================] - 39s 3ms/step - loss: 0.4935 - accuracy: 0.7553 - val_loss: 0.5053 - val_accuracy: 0.7465\n",
            "Epoch 14/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.4917 - accuracy: 0.7562 - val_loss: 0.5091 - val_accuracy: 0.7451\n",
            "Epoch 15/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.4896 - accuracy: 0.7578 - val_loss: 0.5061 - val_accuracy: 0.7452\n",
            "Epoch 16/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.4881 - accuracy: 0.7590 - val_loss: 0.5068 - val_accuracy: 0.7464\n",
            "Epoch 17/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.4864 - accuracy: 0.7592 - val_loss: 0.5071 - val_accuracy: 0.7457\n",
            "Epoch 18/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.4852 - accuracy: 0.7607 - val_loss: 0.5049 - val_accuracy: 0.7473\n",
            "Epoch 19/100\n",
            "11250/11250 [==============================] - 38s 3ms/step - loss: 0.4836 - accuracy: 0.7613 - val_loss: 0.5108 - val_accuracy: 0.7449\n",
            "Epoch 20/100\n",
            "11250/11250 [==============================] - 34s 3ms/step - loss: 0.4821 - accuracy: 0.7622 - val_loss: 0.5071 - val_accuracy: 0.7460\n",
            "Epoch 21/100\n",
            "11250/11250 [==============================] - 38s 3ms/step - loss: 0.4810 - accuracy: 0.7634 - val_loss: 0.5087 - val_accuracy: 0.7466\n",
            "Epoch 22/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.4800 - accuracy: 0.7635 - val_loss: 0.5100 - val_accuracy: 0.7450\n",
            "Epoch 23/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.4786 - accuracy: 0.7648 - val_loss: 0.5059 - val_accuracy: 0.7468\n",
            "Epoch 24/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.4772 - accuracy: 0.7652 - val_loss: 0.5100 - val_accuracy: 0.7452\n",
            "Epoch 25/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.4766 - accuracy: 0.7659 - val_loss: 0.5065 - val_accuracy: 0.7467\n",
            "Epoch 26/100\n",
            "11250/11250 [==============================] - 38s 3ms/step - loss: 0.4755 - accuracy: 0.7660 - val_loss: 0.5086 - val_accuracy: 0.7450\n",
            "Epoch 27/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.4746 - accuracy: 0.7670 - val_loss: 0.5112 - val_accuracy: 0.7448\n",
            "Epoch 28/100\n",
            "11250/11250 [==============================] - 38s 3ms/step - loss: 0.4736 - accuracy: 0.7685 - val_loss: 0.5091 - val_accuracy: 0.7456\n",
            "Epoch 29/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.4722 - accuracy: 0.7691 - val_loss: 0.5104 - val_accuracy: 0.7441\n",
            "Epoch 30/100\n",
            "11250/11250 [==============================] - 38s 3ms/step - loss: 0.4715 - accuracy: 0.7691 - val_loss: 0.5083 - val_accuracy: 0.7452\n",
            "Epoch 31/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.4702 - accuracy: 0.7699 - val_loss: 0.5116 - val_accuracy: 0.7446\n",
            "Epoch 32/100\n",
            "11250/11250 [==============================] - 34s 3ms/step - loss: 0.4701 - accuracy: 0.7701 - val_loss: 0.5122 - val_accuracy: 0.7451\n",
            "Epoch 33/100\n",
            "11250/11250 [==============================] - 32s 3ms/step - loss: 0.4688 - accuracy: 0.7710 - val_loss: 0.5084 - val_accuracy: 0.7443\n",
            "Epoch 34/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.4681 - accuracy: 0.7717 - val_loss: 0.5085 - val_accuracy: 0.7438\n",
            "Epoch 35/100\n",
            "11250/11250 [==============================] - 34s 3ms/step - loss: 0.4673 - accuracy: 0.7719 - val_loss: 0.5104 - val_accuracy: 0.7452\n",
            "Epoch 36/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.4663 - accuracy: 0.7724 - val_loss: 0.5105 - val_accuracy: 0.7449\n",
            "Epoch 37/100\n",
            "11250/11250 [==============================] - 34s 3ms/step - loss: 0.4657 - accuracy: 0.7732 - val_loss: 0.5107 - val_accuracy: 0.7442\n",
            "Epoch 38/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.4648 - accuracy: 0.7731 - val_loss: 0.5142 - val_accuracy: 0.7444\n",
            "Epoch 39/100\n",
            "11250/11250 [==============================] - 39s 3ms/step - loss: 0.4643 - accuracy: 0.7742 - val_loss: 0.5121 - val_accuracy: 0.7451\n",
            "Epoch 40/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.4637 - accuracy: 0.7744 - val_loss: 0.5131 - val_accuracy: 0.7449\n",
            "Epoch 41/100\n",
            "11250/11250 [==============================] - 37s 3ms/step - loss: 0.4630 - accuracy: 0.7747 - val_loss: 0.5118 - val_accuracy: 0.7441\n",
            "Epoch 42/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.4620 - accuracy: 0.7757 - val_loss: 0.5148 - val_accuracy: 0.7447\n",
            "Epoch 43/100\n",
            "11250/11250 [==============================] - 32s 3ms/step - loss: 0.4614 - accuracy: 0.7759 - val_loss: 0.5102 - val_accuracy: 0.7437\n",
            "Epoch 44/100\n",
            "11250/11250 [==============================] - 31s 3ms/step - loss: 0.4607 - accuracy: 0.7758 - val_loss: 0.5132 - val_accuracy: 0.7428\n",
            "Epoch 45/100\n",
            "11250/11250 [==============================] - 32s 3ms/step - loss: 0.4603 - accuracy: 0.7763 - val_loss: 0.5117 - val_accuracy: 0.7447\n",
            "Epoch 46/100\n",
            "11250/11250 [==============================] - 32s 3ms/step - loss: 0.4598 - accuracy: 0.7764 - val_loss: 0.5137 - val_accuracy: 0.7439\n",
            "Epoch 47/100\n",
            "11250/11250 [==============================] - 32s 3ms/step - loss: 0.4595 - accuracy: 0.7766 - val_loss: 0.5141 - val_accuracy: 0.7435\n",
            "Epoch 48/100\n",
            "11250/11250 [==============================] - 32s 3ms/step - loss: 0.4589 - accuracy: 0.7775 - val_loss: 0.5125 - val_accuracy: 0.7435\n",
            "Epoch 49/100\n",
            "11250/11250 [==============================] - 32s 3ms/step - loss: 0.4575 - accuracy: 0.7780 - val_loss: 0.5160 - val_accuracy: 0.7429\n",
            "Epoch 50/100\n",
            "11250/11250 [==============================] - 32s 3ms/step - loss: 0.4575 - accuracy: 0.7782 - val_loss: 0.5130 - val_accuracy: 0.7433\n",
            "Epoch 51/100\n",
            "11250/11250 [==============================] - 31s 3ms/step - loss: 0.4568 - accuracy: 0.7784 - val_loss: 0.5127 - val_accuracy: 0.7419\n",
            "Epoch 52/100\n",
            "11250/11250 [==============================] - 31s 3ms/step - loss: 0.4562 - accuracy: 0.7781 - val_loss: 0.5185 - val_accuracy: 0.7424\n",
            "Epoch 53/100\n",
            "11250/11250 [==============================] - 32s 3ms/step - loss: 0.4560 - accuracy: 0.7797 - val_loss: 0.5167 - val_accuracy: 0.7420\n",
            "Epoch 54/100\n",
            "11250/11250 [==============================] - 32s 3ms/step - loss: 0.4552 - accuracy: 0.7795 - val_loss: 0.5214 - val_accuracy: 0.7421\n",
            "Epoch 55/100\n",
            "11250/11250 [==============================] - 32s 3ms/step - loss: 0.4549 - accuracy: 0.7796 - val_loss: 0.5171 - val_accuracy: 0.7415\n",
            "Epoch 56/100\n",
            "11250/11250 [==============================] - 32s 3ms/step - loss: 0.4545 - accuracy: 0.7799 - val_loss: 0.5178 - val_accuracy: 0.7411\n",
            "Epoch 57/100\n",
            "11250/11250 [==============================] - 31s 3ms/step - loss: 0.4538 - accuracy: 0.7810 - val_loss: 0.5173 - val_accuracy: 0.7420\n",
            "Epoch 58/100\n",
            "11250/11250 [==============================] - 32s 3ms/step - loss: 0.4533 - accuracy: 0.7807 - val_loss: 0.5198 - val_accuracy: 0.7429\n",
            "Epoch 59/100\n",
            "11250/11250 [==============================] - 32s 3ms/step - loss: 0.4530 - accuracy: 0.7808 - val_loss: 0.5139 - val_accuracy: 0.7425\n",
            "Epoch 60/100\n",
            "11250/11250 [==============================] - 31s 3ms/step - loss: 0.4523 - accuracy: 0.7812 - val_loss: 0.5161 - val_accuracy: 0.7410\n",
            "Epoch 61/100\n",
            "11250/11250 [==============================] - 37s 3ms/step - loss: 0.4522 - accuracy: 0.7815 - val_loss: 0.5218 - val_accuracy: 0.7405\n",
            "Epoch 62/100\n",
            "11250/11250 [==============================] - 31s 3ms/step - loss: 0.4517 - accuracy: 0.7812 - val_loss: 0.5253 - val_accuracy: 0.7399\n",
            "Epoch 63/100\n",
            "11250/11250 [==============================] - 32s 3ms/step - loss: 0.4509 - accuracy: 0.7823 - val_loss: 0.5219 - val_accuracy: 0.7430\n",
            "Epoch 64/100\n",
            "11250/11250 [==============================] - 32s 3ms/step - loss: 0.4502 - accuracy: 0.7830 - val_loss: 0.5159 - val_accuracy: 0.7430\n",
            "Epoch 65/100\n",
            "11250/11250 [==============================] - 31s 3ms/step - loss: 0.4497 - accuracy: 0.7828 - val_loss: 0.5230 - val_accuracy: 0.7421\n",
            "Epoch 66/100\n",
            "11250/11250 [==============================] - 32s 3ms/step - loss: 0.4498 - accuracy: 0.7833 - val_loss: 0.5236 - val_accuracy: 0.7418\n",
            "Epoch 67/100\n",
            "11250/11250 [==============================] - 32s 3ms/step - loss: 0.4495 - accuracy: 0.7835 - val_loss: 0.5209 - val_accuracy: 0.7411\n",
            "Epoch 68/100\n",
            "11250/11250 [==============================] - 32s 3ms/step - loss: 0.4489 - accuracy: 0.7836 - val_loss: 0.5197 - val_accuracy: 0.7400\n",
            "Epoch 69/100\n",
            "11250/11250 [==============================] - 32s 3ms/step - loss: 0.4484 - accuracy: 0.7841 - val_loss: 0.5239 - val_accuracy: 0.7402\n",
            "Epoch 70/100\n",
            "11250/11250 [==============================] - 32s 3ms/step - loss: 0.4482 - accuracy: 0.7838 - val_loss: 0.5232 - val_accuracy: 0.7415\n",
            "Epoch 71/100\n",
            "11250/11250 [==============================] - 32s 3ms/step - loss: 0.4476 - accuracy: 0.7848 - val_loss: 0.5198 - val_accuracy: 0.7412\n",
            "Epoch 72/100\n",
            "11250/11250 [==============================] - 32s 3ms/step - loss: 0.4470 - accuracy: 0.7845 - val_loss: 0.5218 - val_accuracy: 0.7400\n",
            "Epoch 73/100\n",
            "11250/11250 [==============================] - 32s 3ms/step - loss: 0.4466 - accuracy: 0.7853 - val_loss: 0.5174 - val_accuracy: 0.7417\n",
            "Epoch 74/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.4465 - accuracy: 0.7849 - val_loss: 0.5250 - val_accuracy: 0.7395\n",
            "Epoch 75/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.4466 - accuracy: 0.7847 - val_loss: 0.5223 - val_accuracy: 0.7389\n",
            "Epoch 76/100\n",
            "11250/11250 [==============================] - 34s 3ms/step - loss: 0.4461 - accuracy: 0.7853 - val_loss: 0.5207 - val_accuracy: 0.7398\n",
            "Epoch 77/100\n",
            "11250/11250 [==============================] - 34s 3ms/step - loss: 0.4455 - accuracy: 0.7856 - val_loss: 0.5258 - val_accuracy: 0.7391\n",
            "Epoch 78/100\n",
            "11250/11250 [==============================] - 39s 3ms/step - loss: 0.4458 - accuracy: 0.7849 - val_loss: 0.5274 - val_accuracy: 0.7415\n",
            "Epoch 79/100\n",
            "11250/11250 [==============================] - 34s 3ms/step - loss: 0.4451 - accuracy: 0.7863 - val_loss: 0.5294 - val_accuracy: 0.7406\n",
            "Epoch 80/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.4442 - accuracy: 0.7873 - val_loss: 0.5324 - val_accuracy: 0.7390\n",
            "Epoch 81/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.4444 - accuracy: 0.7859 - val_loss: 0.5236 - val_accuracy: 0.7392\n",
            "Epoch 82/100\n",
            "11250/11250 [==============================] - 34s 3ms/step - loss: 0.4443 - accuracy: 0.7865 - val_loss: 0.5282 - val_accuracy: 0.7393\n",
            "Epoch 83/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.4435 - accuracy: 0.7864 - val_loss: 0.5295 - val_accuracy: 0.7386\n",
            "Epoch 84/100\n",
            "11250/11250 [==============================] - 39s 3ms/step - loss: 0.4439 - accuracy: 0.7866 - val_loss: 0.5257 - val_accuracy: 0.7404\n",
            "Epoch 85/100\n",
            "11250/11250 [==============================] - 34s 3ms/step - loss: 0.4433 - accuracy: 0.7873 - val_loss: 0.5292 - val_accuracy: 0.7382\n",
            "Epoch 86/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.4420 - accuracy: 0.7877 - val_loss: 0.5291 - val_accuracy: 0.7390\n",
            "Epoch 87/100\n",
            "11250/11250 [==============================] - 34s 3ms/step - loss: 0.4417 - accuracy: 0.7885 - val_loss: 0.5292 - val_accuracy: 0.7381\n",
            "Epoch 88/100\n",
            "11250/11250 [==============================] - 34s 3ms/step - loss: 0.4418 - accuracy: 0.7884 - val_loss: 0.5277 - val_accuracy: 0.7382\n",
            "Epoch 89/100\n",
            "11250/11250 [==============================] - 34s 3ms/step - loss: 0.4417 - accuracy: 0.7881 - val_loss: 0.5265 - val_accuracy: 0.7390\n",
            "Epoch 90/100\n",
            "11250/11250 [==============================] - 34s 3ms/step - loss: 0.4413 - accuracy: 0.7880 - val_loss: 0.5260 - val_accuracy: 0.7382\n",
            "Epoch 91/100\n",
            "11250/11250 [==============================] - 34s 3ms/step - loss: 0.4409 - accuracy: 0.7885 - val_loss: 0.5264 - val_accuracy: 0.7372\n",
            "Epoch 92/100\n",
            "11250/11250 [==============================] - 34s 3ms/step - loss: 0.4411 - accuracy: 0.7889 - val_loss: 0.5272 - val_accuracy: 0.7385\n",
            "Epoch 93/100\n",
            "11250/11250 [==============================] - 34s 3ms/step - loss: 0.4406 - accuracy: 0.7893 - val_loss: 0.5284 - val_accuracy: 0.7395\n",
            "Epoch 94/100\n",
            "11250/11250 [==============================] - 34s 3ms/step - loss: 0.4405 - accuracy: 0.7887 - val_loss: 0.5285 - val_accuracy: 0.7368\n",
            "Epoch 95/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.4400 - accuracy: 0.7890 - val_loss: 0.5269 - val_accuracy: 0.7387\n",
            "Epoch 96/100\n",
            "11250/11250 [==============================] - 34s 3ms/step - loss: 0.4394 - accuracy: 0.7895 - val_loss: 0.5311 - val_accuracy: 0.7388\n",
            "Epoch 97/100\n",
            "11250/11250 [==============================] - 33s 3ms/step - loss: 0.4388 - accuracy: 0.7893 - val_loss: 0.5300 - val_accuracy: 0.7389\n",
            "Epoch 98/100\n",
            "11250/11250 [==============================] - 34s 3ms/step - loss: 0.4391 - accuracy: 0.7898 - val_loss: 0.5309 - val_accuracy: 0.7391\n",
            "Epoch 99/100\n",
            "11250/11250 [==============================] - 34s 3ms/step - loss: 0.4390 - accuracy: 0.7896 - val_loss: 0.5357 - val_accuracy: 0.7377\n",
            "Epoch 100/100\n",
            "11250/11250 [==============================] - 34s 3ms/step - loss: 0.4385 - accuracy: 0.7901 - val_loss: 0.5334 - val_accuracy: 0.7369\n",
            "3750/3750 [==============================] - 7s 2ms/step - loss: 0.5272 - accuracy: 0.7423\n",
            "Test loss: 0.5272\n",
            "Test accuracy: 0.7423\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, we have used the StandardScaler from the scikit-learn library to normalize the input data. We have added more hidden layers and increased the number of neurons in the hidden layers. We have also added a dropout layer and an L2 regularization to prevent overfitting. Finally, we have monitored the performance of the model on the validation set."
      ],
      "metadata": {
        "id": "_KxmenQPbgUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Normalize the input data\n",
        "scaler = StandardScaler()\n",
        "train_features = scaler.fit_transform(train_features)\n",
        "val_features = scaler.transform(val_features)\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_dim=28, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Early stopping callback\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_features, train_labels, epochs=50, batch_size=64, validation_data=(val_features, val_labels), callbacks=[es])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_features, test_labels)\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V8Q8wOAyl60",
        "outputId": "fd3a59ee-df61-48a1-d72e-4ddf058fba35"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "5625/5625 [==============================] - 80s 14ms/step - loss: 0.6057 - accuracy: 0.6847 - val_loss: 0.5479 - val_accuracy: 0.7203\n",
            "Epoch 2/50\n",
            "5625/5625 [==============================] - 76s 13ms/step - loss: 0.5559 - accuracy: 0.7135 - val_loss: 0.5347 - val_accuracy: 0.7277\n",
            "Epoch 3/50\n",
            "5625/5625 [==============================] - 77s 14ms/step - loss: 0.5455 - accuracy: 0.7202 - val_loss: 0.5282 - val_accuracy: 0.7326\n",
            "Epoch 4/50\n",
            "5625/5625 [==============================] - 79s 14ms/step - loss: 0.5383 - accuracy: 0.7251 - val_loss: 0.5214 - val_accuracy: 0.7369\n",
            "Epoch 5/50\n",
            "5625/5625 [==============================] - 74s 13ms/step - loss: 0.5331 - accuracy: 0.7287 - val_loss: 0.5174 - val_accuracy: 0.7395\n",
            "Epoch 6/50\n",
            "5625/5625 [==============================] - 77s 14ms/step - loss: 0.5294 - accuracy: 0.7314 - val_loss: 0.5152 - val_accuracy: 0.7413\n",
            "Epoch 7/50\n",
            "5625/5625 [==============================] - 76s 13ms/step - loss: 0.5272 - accuracy: 0.7335 - val_loss: 0.5127 - val_accuracy: 0.7424\n",
            "Epoch 8/50\n",
            "5625/5625 [==============================] - 73s 13ms/step - loss: 0.5243 - accuracy: 0.7349 - val_loss: 0.5087 - val_accuracy: 0.7447\n",
            "Epoch 9/50\n",
            "5625/5625 [==============================] - 75s 13ms/step - loss: 0.5230 - accuracy: 0.7358 - val_loss: 0.5076 - val_accuracy: 0.7454\n",
            "Epoch 10/50\n",
            "5625/5625 [==============================] - 71s 13ms/step - loss: 0.5202 - accuracy: 0.7379 - val_loss: 0.5070 - val_accuracy: 0.7458\n",
            "Epoch 11/50\n",
            "5625/5625 [==============================] - 76s 13ms/step - loss: 0.5192 - accuracy: 0.7376 - val_loss: 0.5059 - val_accuracy: 0.7459\n",
            "Epoch 12/50\n",
            "5625/5625 [==============================] - 73s 13ms/step - loss: 0.5170 - accuracy: 0.7390 - val_loss: 0.5068 - val_accuracy: 0.7465\n",
            "Epoch 13/50\n",
            "5625/5625 [==============================] - 76s 13ms/step - loss: 0.5165 - accuracy: 0.7395 - val_loss: 0.5030 - val_accuracy: 0.7476\n",
            "Epoch 14/50\n",
            "5625/5625 [==============================] - 72s 13ms/step - loss: 0.5148 - accuracy: 0.7410 - val_loss: 0.5012 - val_accuracy: 0.7494\n",
            "Epoch 15/50\n",
            "5625/5625 [==============================] - 71s 13ms/step - loss: 0.5138 - accuracy: 0.7418 - val_loss: 0.5024 - val_accuracy: 0.7489\n",
            "Epoch 16/50\n",
            "5625/5625 [==============================] - 73s 13ms/step - loss: 0.5132 - accuracy: 0.7417 - val_loss: 0.5019 - val_accuracy: 0.7482\n",
            "Epoch 17/50\n",
            "5625/5625 [==============================] - 73s 13ms/step - loss: 0.5118 - accuracy: 0.7427 - val_loss: 0.5020 - val_accuracy: 0.7491\n",
            "Epoch 18/50\n",
            "5625/5625 [==============================] - 73s 13ms/step - loss: 0.5106 - accuracy: 0.7433 - val_loss: 0.5002 - val_accuracy: 0.7489\n",
            "Epoch 19/50\n",
            "5625/5625 [==============================] - 68s 12ms/step - loss: 0.5102 - accuracy: 0.7437 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
            "Epoch 20/50\n",
            "5625/5625 [==============================] - 68s 12ms/step - loss: 0.5100 - accuracy: 0.7438 - val_loss: 0.4990 - val_accuracy: 0.7505\n",
            "Epoch 21/50\n",
            "5625/5625 [==============================] - 68s 12ms/step - loss: 0.5085 - accuracy: 0.7452 - val_loss: 0.4994 - val_accuracy: 0.7500\n",
            "Epoch 22/50\n",
            "5625/5625 [==============================] - 68s 12ms/step - loss: 0.5077 - accuracy: 0.7455 - val_loss: 0.4984 - val_accuracy: 0.7500\n",
            "Epoch 23/50\n",
            "5625/5625 [==============================] - 72s 13ms/step - loss: 0.5068 - accuracy: 0.7462 - val_loss: 0.4991 - val_accuracy: 0.7520\n",
            "Epoch 24/50\n",
            "5625/5625 [==============================] - 68s 12ms/step - loss: 0.5068 - accuracy: 0.7459 - val_loss: 0.4972 - val_accuracy: 0.7527\n",
            "Epoch 25/50\n",
            "5625/5625 [==============================] - 68s 12ms/step - loss: 0.5058 - accuracy: 0.7469 - val_loss: 0.4970 - val_accuracy: 0.7523\n",
            "Epoch 26/50\n",
            "5625/5625 [==============================] - 68s 12ms/step - loss: 0.5056 - accuracy: 0.7472 - val_loss: 0.4978 - val_accuracy: 0.7523\n",
            "Epoch 27/50\n",
            "5625/5625 [==============================] - 69s 12ms/step - loss: 0.5050 - accuracy: 0.7477 - val_loss: 0.4976 - val_accuracy: 0.7536\n",
            "Epoch 28/50\n",
            "5625/5625 [==============================] - 71s 13ms/step - loss: 0.5041 - accuracy: 0.7482 - val_loss: 0.4979 - val_accuracy: 0.7531\n",
            "Epoch 29/50\n",
            "5625/5625 [==============================] - 71s 13ms/step - loss: 0.5043 - accuracy: 0.7480 - val_loss: 0.4962 - val_accuracy: 0.7528\n",
            "Epoch 30/50\n",
            "5625/5625 [==============================] - 72s 13ms/step - loss: 0.5030 - accuracy: 0.7494 - val_loss: 0.4963 - val_accuracy: 0.7535\n",
            "Epoch 31/50\n",
            "5625/5625 [==============================] - 72s 13ms/step - loss: 0.5026 - accuracy: 0.7488 - val_loss: 0.4968 - val_accuracy: 0.7528\n",
            "Epoch 32/50\n",
            "5625/5625 [==============================] - 71s 13ms/step - loss: 0.5022 - accuracy: 0.7486 - val_loss: 0.4962 - val_accuracy: 0.7527\n",
            "Epoch 33/50\n",
            "5625/5625 [==============================] - 71s 13ms/step - loss: 0.5017 - accuracy: 0.7496 - val_loss: 0.4959 - val_accuracy: 0.7531\n",
            "Epoch 34/50\n",
            "5625/5625 [==============================] - 71s 13ms/step - loss: 0.5016 - accuracy: 0.7496 - val_loss: 0.4943 - val_accuracy: 0.7538\n",
            "Epoch 35/50\n",
            "5625/5625 [==============================] - 70s 12ms/step - loss: 0.5012 - accuracy: 0.7490 - val_loss: 0.4952 - val_accuracy: 0.7539\n",
            "Epoch 36/50\n",
            "5625/5625 [==============================] - 74s 13ms/step - loss: 0.5004 - accuracy: 0.7498 - val_loss: 0.4956 - val_accuracy: 0.7531\n",
            "Epoch 37/50\n",
            "5625/5625 [==============================] - 70s 12ms/step - loss: 0.5003 - accuracy: 0.7506 - val_loss: 0.4956 - val_accuracy: 0.7529\n",
            "Epoch 38/50\n",
            "5625/5625 [==============================] - 71s 13ms/step - loss: 0.5005 - accuracy: 0.7506 - val_loss: 0.4956 - val_accuracy: 0.7534\n",
            "Epoch 39/50\n",
            "5625/5625 [==============================] - 72s 13ms/step - loss: 0.4993 - accuracy: 0.7512 - val_loss: 0.4942 - val_accuracy: 0.7546\n",
            "Epoch 40/50\n",
            "5625/5625 [==============================] - 72s 13ms/step - loss: 0.4994 - accuracy: 0.7512 - val_loss: 0.4954 - val_accuracy: 0.7536\n",
            "Epoch 41/50\n",
            "5625/5625 [==============================] - 77s 14ms/step - loss: 0.4986 - accuracy: 0.7515 - val_loss: 0.4943 - val_accuracy: 0.7541\n",
            "Epoch 42/50\n",
            "5625/5625 [==============================] - 72s 13ms/step - loss: 0.4981 - accuracy: 0.7517 - val_loss: 0.4943 - val_accuracy: 0.7551\n",
            "Epoch 43/50\n",
            "5625/5625 [==============================] - 71s 13ms/step - loss: 0.4981 - accuracy: 0.7518 - val_loss: 0.4939 - val_accuracy: 0.7549\n",
            "Epoch 44/50\n",
            "5625/5625 [==============================] - 72s 13ms/step - loss: 0.4985 - accuracy: 0.7517 - val_loss: 0.4933 - val_accuracy: 0.7548\n",
            "Epoch 45/50\n",
            "5625/5625 [==============================] - 71s 13ms/step - loss: 0.4973 - accuracy: 0.7528 - val_loss: 0.4931 - val_accuracy: 0.7549\n",
            "Epoch 46/50\n",
            "5625/5625 [==============================] - 70s 12ms/step - loss: 0.4967 - accuracy: 0.7524 - val_loss: 0.4930 - val_accuracy: 0.7552\n",
            "Epoch 47/50\n",
            "5625/5625 [==============================] - 68s 12ms/step - loss: 0.4961 - accuracy: 0.7532 - val_loss: 0.4930 - val_accuracy: 0.7550\n",
            "Epoch 48/50\n",
            "5625/5625 [==============================] - 67s 12ms/step - loss: 0.4963 - accuracy: 0.7536 - val_loss: 0.4930 - val_accuracy: 0.7550\n",
            "Epoch 49/50\n",
            "5625/5625 [==============================] - 71s 13ms/step - loss: 0.4957 - accuracy: 0.7537 - val_loss: 0.4924 - val_accuracy: 0.7558\n",
            "Epoch 50/50\n",
            "5625/5625 [==============================] - 71s 13ms/step - loss: 0.4964 - accuracy: 0.7533 - val_loss: 0.4932 - val_accuracy: 0.7558\n",
            "3750/3750 [==============================] - 13s 3ms/step - loss: 0.4878 - accuracy: 0.7592\n",
            "Test loss: 0.4878\n",
            "Test accuracy: 0.7592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Normalize the input data\n",
        "scaler = StandardScaler()\n",
        "train_features = scaler.fit_transform(train_features)\n",
        "val_features = scaler.transform(val_features)\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_dim=28, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Early stopping callback\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_features, train_labels, epochs=100, batch_size=64, validation_data=(val_features, val_labels), callbacks=[es])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_features, test_labels)\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eS7lP8UPB0e",
        "outputId": "e8219367-5a5e-4f54-8f03-c187a53c2e09"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "5625/5625 [==============================] - 77s 13ms/step - loss: 0.6111 - accuracy: 0.6823 - val_loss: 0.5515 - val_accuracy: 0.7176\n",
            "Epoch 2/100\n",
            "5625/5625 [==============================] - 67s 12ms/step - loss: 0.5566 - accuracy: 0.7132 - val_loss: 0.5375 - val_accuracy: 0.7270\n",
            "Epoch 3/100\n",
            "5625/5625 [==============================] - 65s 11ms/step - loss: 0.5463 - accuracy: 0.7199 - val_loss: 0.5331 - val_accuracy: 0.7303\n",
            "Epoch 4/100\n",
            "5625/5625 [==============================] - 65s 11ms/step - loss: 0.5393 - accuracy: 0.7246 - val_loss: 0.5249 - val_accuracy: 0.7349\n",
            "Epoch 5/100\n",
            "5625/5625 [==============================] - 65s 12ms/step - loss: 0.5343 - accuracy: 0.7278 - val_loss: 0.5206 - val_accuracy: 0.7388\n",
            "Epoch 6/100\n",
            "5625/5625 [==============================] - 65s 12ms/step - loss: 0.5305 - accuracy: 0.7310 - val_loss: 0.5160 - val_accuracy: 0.7401\n",
            "Epoch 7/100\n",
            "5625/5625 [==============================] - 64s 11ms/step - loss: 0.5270 - accuracy: 0.7330 - val_loss: 0.5125 - val_accuracy: 0.7419\n",
            "Epoch 8/100\n",
            "5625/5625 [==============================] - 65s 11ms/step - loss: 0.5251 - accuracy: 0.7339 - val_loss: 0.5124 - val_accuracy: 0.7422\n",
            "Epoch 9/100\n",
            "5625/5625 [==============================] - 66s 12ms/step - loss: 0.5230 - accuracy: 0.7356 - val_loss: 0.5098 - val_accuracy: 0.7444\n",
            "Epoch 10/100\n",
            "5625/5625 [==============================] - 65s 12ms/step - loss: 0.5209 - accuracy: 0.7364 - val_loss: 0.5068 - val_accuracy: 0.7454\n",
            "Epoch 11/100\n",
            "5625/5625 [==============================] - 70s 12ms/step - loss: 0.5190 - accuracy: 0.7379 - val_loss: 0.5086 - val_accuracy: 0.7455\n",
            "Epoch 12/100\n",
            "5625/5625 [==============================] - 69s 12ms/step - loss: 0.5178 - accuracy: 0.7389 - val_loss: 0.5064 - val_accuracy: 0.7457\n",
            "Epoch 13/100\n",
            "5625/5625 [==============================] - 69s 12ms/step - loss: 0.5159 - accuracy: 0.7401 - val_loss: 0.5043 - val_accuracy: 0.7473\n",
            "Epoch 14/100\n",
            "5625/5625 [==============================] - 65s 12ms/step - loss: 0.5159 - accuracy: 0.7400 - val_loss: 0.5036 - val_accuracy: 0.7483\n",
            "Epoch 15/100\n",
            "5625/5625 [==============================] - 69s 12ms/step - loss: 0.5143 - accuracy: 0.7417 - val_loss: 0.5019 - val_accuracy: 0.7485\n",
            "Epoch 16/100\n",
            "5625/5625 [==============================] - 69s 12ms/step - loss: 0.5132 - accuracy: 0.7423 - val_loss: 0.5041 - val_accuracy: 0.7469\n",
            "Epoch 17/100\n",
            "5625/5625 [==============================] - 69s 12ms/step - loss: 0.5124 - accuracy: 0.7425 - val_loss: 0.5014 - val_accuracy: 0.7489\n",
            "Epoch 18/100\n",
            "5625/5625 [==============================] - 70s 12ms/step - loss: 0.5109 - accuracy: 0.7428 - val_loss: 0.5011 - val_accuracy: 0.7505\n",
            "Epoch 19/100\n",
            "5625/5625 [==============================] - 66s 12ms/step - loss: 0.5100 - accuracy: 0.7440 - val_loss: 0.5007 - val_accuracy: 0.7505\n",
            "Epoch 20/100\n",
            "5625/5625 [==============================] - 70s 12ms/step - loss: 0.5093 - accuracy: 0.7444 - val_loss: 0.4994 - val_accuracy: 0.7511\n",
            "Epoch 21/100\n",
            "5625/5625 [==============================] - 66s 12ms/step - loss: 0.5086 - accuracy: 0.7448 - val_loss: 0.4989 - val_accuracy: 0.7503\n",
            "Epoch 22/100\n",
            "5625/5625 [==============================] - 65s 12ms/step - loss: 0.5081 - accuracy: 0.7447 - val_loss: 0.4991 - val_accuracy: 0.7503\n",
            "Epoch 23/100\n",
            "5625/5625 [==============================] - 69s 12ms/step - loss: 0.5072 - accuracy: 0.7455 - val_loss: 0.4984 - val_accuracy: 0.7507\n",
            "Epoch 24/100\n",
            "5625/5625 [==============================] - 65s 12ms/step - loss: 0.5071 - accuracy: 0.7464 - val_loss: 0.4988 - val_accuracy: 0.7505\n",
            "Epoch 25/100\n",
            "5625/5625 [==============================] - 64s 11ms/step - loss: 0.5066 - accuracy: 0.7471 - val_loss: 0.4978 - val_accuracy: 0.7511\n",
            "Epoch 26/100\n",
            "5625/5625 [==============================] - 64s 11ms/step - loss: 0.5054 - accuracy: 0.7470 - val_loss: 0.4971 - val_accuracy: 0.7520\n",
            "Epoch 27/100\n",
            "5625/5625 [==============================] - 70s 12ms/step - loss: 0.5048 - accuracy: 0.7480 - val_loss: 0.4965 - val_accuracy: 0.7528\n",
            "Epoch 28/100\n",
            "5625/5625 [==============================] - 65s 12ms/step - loss: 0.5044 - accuracy: 0.7478 - val_loss: 0.4983 - val_accuracy: 0.7518\n",
            "Epoch 29/100\n",
            "5625/5625 [==============================] - 70s 12ms/step - loss: 0.5031 - accuracy: 0.7485 - val_loss: 0.4962 - val_accuracy: 0.7529\n",
            "Epoch 30/100\n",
            "5625/5625 [==============================] - 67s 12ms/step - loss: 0.5037 - accuracy: 0.7489 - val_loss: 0.4966 - val_accuracy: 0.7533\n",
            "Epoch 31/100\n",
            "5625/5625 [==============================] - 65s 12ms/step - loss: 0.5029 - accuracy: 0.7487 - val_loss: 0.4956 - val_accuracy: 0.7527\n",
            "Epoch 32/100\n",
            "5625/5625 [==============================] - 66s 12ms/step - loss: 0.5026 - accuracy: 0.7492 - val_loss: 0.4953 - val_accuracy: 0.7540\n",
            "Epoch 33/100\n",
            "5625/5625 [==============================] - 65s 12ms/step - loss: 0.5018 - accuracy: 0.7493 - val_loss: 0.4954 - val_accuracy: 0.7527\n",
            "Epoch 34/100\n",
            "5625/5625 [==============================] - 66s 12ms/step - loss: 0.5014 - accuracy: 0.7495 - val_loss: 0.4956 - val_accuracy: 0.7533\n",
            "Epoch 35/100\n",
            "5625/5625 [==============================] - 66s 12ms/step - loss: 0.5009 - accuracy: 0.7497 - val_loss: 0.4953 - val_accuracy: 0.7522\n",
            "Epoch 36/100\n",
            "5625/5625 [==============================] - 71s 13ms/step - loss: 0.5010 - accuracy: 0.7498 - val_loss: 0.4954 - val_accuracy: 0.7530\n",
            "Epoch 37/100\n",
            "5625/5625 [==============================] - 67s 12ms/step - loss: 0.5005 - accuracy: 0.7502 - val_loss: 0.4940 - val_accuracy: 0.7538\n",
            "Epoch 38/100\n",
            "5625/5625 [==============================] - 67s 12ms/step - loss: 0.4995 - accuracy: 0.7513 - val_loss: 0.4943 - val_accuracy: 0.7535\n",
            "Epoch 39/100\n",
            "5625/5625 [==============================] - 72s 13ms/step - loss: 0.4995 - accuracy: 0.7508 - val_loss: 0.4936 - val_accuracy: 0.7539\n",
            "Epoch 40/100\n",
            "5625/5625 [==============================] - 66s 12ms/step - loss: 0.4985 - accuracy: 0.7513 - val_loss: 0.4941 - val_accuracy: 0.7535\n",
            "Epoch 41/100\n",
            "5625/5625 [==============================] - 70s 13ms/step - loss: 0.4991 - accuracy: 0.7510 - val_loss: 0.4936 - val_accuracy: 0.7546\n",
            "Epoch 42/100\n",
            "5625/5625 [==============================] - 67s 12ms/step - loss: 0.4981 - accuracy: 0.7521 - val_loss: 0.4951 - val_accuracy: 0.7521\n",
            "Epoch 43/100\n",
            "5625/5625 [==============================] - 70s 12ms/step - loss: 0.4976 - accuracy: 0.7520 - val_loss: 0.4946 - val_accuracy: 0.7531\n",
            "Epoch 44/100\n",
            "5625/5625 [==============================] - 67s 12ms/step - loss: 0.4974 - accuracy: 0.7526 - val_loss: 0.4935 - val_accuracy: 0.7549\n",
            "Epoch 45/100\n",
            "5625/5625 [==============================] - 70s 12ms/step - loss: 0.4978 - accuracy: 0.7522 - val_loss: 0.4944 - val_accuracy: 0.7549\n",
            "Epoch 46/100\n",
            "5625/5625 [==============================] - 71s 13ms/step - loss: 0.4968 - accuracy: 0.7535 - val_loss: 0.4935 - val_accuracy: 0.7544\n",
            "Epoch 47/100\n",
            "5625/5625 [==============================] - 74s 13ms/step - loss: 0.4970 - accuracy: 0.7528 - val_loss: 0.4928 - val_accuracy: 0.7549\n",
            "Epoch 48/100\n",
            "5625/5625 [==============================] - 70s 12ms/step - loss: 0.4963 - accuracy: 0.7523 - val_loss: 0.4929 - val_accuracy: 0.7547\n",
            "Epoch 49/100\n",
            "5625/5625 [==============================] - 68s 12ms/step - loss: 0.4956 - accuracy: 0.7534 - val_loss: 0.4920 - val_accuracy: 0.7551\n",
            "Epoch 50/100\n",
            "5625/5625 [==============================] - 69s 12ms/step - loss: 0.4961 - accuracy: 0.7536 - val_loss: 0.4931 - val_accuracy: 0.7542\n",
            "Epoch 51/100\n",
            "5625/5625 [==============================] - 68s 12ms/step - loss: 0.4952 - accuracy: 0.7540 - val_loss: 0.4930 - val_accuracy: 0.7559\n",
            "Epoch 52/100\n",
            "5625/5625 [==============================] - 68s 12ms/step - loss: 0.4956 - accuracy: 0.7534 - val_loss: 0.4925 - val_accuracy: 0.7551\n",
            "Epoch 53/100\n",
            "5625/5625 [==============================] - 74s 13ms/step - loss: 0.4947 - accuracy: 0.7546 - val_loss: 0.4923 - val_accuracy: 0.7547\n",
            "Epoch 54/100\n",
            "5625/5625 [==============================] - 70s 12ms/step - loss: 0.4949 - accuracy: 0.7542 - val_loss: 0.4931 - val_accuracy: 0.7551\n",
            "Epoch 54: early stopping\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.4869 - accuracy: 0.7603\n",
            "Test loss: 0.4869\n",
            "Test accuracy: 0.7603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Normalize the input data\n",
        "scaler = StandardScaler()\n",
        "train_features = scaler.fit_transform(train_features)\n",
        "val_features = scaler.transform(val_features)\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_dim=28, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Early stopping callback\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_features, train_labels, epochs=100, batch_size=128, validation_data=(val_features, val_labels), callbacks=[es])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_features, test_labels)\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTjor0x2GQCM",
        "outputId": "c2981521-6949-4776-fab8-0f4d111b8678"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2813/2813 [==============================] - 51s 17ms/step - loss: 0.7170 - accuracy: 0.5742 - val_loss: 0.6630 - val_accuracy: 0.6275\n",
            "Epoch 2/100\n",
            "2813/2813 [==============================] - 51s 18ms/step - loss: 0.6651 - accuracy: 0.6298 - val_loss: 0.6329 - val_accuracy: 0.6613\n",
            "Epoch 3/100\n",
            "2813/2813 [==============================] - 46s 16ms/step - loss: 0.6394 - accuracy: 0.6548 - val_loss: 0.6120 - val_accuracy: 0.6806\n",
            "Epoch 4/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.6206 - accuracy: 0.6713 - val_loss: 0.5948 - val_accuracy: 0.6913\n",
            "Epoch 5/100\n",
            "2813/2813 [==============================] - 53s 19ms/step - loss: 0.6054 - accuracy: 0.6825 - val_loss: 0.5819 - val_accuracy: 0.7004\n",
            "Epoch 6/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5944 - accuracy: 0.6902 - val_loss: 0.5728 - val_accuracy: 0.7046\n",
            "Epoch 7/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5852 - accuracy: 0.6953 - val_loss: 0.5639 - val_accuracy: 0.7093\n",
            "Epoch 8/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5785 - accuracy: 0.6997 - val_loss: 0.5578 - val_accuracy: 0.7141\n",
            "Epoch 9/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5722 - accuracy: 0.7039 - val_loss: 0.5520 - val_accuracy: 0.7196\n",
            "Epoch 10/100\n",
            "2813/2813 [==============================] - 49s 17ms/step - loss: 0.5674 - accuracy: 0.7067 - val_loss: 0.5485 - val_accuracy: 0.7214\n",
            "Epoch 11/100\n",
            "2813/2813 [==============================] - 47s 17ms/step - loss: 0.5631 - accuracy: 0.7094 - val_loss: 0.5439 - val_accuracy: 0.7246\n",
            "Epoch 12/100\n",
            "2813/2813 [==============================] - 47s 17ms/step - loss: 0.5602 - accuracy: 0.7115 - val_loss: 0.5411 - val_accuracy: 0.7265\n",
            "Epoch 13/100\n",
            "2813/2813 [==============================] - 46s 16ms/step - loss: 0.5571 - accuracy: 0.7132 - val_loss: 0.5383 - val_accuracy: 0.7272\n",
            "Epoch 14/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5543 - accuracy: 0.7152 - val_loss: 0.5366 - val_accuracy: 0.7286\n",
            "Epoch 15/100\n",
            "2813/2813 [==============================] - 46s 16ms/step - loss: 0.5517 - accuracy: 0.7177 - val_loss: 0.5349 - val_accuracy: 0.7300\n",
            "Epoch 16/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5508 - accuracy: 0.7181 - val_loss: 0.5324 - val_accuracy: 0.7306\n",
            "Epoch 17/100\n",
            "2813/2813 [==============================] - 46s 16ms/step - loss: 0.5481 - accuracy: 0.7191 - val_loss: 0.5305 - val_accuracy: 0.7312\n",
            "Epoch 18/100\n",
            "2813/2813 [==============================] - 46s 16ms/step - loss: 0.5466 - accuracy: 0.7199 - val_loss: 0.5301 - val_accuracy: 0.7324\n",
            "Epoch 19/100\n",
            "2813/2813 [==============================] - 46s 16ms/step - loss: 0.5455 - accuracy: 0.7214 - val_loss: 0.5286 - val_accuracy: 0.7331\n",
            "Epoch 20/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5436 - accuracy: 0.7225 - val_loss: 0.5273 - val_accuracy: 0.7332\n",
            "Epoch 21/100\n",
            "2813/2813 [==============================] - 45s 16ms/step - loss: 0.5420 - accuracy: 0.7232 - val_loss: 0.5259 - val_accuracy: 0.7338\n",
            "Epoch 22/100\n",
            "2813/2813 [==============================] - 51s 18ms/step - loss: 0.5410 - accuracy: 0.7238 - val_loss: 0.5260 - val_accuracy: 0.7343\n",
            "Epoch 23/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5397 - accuracy: 0.7246 - val_loss: 0.5243 - val_accuracy: 0.7351\n",
            "Epoch 24/100\n",
            "2813/2813 [==============================] - 46s 16ms/step - loss: 0.5384 - accuracy: 0.7251 - val_loss: 0.5237 - val_accuracy: 0.7356\n",
            "Epoch 25/100\n",
            "2813/2813 [==============================] - 46s 16ms/step - loss: 0.5380 - accuracy: 0.7252 - val_loss: 0.5219 - val_accuracy: 0.7365\n",
            "Epoch 26/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5365 - accuracy: 0.7269 - val_loss: 0.5208 - val_accuracy: 0.7366\n",
            "Epoch 27/100\n",
            "2813/2813 [==============================] - 45s 16ms/step - loss: 0.5361 - accuracy: 0.7269 - val_loss: 0.5209 - val_accuracy: 0.7369\n",
            "Epoch 28/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5353 - accuracy: 0.7269 - val_loss: 0.5199 - val_accuracy: 0.7367\n",
            "Epoch 29/100\n",
            "2813/2813 [==============================] - 46s 17ms/step - loss: 0.5350 - accuracy: 0.7278 - val_loss: 0.5192 - val_accuracy: 0.7383\n",
            "Epoch 30/100\n",
            "2813/2813 [==============================] - 46s 16ms/step - loss: 0.5332 - accuracy: 0.7296 - val_loss: 0.5190 - val_accuracy: 0.7381\n",
            "Epoch 31/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5329 - accuracy: 0.7295 - val_loss: 0.5178 - val_accuracy: 0.7387\n",
            "Epoch 32/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5320 - accuracy: 0.7284 - val_loss: 0.5168 - val_accuracy: 0.7393\n",
            "Epoch 33/100\n",
            "2813/2813 [==============================] - 46s 16ms/step - loss: 0.5311 - accuracy: 0.7300 - val_loss: 0.5164 - val_accuracy: 0.7391\n",
            "Epoch 34/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5299 - accuracy: 0.7307 - val_loss: 0.5155 - val_accuracy: 0.7398\n",
            "Epoch 35/100\n",
            "2813/2813 [==============================] - 51s 18ms/step - loss: 0.5299 - accuracy: 0.7301 - val_loss: 0.5152 - val_accuracy: 0.7404\n",
            "Epoch 36/100\n",
            "2813/2813 [==============================] - 47s 17ms/step - loss: 0.5296 - accuracy: 0.7306 - val_loss: 0.5147 - val_accuracy: 0.7404\n",
            "Epoch 37/100\n",
            "2813/2813 [==============================] - 47s 17ms/step - loss: 0.5287 - accuracy: 0.7317 - val_loss: 0.5144 - val_accuracy: 0.7408\n",
            "Epoch 38/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5279 - accuracy: 0.7325 - val_loss: 0.5132 - val_accuracy: 0.7413\n",
            "Epoch 39/100\n",
            "2813/2813 [==============================] - 47s 17ms/step - loss: 0.5272 - accuracy: 0.7326 - val_loss: 0.5130 - val_accuracy: 0.7419\n",
            "Epoch 40/100\n",
            "2813/2813 [==============================] - 47s 17ms/step - loss: 0.5270 - accuracy: 0.7329 - val_loss: 0.5130 - val_accuracy: 0.7413\n",
            "Epoch 41/100\n",
            "2813/2813 [==============================] - 46s 16ms/step - loss: 0.5263 - accuracy: 0.7333 - val_loss: 0.5123 - val_accuracy: 0.7428\n",
            "Epoch 42/100\n",
            "2813/2813 [==============================] - 47s 17ms/step - loss: 0.5256 - accuracy: 0.7333 - val_loss: 0.5123 - val_accuracy: 0.7419\n",
            "Epoch 43/100\n",
            "2813/2813 [==============================] - 49s 17ms/step - loss: 0.5243 - accuracy: 0.7346 - val_loss: 0.5105 - val_accuracy: 0.7427\n",
            "Epoch 44/100\n",
            "2813/2813 [==============================] - 47s 17ms/step - loss: 0.5256 - accuracy: 0.7338 - val_loss: 0.5113 - val_accuracy: 0.7430\n",
            "Epoch 45/100\n",
            "2813/2813 [==============================] - 46s 16ms/step - loss: 0.5243 - accuracy: 0.7348 - val_loss: 0.5110 - val_accuracy: 0.7429\n",
            "Epoch 46/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5242 - accuracy: 0.7344 - val_loss: 0.5104 - val_accuracy: 0.7430\n",
            "Epoch 47/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5233 - accuracy: 0.7350 - val_loss: 0.5099 - val_accuracy: 0.7435\n",
            "Epoch 48/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5225 - accuracy: 0.7362 - val_loss: 0.5093 - val_accuracy: 0.7438\n",
            "Epoch 49/100\n",
            "2813/2813 [==============================] - 46s 16ms/step - loss: 0.5228 - accuracy: 0.7351 - val_loss: 0.5087 - val_accuracy: 0.7446\n",
            "Epoch 50/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5218 - accuracy: 0.7354 - val_loss: 0.5087 - val_accuracy: 0.7441\n",
            "Epoch 51/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5213 - accuracy: 0.7367 - val_loss: 0.5079 - val_accuracy: 0.7438\n",
            "Epoch 52/100\n",
            "2813/2813 [==============================] - 46s 16ms/step - loss: 0.5203 - accuracy: 0.7372 - val_loss: 0.5078 - val_accuracy: 0.7439\n",
            "Epoch 53/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5207 - accuracy: 0.7368 - val_loss: 0.5073 - val_accuracy: 0.7442\n",
            "Epoch 54/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5201 - accuracy: 0.7368 - val_loss: 0.5076 - val_accuracy: 0.7444\n",
            "Epoch 55/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5198 - accuracy: 0.7373 - val_loss: 0.5068 - val_accuracy: 0.7456\n",
            "Epoch 56/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5199 - accuracy: 0.7380 - val_loss: 0.5068 - val_accuracy: 0.7453\n",
            "Epoch 57/100\n",
            "2813/2813 [==============================] - 47s 17ms/step - loss: 0.5195 - accuracy: 0.7381 - val_loss: 0.5069 - val_accuracy: 0.7451\n",
            "Epoch 58/100\n",
            "2813/2813 [==============================] - 46s 16ms/step - loss: 0.5191 - accuracy: 0.7382 - val_loss: 0.5061 - val_accuracy: 0.7454\n",
            "Epoch 59/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5187 - accuracy: 0.7381 - val_loss: 0.5049 - val_accuracy: 0.7464\n",
            "Epoch 60/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5170 - accuracy: 0.7393 - val_loss: 0.5065 - val_accuracy: 0.7453\n",
            "Epoch 61/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5183 - accuracy: 0.7381 - val_loss: 0.5056 - val_accuracy: 0.7460\n",
            "Epoch 62/100\n",
            "2813/2813 [==============================] - 47s 17ms/step - loss: 0.5179 - accuracy: 0.7391 - val_loss: 0.5056 - val_accuracy: 0.7462\n",
            "Epoch 63/100\n",
            "2813/2813 [==============================] - 46s 16ms/step - loss: 0.5178 - accuracy: 0.7388 - val_loss: 0.5047 - val_accuracy: 0.7464\n",
            "Epoch 64/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5171 - accuracy: 0.7392 - val_loss: 0.5045 - val_accuracy: 0.7468\n",
            "Epoch 65/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5169 - accuracy: 0.7388 - val_loss: 0.5051 - val_accuracy: 0.7465\n",
            "Epoch 66/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5166 - accuracy: 0.7400 - val_loss: 0.5043 - val_accuracy: 0.7468\n",
            "Epoch 67/100\n",
            "2813/2813 [==============================] - 47s 17ms/step - loss: 0.5169 - accuracy: 0.7399 - val_loss: 0.5039 - val_accuracy: 0.7474\n",
            "Epoch 68/100\n",
            "2813/2813 [==============================] - 46s 16ms/step - loss: 0.5165 - accuracy: 0.7400 - val_loss: 0.5047 - val_accuracy: 0.7473\n",
            "Epoch 69/100\n",
            "2813/2813 [==============================] - 46s 16ms/step - loss: 0.5156 - accuracy: 0.7408 - val_loss: 0.5030 - val_accuracy: 0.7480\n",
            "Epoch 70/100\n",
            "2813/2813 [==============================] - 46s 16ms/step - loss: 0.5156 - accuracy: 0.7402 - val_loss: 0.5021 - val_accuracy: 0.7478\n",
            "Epoch 71/100\n",
            "2813/2813 [==============================] - 47s 17ms/step - loss: 0.5159 - accuracy: 0.7402 - val_loss: 0.5031 - val_accuracy: 0.7476\n",
            "Epoch 72/100\n",
            "2813/2813 [==============================] - 43s 15ms/step - loss: 0.5153 - accuracy: 0.7403 - val_loss: 0.5039 - val_accuracy: 0.7471\n",
            "Epoch 73/100\n",
            "2813/2813 [==============================] - 46s 16ms/step - loss: 0.5145 - accuracy: 0.7407 - val_loss: 0.5029 - val_accuracy: 0.7477\n",
            "Epoch 74/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5148 - accuracy: 0.7408 - val_loss: 0.5030 - val_accuracy: 0.7485\n",
            "Epoch 75/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5138 - accuracy: 0.7405 - val_loss: 0.5017 - val_accuracy: 0.7487\n",
            "Epoch 76/100\n",
            "2813/2813 [==============================] - 46s 16ms/step - loss: 0.5141 - accuracy: 0.7418 - val_loss: 0.5026 - val_accuracy: 0.7490\n",
            "Epoch 77/100\n",
            "2813/2813 [==============================] - 46s 16ms/step - loss: 0.5140 - accuracy: 0.7420 - val_loss: 0.5023 - val_accuracy: 0.7485\n",
            "Epoch 78/100\n",
            "2813/2813 [==============================] - 46s 16ms/step - loss: 0.5139 - accuracy: 0.7413 - val_loss: 0.5025 - val_accuracy: 0.7484\n",
            "Epoch 79/100\n",
            "2813/2813 [==============================] - 47s 17ms/step - loss: 0.5136 - accuracy: 0.7422 - val_loss: 0.5038 - val_accuracy: 0.7480\n",
            "Epoch 80/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5132 - accuracy: 0.7420 - val_loss: 0.5016 - val_accuracy: 0.7489\n",
            "Epoch 81/100\n",
            "2813/2813 [==============================] - 49s 17ms/step - loss: 0.5131 - accuracy: 0.7424 - val_loss: 0.5014 - val_accuracy: 0.7492\n",
            "Epoch 82/100\n",
            "2813/2813 [==============================] - 49s 17ms/step - loss: 0.5126 - accuracy: 0.7422 - val_loss: 0.5014 - val_accuracy: 0.7488\n",
            "Epoch 83/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5130 - accuracy: 0.7421 - val_loss: 0.5016 - val_accuracy: 0.7493\n",
            "Epoch 84/100\n",
            "2813/2813 [==============================] - 46s 16ms/step - loss: 0.5120 - accuracy: 0.7426 - val_loss: 0.5012 - val_accuracy: 0.7486\n",
            "Epoch 85/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5121 - accuracy: 0.7436 - val_loss: 0.5004 - val_accuracy: 0.7494\n",
            "Epoch 86/100\n",
            "2813/2813 [==============================] - 49s 17ms/step - loss: 0.5112 - accuracy: 0.7426 - val_loss: 0.5010 - val_accuracy: 0.7495\n",
            "Epoch 87/100\n",
            "2813/2813 [==============================] - 46s 16ms/step - loss: 0.5126 - accuracy: 0.7426 - val_loss: 0.5009 - val_accuracy: 0.7492\n",
            "Epoch 88/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5118 - accuracy: 0.7431 - val_loss: 0.5009 - val_accuracy: 0.7497\n",
            "Epoch 89/100\n",
            "2813/2813 [==============================] - 49s 17ms/step - loss: 0.5119 - accuracy: 0.7426 - val_loss: 0.5003 - val_accuracy: 0.7496\n",
            "Epoch 90/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5113 - accuracy: 0.7426 - val_loss: 0.5010 - val_accuracy: 0.7497\n",
            "Epoch 91/100\n",
            "2813/2813 [==============================] - 49s 17ms/step - loss: 0.5112 - accuracy: 0.7441 - val_loss: 0.5000 - val_accuracy: 0.7496\n",
            "Epoch 92/100\n",
            "2813/2813 [==============================] - 46s 16ms/step - loss: 0.5107 - accuracy: 0.7432 - val_loss: 0.5008 - val_accuracy: 0.7496\n",
            "Epoch 93/100\n",
            "2813/2813 [==============================] - 50s 18ms/step - loss: 0.5108 - accuracy: 0.7442 - val_loss: 0.4995 - val_accuracy: 0.7503\n",
            "Epoch 94/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5099 - accuracy: 0.7443 - val_loss: 0.5000 - val_accuracy: 0.7503\n",
            "Epoch 95/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5106 - accuracy: 0.7441 - val_loss: 0.4993 - val_accuracy: 0.7505\n",
            "Epoch 96/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5110 - accuracy: 0.7443 - val_loss: 0.4997 - val_accuracy: 0.7500\n",
            "Epoch 97/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5107 - accuracy: 0.7438 - val_loss: 0.4991 - val_accuracy: 0.7499\n",
            "Epoch 98/100\n",
            "2813/2813 [==============================] - 46s 16ms/step - loss: 0.5103 - accuracy: 0.7439 - val_loss: 0.4989 - val_accuracy: 0.7499\n",
            "Epoch 99/100\n",
            "2813/2813 [==============================] - 47s 17ms/step - loss: 0.5105 - accuracy: 0.7434 - val_loss: 0.4990 - val_accuracy: 0.7506\n",
            "Epoch 100/100\n",
            "2813/2813 [==============================] - 48s 17ms/step - loss: 0.5099 - accuracy: 0.7444 - val_loss: 0.5001 - val_accuracy: 0.7500\n",
            "3750/3750 [==============================] - 12s 3ms/step - loss: 0.4944 - accuracy: 0.7537\n",
            "Test loss: 0.4944\n",
            "Test accuracy: 0.7537\n"
          ]
        }
      ]
    }
  ]
}