{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3aPf3ScyB25"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive in Colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load data from Google Drive\n",
        "train_path = '/content/drive/MyDrive/Colab Notebooks/training_data.pkl'\n",
        "val_path   = '/content/drive/MyDrive/Colab Notebooks/validation_data.pkl'\n",
        "test_path  = '/content/drive/MyDrive/Colab Notebooks/testing_data.pkl'\n",
        "train_data =pd.read_pickle(train_path)\n",
        "val_data = pd.read_pickle(val_path)\n",
        "test_data = pd.read_pickle(test_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_wwMu0NyEUj",
        "outputId": "d11a45d6-7e7f-4934-fbc4-50eacd45d9cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ufyncxRhaCMv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and labels\n",
        "train_labels = train_data['class_label']\n",
        "train_features = train_data.drop('class_label', axis=1)\n",
        "val_labels = val_data['class_label']\n",
        "val_features = val_data.drop('class_label', axis=1)\n",
        "test_labels = test_data['class_label']\n",
        "test_features = test_data.drop('class_label', axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "8NPjn62iyJnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize the data\n",
        "# # Normalize the feature columns\n",
        "scaler = StandardScaler()\n",
        "scaler = scaler.fit(train_features)\n",
        "train_features=scaler.transform(train_features)\n",
        "val_features=scaler.transform(val_features)\n",
        "test_features=scaler.transform(test_features)"
      ],
      "metadata": {
        "id": "OF0Go8Nahnt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from sklearn.metrics import accuracy_score, precision_score,recall_score, f1_score, confusion_matrix, classification_report, roc_auc_score"
      ],
      "metadata": {
        "id": "Qsih9HlDyM8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(128, input_dim=28, activation='relu'))\n",
        "# model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "# model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "bpYVvbNmyQMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "vpTzgINSySzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_features, train_labels, epochs=10, batch_size=32, validation_data=(val_features, val_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVKmphZoyWW_",
        "outputId": "21f1ed3c-1127-48bf-a669-7f5bffd7f92f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "13117/13117 [==============================] - 24s 2ms/step - loss: 0.6058 - accuracy: 0.6726 - val_loss: 0.5704 - val_accuracy: 0.7097\n",
            "Epoch 2/10\n",
            "13117/13117 [==============================] - 22s 2ms/step - loss: 0.5826 - accuracy: 0.6940 - val_loss: 0.5649 - val_accuracy: 0.7112\n",
            "Epoch 3/10\n",
            "13117/13117 [==============================] - 22s 2ms/step - loss: 0.5795 - accuracy: 0.6961 - val_loss: 0.5611 - val_accuracy: 0.7151\n",
            "Epoch 4/10\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5767 - accuracy: 0.6996 - val_loss: 0.5593 - val_accuracy: 0.7164\n",
            "Epoch 5/10\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5755 - accuracy: 0.6993 - val_loss: 0.5575 - val_accuracy: 0.7163\n",
            "Epoch 6/10\n",
            "13117/13117 [==============================] - 22s 2ms/step - loss: 0.5729 - accuracy: 0.7016 - val_loss: 0.5593 - val_accuracy: 0.7163\n",
            "Epoch 7/10\n",
            "13117/13117 [==============================] - 22s 2ms/step - loss: 0.5726 - accuracy: 0.7013 - val_loss: 0.5552 - val_accuracy: 0.7208\n",
            "Epoch 8/10\n",
            "13117/13117 [==============================] - 22s 2ms/step - loss: 0.5711 - accuracy: 0.7031 - val_loss: 0.5560 - val_accuracy: 0.7162\n",
            "Epoch 9/10\n",
            "13117/13117 [==============================] - 24s 2ms/step - loss: 0.5701 - accuracy: 0.7036 - val_loss: 0.5553 - val_accuracy: 0.7176\n",
            "Epoch 10/10\n",
            "13117/13117 [==============================] - 22s 2ms/step - loss: 0.5695 - accuracy: 0.7044 - val_loss: 0.5555 - val_accuracy: 0.7190\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f62bbb75c70>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_features, test_labels)\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "test_pred = model.predict(test_features)\n",
        "test_pred_binary = (test_pred >= 0.5).astype(int)\n",
        "test_auc = roc_auc_score(test_labels, test_pred)\n",
        "test_f1 = f1_score(test_labels, test_pred_binary)\n",
        "\n",
        "print(f\"Test AUC: {test_auc:.4f}\")\n",
        "print(f\"Test F1 score: {test_f1:.4f}\")\n",
        "# Calculate the accuracy of the model on the test data\n",
        "# accuracy = accuracy_score(y_test, test_preds)\n",
        "# auc = roc_auc_score(y_test, test_preds)\n",
        "# accuracy = accuracy_score(y_test, test_preds)\n",
        "# precision = precision_score(y_test, test_preds)\n",
        "# recall = recall_score(y_test, test_preds)\n",
        "# f1 = f1_score(y_test, test_preds)\n",
        "# print(\"Test AUC score: {:.4f}\".format(auc))\n",
        "# print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
        "# print('Precision:', precision)\n",
        "# print('Recall:', recall)\n",
        "# print('F1 Score:', f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGsfQsskjKNe",
        "outputId": "984ee33d-0fa7-4083-fea7-b397b70fdd23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2813/2813 [==============================] - 4s 1ms/step - loss: 0.5544 - accuracy: 0.7205\n",
            "Test loss: 0.5544\n",
            "Test accuracy: 0.7205\n",
            "2813/2813 [==============================] - 3s 974us/step\n",
            "Test AUC: 0.7919\n",
            "Test F1 score: 0.7451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_features, train_labels, epochs=100, batch_size=32, validation_data=(val_features, val_labels))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fz0XOWEnBgoO",
        "outputId": "dee8fca9-986e-494e-cdcd-14dc3ce48837"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "13117/13117 [==============================] - 26s 2ms/step - loss: 0.5678 - accuracy: 0.7055 - val_loss: 0.5508 - val_accuracy: 0.7224\n",
            "Epoch 2/100\n",
            "13117/13117 [==============================] - 25s 2ms/step - loss: 0.5680 - accuracy: 0.7054 - val_loss: 0.5531 - val_accuracy: 0.7185\n",
            "Epoch 3/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5677 - accuracy: 0.7054 - val_loss: 0.5512 - val_accuracy: 0.7222\n",
            "Epoch 4/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5670 - accuracy: 0.7060 - val_loss: 0.5517 - val_accuracy: 0.7195\n",
            "Epoch 5/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5671 - accuracy: 0.7068 - val_loss: 0.5526 - val_accuracy: 0.7206\n",
            "Epoch 6/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5665 - accuracy: 0.7061 - val_loss: 0.5503 - val_accuracy: 0.7221\n",
            "Epoch 7/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5672 - accuracy: 0.7053 - val_loss: 0.5506 - val_accuracy: 0.7221\n",
            "Epoch 8/100\n",
            "13117/13117 [==============================] - 22s 2ms/step - loss: 0.5666 - accuracy: 0.7057 - val_loss: 0.5499 - val_accuracy: 0.7222\n",
            "Epoch 9/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5668 - accuracy: 0.7064 - val_loss: 0.5493 - val_accuracy: 0.7227\n",
            "Epoch 10/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5656 - accuracy: 0.7065 - val_loss: 0.5510 - val_accuracy: 0.7195\n",
            "Epoch 11/100\n",
            "13117/13117 [==============================] - 25s 2ms/step - loss: 0.5656 - accuracy: 0.7071 - val_loss: 0.5510 - val_accuracy: 0.7238\n",
            "Epoch 12/100\n",
            "13117/13117 [==============================] - 26s 2ms/step - loss: 0.5658 - accuracy: 0.7074 - val_loss: 0.5535 - val_accuracy: 0.7155\n",
            "Epoch 13/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5654 - accuracy: 0.7071 - val_loss: 0.5480 - val_accuracy: 0.7235\n",
            "Epoch 14/100\n",
            "13117/13117 [==============================] - 25s 2ms/step - loss: 0.5655 - accuracy: 0.7074 - val_loss: 0.5504 - val_accuracy: 0.7186\n",
            "Epoch 15/100\n",
            "13117/13117 [==============================] - 25s 2ms/step - loss: 0.5651 - accuracy: 0.7074 - val_loss: 0.5505 - val_accuracy: 0.7247\n",
            "Epoch 16/100\n",
            "13117/13117 [==============================] - 26s 2ms/step - loss: 0.5646 - accuracy: 0.7078 - val_loss: 0.5511 - val_accuracy: 0.7203\n",
            "Epoch 17/100\n",
            "13117/13117 [==============================] - 25s 2ms/step - loss: 0.5648 - accuracy: 0.7073 - val_loss: 0.5509 - val_accuracy: 0.7202\n",
            "Epoch 18/100\n",
            "13117/13117 [==============================] - 25s 2ms/step - loss: 0.5644 - accuracy: 0.7086 - val_loss: 0.5479 - val_accuracy: 0.7233\n",
            "Epoch 19/100\n",
            "13117/13117 [==============================] - 26s 2ms/step - loss: 0.5651 - accuracy: 0.7073 - val_loss: 0.5482 - val_accuracy: 0.7227\n",
            "Epoch 20/100\n",
            "13117/13117 [==============================] - 25s 2ms/step - loss: 0.5647 - accuracy: 0.7085 - val_loss: 0.5506 - val_accuracy: 0.7193\n",
            "Epoch 21/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5647 - accuracy: 0.7079 - val_loss: 0.5471 - val_accuracy: 0.7234\n",
            "Epoch 22/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5647 - accuracy: 0.7078 - val_loss: 0.5498 - val_accuracy: 0.7205\n",
            "Epoch 23/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5643 - accuracy: 0.7087 - val_loss: 0.5488 - val_accuracy: 0.7240\n",
            "Epoch 24/100\n",
            "13117/13117 [==============================] - 24s 2ms/step - loss: 0.5643 - accuracy: 0.7081 - val_loss: 0.5483 - val_accuracy: 0.7253\n",
            "Epoch 25/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5644 - accuracy: 0.7079 - val_loss: 0.5475 - val_accuracy: 0.7254\n",
            "Epoch 26/100\n",
            "13117/13117 [==============================] - 25s 2ms/step - loss: 0.5644 - accuracy: 0.7088 - val_loss: 0.5478 - val_accuracy: 0.7265\n",
            "Epoch 27/100\n",
            "13117/13117 [==============================] - 25s 2ms/step - loss: 0.5637 - accuracy: 0.7086 - val_loss: 0.5478 - val_accuracy: 0.7230\n",
            "Epoch 28/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5637 - accuracy: 0.7091 - val_loss: 0.5502 - val_accuracy: 0.7200\n",
            "Epoch 29/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5634 - accuracy: 0.7090 - val_loss: 0.5470 - val_accuracy: 0.7247\n",
            "Epoch 30/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5638 - accuracy: 0.7086 - val_loss: 0.5483 - val_accuracy: 0.7229\n",
            "Epoch 31/100\n",
            "13117/13117 [==============================] - 24s 2ms/step - loss: 0.5635 - accuracy: 0.7095 - val_loss: 0.5484 - val_accuracy: 0.7252\n",
            "Epoch 32/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5634 - accuracy: 0.7086 - val_loss: 0.5481 - val_accuracy: 0.7227\n",
            "Epoch 33/100\n",
            "13117/13117 [==============================] - 27s 2ms/step - loss: 0.5641 - accuracy: 0.7082 - val_loss: 0.5475 - val_accuracy: 0.7225\n",
            "Epoch 34/100\n",
            "13117/13117 [==============================] - 26s 2ms/step - loss: 0.5628 - accuracy: 0.7094 - val_loss: 0.5477 - val_accuracy: 0.7216\n",
            "Epoch 35/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5633 - accuracy: 0.7095 - val_loss: 0.5472 - val_accuracy: 0.7236\n",
            "Epoch 36/100\n",
            "13117/13117 [==============================] - 25s 2ms/step - loss: 0.5635 - accuracy: 0.7088 - val_loss: 0.5477 - val_accuracy: 0.7241\n",
            "Epoch 37/100\n",
            "13117/13117 [==============================] - 25s 2ms/step - loss: 0.5633 - accuracy: 0.7096 - val_loss: 0.5480 - val_accuracy: 0.7240\n",
            "Epoch 38/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5633 - accuracy: 0.7095 - val_loss: 0.5468 - val_accuracy: 0.7234\n",
            "Epoch 39/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5629 - accuracy: 0.7098 - val_loss: 0.5471 - val_accuracy: 0.7261\n",
            "Epoch 40/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5635 - accuracy: 0.7094 - val_loss: 0.5469 - val_accuracy: 0.7251\n",
            "Epoch 41/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5629 - accuracy: 0.7088 - val_loss: 0.5466 - val_accuracy: 0.7253\n",
            "Epoch 42/100\n",
            "13117/13117 [==============================] - 26s 2ms/step - loss: 0.5634 - accuracy: 0.7089 - val_loss: 0.5467 - val_accuracy: 0.7240\n",
            "Epoch 43/100\n",
            "13117/13117 [==============================] - 24s 2ms/step - loss: 0.5634 - accuracy: 0.7092 - val_loss: 0.5471 - val_accuracy: 0.7250\n",
            "Epoch 44/100\n",
            "13117/13117 [==============================] - 25s 2ms/step - loss: 0.5632 - accuracy: 0.7087 - val_loss: 0.5480 - val_accuracy: 0.7223\n",
            "Epoch 45/100\n",
            "13117/13117 [==============================] - 25s 2ms/step - loss: 0.5627 - accuracy: 0.7095 - val_loss: 0.5477 - val_accuracy: 0.7241\n",
            "Epoch 46/100\n",
            "13117/13117 [==============================] - 25s 2ms/step - loss: 0.5628 - accuracy: 0.7103 - val_loss: 0.5471 - val_accuracy: 0.7242\n",
            "Epoch 47/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5630 - accuracy: 0.7090 - val_loss: 0.5482 - val_accuracy: 0.7237\n",
            "Epoch 48/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5629 - accuracy: 0.7096 - val_loss: 0.5474 - val_accuracy: 0.7238\n",
            "Epoch 49/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5631 - accuracy: 0.7092 - val_loss: 0.5463 - val_accuracy: 0.7263\n",
            "Epoch 50/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5625 - accuracy: 0.7098 - val_loss: 0.5460 - val_accuracy: 0.7247\n",
            "Epoch 51/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5626 - accuracy: 0.7090 - val_loss: 0.5461 - val_accuracy: 0.7258\n",
            "Epoch 52/100\n",
            "13117/13117 [==============================] - 25s 2ms/step - loss: 0.5629 - accuracy: 0.7091 - val_loss: 0.5450 - val_accuracy: 0.7270\n",
            "Epoch 53/100\n",
            "13117/13117 [==============================] - 25s 2ms/step - loss: 0.5628 - accuracy: 0.7093 - val_loss: 0.5455 - val_accuracy: 0.7252\n",
            "Epoch 54/100\n",
            "13117/13117 [==============================] - 25s 2ms/step - loss: 0.5625 - accuracy: 0.7097 - val_loss: 0.5461 - val_accuracy: 0.7251\n",
            "Epoch 55/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5628 - accuracy: 0.7095 - val_loss: 0.5464 - val_accuracy: 0.7250\n",
            "Epoch 56/100\n",
            "13117/13117 [==============================] - 26s 2ms/step - loss: 0.5620 - accuracy: 0.7093 - val_loss: 0.5468 - val_accuracy: 0.7273\n",
            "Epoch 57/100\n",
            "13117/13117 [==============================] - 25s 2ms/step - loss: 0.5621 - accuracy: 0.7100 - val_loss: 0.5466 - val_accuracy: 0.7249\n",
            "Epoch 58/100\n",
            "13117/13117 [==============================] - 26s 2ms/step - loss: 0.5623 - accuracy: 0.7100 - val_loss: 0.5479 - val_accuracy: 0.7249\n",
            "Epoch 59/100\n",
            "13117/13117 [==============================] - 24s 2ms/step - loss: 0.5621 - accuracy: 0.7102 - val_loss: 0.5471 - val_accuracy: 0.7247\n",
            "Epoch 60/100\n",
            "13117/13117 [==============================] - 24s 2ms/step - loss: 0.5618 - accuracy: 0.7093 - val_loss: 0.5469 - val_accuracy: 0.7228\n",
            "Epoch 61/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5627 - accuracy: 0.7096 - val_loss: 0.5457 - val_accuracy: 0.7274\n",
            "Epoch 62/100\n",
            "13117/13117 [==============================] - 26s 2ms/step - loss: 0.5627 - accuracy: 0.7093 - val_loss: 0.5462 - val_accuracy: 0.7268\n",
            "Epoch 63/100\n",
            "13117/13117 [==============================] - 26s 2ms/step - loss: 0.5623 - accuracy: 0.7095 - val_loss: 0.5484 - val_accuracy: 0.7225\n",
            "Epoch 64/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5624 - accuracy: 0.7096 - val_loss: 0.5484 - val_accuracy: 0.7201\n",
            "Epoch 65/100\n",
            "13117/13117 [==============================] - 26s 2ms/step - loss: 0.5618 - accuracy: 0.7105 - val_loss: 0.5466 - val_accuracy: 0.7234\n",
            "Epoch 66/100\n",
            "13117/13117 [==============================] - 26s 2ms/step - loss: 0.5624 - accuracy: 0.7105 - val_loss: 0.5472 - val_accuracy: 0.7218\n",
            "Epoch 67/100\n",
            "13117/13117 [==============================] - 24s 2ms/step - loss: 0.5625 - accuracy: 0.7102 - val_loss: 0.5463 - val_accuracy: 0.7265\n",
            "Epoch 68/100\n",
            "13117/13117 [==============================] - 24s 2ms/step - loss: 0.5620 - accuracy: 0.7101 - val_loss: 0.5462 - val_accuracy: 0.7267\n",
            "Epoch 69/100\n",
            "13117/13117 [==============================] - 26s 2ms/step - loss: 0.5615 - accuracy: 0.7105 - val_loss: 0.5464 - val_accuracy: 0.7273\n",
            "Epoch 70/100\n",
            "13117/13117 [==============================] - 24s 2ms/step - loss: 0.5619 - accuracy: 0.7095 - val_loss: 0.5461 - val_accuracy: 0.7238\n",
            "Epoch 71/100\n",
            "13117/13117 [==============================] - 26s 2ms/step - loss: 0.5615 - accuracy: 0.7109 - val_loss: 0.5459 - val_accuracy: 0.7276\n",
            "Epoch 72/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5615 - accuracy: 0.7109 - val_loss: 0.5460 - val_accuracy: 0.7262\n",
            "Epoch 73/100\n",
            "13117/13117 [==============================] - 24s 2ms/step - loss: 0.5615 - accuracy: 0.7103 - val_loss: 0.5464 - val_accuracy: 0.7281\n",
            "Epoch 74/100\n",
            "13117/13117 [==============================] - 26s 2ms/step - loss: 0.5621 - accuracy: 0.7103 - val_loss: 0.5485 - val_accuracy: 0.7206\n",
            "Epoch 75/100\n",
            "13117/13117 [==============================] - 25s 2ms/step - loss: 0.5624 - accuracy: 0.7100 - val_loss: 0.5449 - val_accuracy: 0.7255\n",
            "Epoch 76/100\n",
            "13117/13117 [==============================] - 26s 2ms/step - loss: 0.5616 - accuracy: 0.7107 - val_loss: 0.5464 - val_accuracy: 0.7258\n",
            "Epoch 77/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5621 - accuracy: 0.7103 - val_loss: 0.5450 - val_accuracy: 0.7269\n",
            "Epoch 78/100\n",
            "13117/13117 [==============================] - 26s 2ms/step - loss: 0.5614 - accuracy: 0.7115 - val_loss: 0.5462 - val_accuracy: 0.7257\n",
            "Epoch 79/100\n",
            "13117/13117 [==============================] - 26s 2ms/step - loss: 0.5616 - accuracy: 0.7103 - val_loss: 0.5451 - val_accuracy: 0.7232\n",
            "Epoch 80/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5615 - accuracy: 0.7104 - val_loss: 0.5449 - val_accuracy: 0.7256\n",
            "Epoch 81/100\n",
            "13117/13117 [==============================] - 26s 2ms/step - loss: 0.5612 - accuracy: 0.7107 - val_loss: 0.5473 - val_accuracy: 0.7277\n",
            "Epoch 82/100\n",
            "13117/13117 [==============================] - 24s 2ms/step - loss: 0.5613 - accuracy: 0.7105 - val_loss: 0.5460 - val_accuracy: 0.7230\n",
            "Epoch 83/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5609 - accuracy: 0.7113 - val_loss: 0.5455 - val_accuracy: 0.7245\n",
            "Epoch 84/100\n",
            "13117/13117 [==============================] - 26s 2ms/step - loss: 0.5609 - accuracy: 0.7109 - val_loss: 0.5453 - val_accuracy: 0.7246\n",
            "Epoch 85/100\n",
            "13117/13117 [==============================] - 24s 2ms/step - loss: 0.5611 - accuracy: 0.7113 - val_loss: 0.5459 - val_accuracy: 0.7283\n",
            "Epoch 86/100\n",
            "13117/13117 [==============================] - 26s 2ms/step - loss: 0.5611 - accuracy: 0.7104 - val_loss: 0.5478 - val_accuracy: 0.7205\n",
            "Epoch 87/100\n",
            "13117/13117 [==============================] - 24s 2ms/step - loss: 0.5611 - accuracy: 0.7107 - val_loss: 0.5447 - val_accuracy: 0.7291\n",
            "Epoch 88/100\n",
            "13117/13117 [==============================] - 26s 2ms/step - loss: 0.5611 - accuracy: 0.7108 - val_loss: 0.5445 - val_accuracy: 0.7272\n",
            "Epoch 89/100\n",
            "13117/13117 [==============================] - 24s 2ms/step - loss: 0.5608 - accuracy: 0.7112 - val_loss: 0.5444 - val_accuracy: 0.7263\n",
            "Epoch 90/100\n",
            "13117/13117 [==============================] - 24s 2ms/step - loss: 0.5613 - accuracy: 0.7103 - val_loss: 0.5436 - val_accuracy: 0.7254\n",
            "Epoch 91/100\n",
            "13117/13117 [==============================] - 26s 2ms/step - loss: 0.5606 - accuracy: 0.7107 - val_loss: 0.5442 - val_accuracy: 0.7260\n",
            "Epoch 92/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5610 - accuracy: 0.7104 - val_loss: 0.5447 - val_accuracy: 0.7276\n",
            "Epoch 93/100\n",
            "13117/13117 [==============================] - 26s 2ms/step - loss: 0.5607 - accuracy: 0.7120 - val_loss: 0.5481 - val_accuracy: 0.7264\n",
            "Epoch 94/100\n",
            "13117/13117 [==============================] - 26s 2ms/step - loss: 0.5608 - accuracy: 0.7112 - val_loss: 0.5466 - val_accuracy: 0.7237\n",
            "Epoch 95/100\n",
            "13117/13117 [==============================] - 24s 2ms/step - loss: 0.5609 - accuracy: 0.7116 - val_loss: 0.5456 - val_accuracy: 0.7249\n",
            "Epoch 96/100\n",
            "13117/13117 [==============================] - 26s 2ms/step - loss: 0.5606 - accuracy: 0.7108 - val_loss: 0.5439 - val_accuracy: 0.7282\n",
            "Epoch 97/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5606 - accuracy: 0.7111 - val_loss: 0.5445 - val_accuracy: 0.7258\n",
            "Epoch 98/100\n",
            "13117/13117 [==============================] - 26s 2ms/step - loss: 0.5611 - accuracy: 0.7102 - val_loss: 0.5439 - val_accuracy: 0.7260\n",
            "Epoch 99/100\n",
            "13117/13117 [==============================] - 24s 2ms/step - loss: 0.5605 - accuracy: 0.7109 - val_loss: 0.5468 - val_accuracy: 0.7217\n",
            "Epoch 100/100\n",
            "13117/13117 [==============================] - 23s 2ms/step - loss: 0.5601 - accuracy: 0.7115 - val_loss: 0.5452 - val_accuracy: 0.7247\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f62bb1ba4f0>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_features, test_labels)\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "test_pred = model.predict(test_features)\n",
        "test_pred_binary = (test_pred >= 0.5).astype(int)\n",
        "test_auc = roc_auc_score(test_labels, test_pred)\n",
        "test_f1 = f1_score(test_labels, test_pred_binary)\n",
        "\n",
        "print(f\"Test AUC: {test_auc:.4f}\")\n",
        "print(f\"Test F1 score: {test_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nelodb1n8-D",
        "outputId": "10e0438a-5b6f-4247-ea05-764d8d46f8e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2813/2813 [==============================] - 3s 1ms/step - loss: 0.5432 - accuracy: 0.7252\n",
            "Test loss: 0.5432\n",
            "Test accuracy: 0.7252\n",
            "2813/2813 [==============================] - 3s 928us/step\n",
            "Test AUC: 0.8017\n",
            "Test F1 score: 0.7533\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Normalize the input data\n",
        "scaler = StandardScaler()\n",
        "train_features = scaler.fit_transform(train_features)\n",
        "val_features = scaler.transform(val_features)\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(256, input_dim=28, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_features, train_labels, epochs=100, batch_size=32, validation_data=(val_features, val_labels))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZndfAzeYaxCR",
        "outputId": "690bb7fc-61d1-4031-820f-0989c0923000"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.5744 - accuracy: 0.7018 - val_loss: 0.5406 - val_accuracy: 0.7270\n",
            "Epoch 2/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.5374 - accuracy: 0.7257 - val_loss: 0.5269 - val_accuracy: 0.7345\n",
            "Epoch 3/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.5253 - accuracy: 0.7335 - val_loss: 0.5194 - val_accuracy: 0.7379\n",
            "Epoch 4/100\n",
            "13117/13117 [==============================] - 31s 2ms/step - loss: 0.5180 - accuracy: 0.7384 - val_loss: 0.5141 - val_accuracy: 0.7418\n",
            "Epoch 5/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.5130 - accuracy: 0.7420 - val_loss: 0.5117 - val_accuracy: 0.7427\n",
            "Epoch 6/100\n",
            "13117/13117 [==============================] - 31s 2ms/step - loss: 0.5091 - accuracy: 0.7449 - val_loss: 0.5075 - val_accuracy: 0.7460\n",
            "Epoch 7/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.5060 - accuracy: 0.7471 - val_loss: 0.5080 - val_accuracy: 0.7464\n",
            "Epoch 8/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.5035 - accuracy: 0.7484 - val_loss: 0.5059 - val_accuracy: 0.7469\n",
            "Epoch 9/100\n",
            "13117/13117 [==============================] - 31s 2ms/step - loss: 0.5005 - accuracy: 0.7498 - val_loss: 0.5034 - val_accuracy: 0.7487\n",
            "Epoch 10/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4979 - accuracy: 0.7523 - val_loss: 0.5032 - val_accuracy: 0.7489\n",
            "Epoch 11/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4964 - accuracy: 0.7532 - val_loss: 0.5027 - val_accuracy: 0.7486\n",
            "Epoch 12/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4948 - accuracy: 0.7538 - val_loss: 0.5013 - val_accuracy: 0.7509\n",
            "Epoch 13/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4923 - accuracy: 0.7559 - val_loss: 0.5012 - val_accuracy: 0.7495\n",
            "Epoch 14/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4910 - accuracy: 0.7573 - val_loss: 0.4998 - val_accuracy: 0.7507\n",
            "Epoch 15/100\n",
            "13117/13117 [==============================] - 31s 2ms/step - loss: 0.4895 - accuracy: 0.7578 - val_loss: 0.5004 - val_accuracy: 0.7503\n",
            "Epoch 16/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4885 - accuracy: 0.7582 - val_loss: 0.5016 - val_accuracy: 0.7498\n",
            "Epoch 17/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4867 - accuracy: 0.7592 - val_loss: 0.4998 - val_accuracy: 0.7506\n",
            "Epoch 18/100\n",
            "13117/13117 [==============================] - 31s 2ms/step - loss: 0.4853 - accuracy: 0.7604 - val_loss: 0.5010 - val_accuracy: 0.7503\n",
            "Epoch 19/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4843 - accuracy: 0.7612 - val_loss: 0.5014 - val_accuracy: 0.7502\n",
            "Epoch 20/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4827 - accuracy: 0.7621 - val_loss: 0.5015 - val_accuracy: 0.7507\n",
            "Epoch 21/100\n",
            "13117/13117 [==============================] - 30s 2ms/step - loss: 0.4822 - accuracy: 0.7629 - val_loss: 0.5005 - val_accuracy: 0.7508\n",
            "Epoch 22/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4809 - accuracy: 0.7635 - val_loss: 0.5004 - val_accuracy: 0.7522\n",
            "Epoch 23/100\n",
            "13117/13117 [==============================] - 31s 2ms/step - loss: 0.4797 - accuracy: 0.7644 - val_loss: 0.5007 - val_accuracy: 0.7513\n",
            "Epoch 24/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4789 - accuracy: 0.7644 - val_loss: 0.5019 - val_accuracy: 0.7517\n",
            "Epoch 25/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4778 - accuracy: 0.7653 - val_loss: 0.5020 - val_accuracy: 0.7501\n",
            "Epoch 26/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4761 - accuracy: 0.7663 - val_loss: 0.5009 - val_accuracy: 0.7507\n",
            "Epoch 27/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4760 - accuracy: 0.7665 - val_loss: 0.4995 - val_accuracy: 0.7519\n",
            "Epoch 28/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4746 - accuracy: 0.7673 - val_loss: 0.5001 - val_accuracy: 0.7519\n",
            "Epoch 29/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4739 - accuracy: 0.7683 - val_loss: 0.5019 - val_accuracy: 0.7507\n",
            "Epoch 30/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4735 - accuracy: 0.7683 - val_loss: 0.5016 - val_accuracy: 0.7504\n",
            "Epoch 31/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4726 - accuracy: 0.7692 - val_loss: 0.5031 - val_accuracy: 0.7509\n",
            "Epoch 32/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4718 - accuracy: 0.7696 - val_loss: 0.5026 - val_accuracy: 0.7503\n",
            "Epoch 33/100\n",
            "13117/13117 [==============================] - 31s 2ms/step - loss: 0.4706 - accuracy: 0.7705 - val_loss: 0.5019 - val_accuracy: 0.7510\n",
            "Epoch 34/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4700 - accuracy: 0.7708 - val_loss: 0.5044 - val_accuracy: 0.7500\n",
            "Epoch 35/100\n",
            "13117/13117 [==============================] - 31s 2ms/step - loss: 0.4695 - accuracy: 0.7708 - val_loss: 0.5032 - val_accuracy: 0.7501\n",
            "Epoch 36/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4683 - accuracy: 0.7721 - val_loss: 0.5023 - val_accuracy: 0.7510\n",
            "Epoch 37/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4679 - accuracy: 0.7721 - val_loss: 0.5019 - val_accuracy: 0.7504\n",
            "Epoch 38/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4675 - accuracy: 0.7721 - val_loss: 0.5018 - val_accuracy: 0.7503\n",
            "Epoch 39/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4664 - accuracy: 0.7726 - val_loss: 0.5025 - val_accuracy: 0.7506\n",
            "Epoch 40/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4661 - accuracy: 0.7731 - val_loss: 0.5056 - val_accuracy: 0.7509\n",
            "Epoch 41/100\n",
            "13117/13117 [==============================] - 31s 2ms/step - loss: 0.4656 - accuracy: 0.7737 - val_loss: 0.5022 - val_accuracy: 0.7504\n",
            "Epoch 42/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4647 - accuracy: 0.7737 - val_loss: 0.5026 - val_accuracy: 0.7500\n",
            "Epoch 43/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4639 - accuracy: 0.7743 - val_loss: 0.5061 - val_accuracy: 0.7499\n",
            "Epoch 44/100\n",
            "13117/13117 [==============================] - 30s 2ms/step - loss: 0.4642 - accuracy: 0.7739 - val_loss: 0.5067 - val_accuracy: 0.7496\n",
            "Epoch 45/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4628 - accuracy: 0.7752 - val_loss: 0.5110 - val_accuracy: 0.7502\n",
            "Epoch 46/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4627 - accuracy: 0.7759 - val_loss: 0.5027 - val_accuracy: 0.7504\n",
            "Epoch 47/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4621 - accuracy: 0.7761 - val_loss: 0.5040 - val_accuracy: 0.7506\n",
            "Epoch 48/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4616 - accuracy: 0.7763 - val_loss: 0.5070 - val_accuracy: 0.7494\n",
            "Epoch 49/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4611 - accuracy: 0.7765 - val_loss: 0.5040 - val_accuracy: 0.7501\n",
            "Epoch 50/100\n",
            "13117/13117 [==============================] - 31s 2ms/step - loss: 0.4609 - accuracy: 0.7759 - val_loss: 0.5066 - val_accuracy: 0.7488\n",
            "Epoch 51/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4605 - accuracy: 0.7762 - val_loss: 0.5041 - val_accuracy: 0.7489\n",
            "Epoch 52/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4594 - accuracy: 0.7771 - val_loss: 0.5078 - val_accuracy: 0.7486\n",
            "Epoch 53/100\n",
            "13117/13117 [==============================] - 31s 2ms/step - loss: 0.4589 - accuracy: 0.7773 - val_loss: 0.5068 - val_accuracy: 0.7492\n",
            "Epoch 54/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4588 - accuracy: 0.7772 - val_loss: 0.5078 - val_accuracy: 0.7493\n",
            "Epoch 55/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4581 - accuracy: 0.7781 - val_loss: 0.5089 - val_accuracy: 0.7479\n",
            "Epoch 56/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4579 - accuracy: 0.7787 - val_loss: 0.5084 - val_accuracy: 0.7477\n",
            "Epoch 57/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4578 - accuracy: 0.7785 - val_loss: 0.5070 - val_accuracy: 0.7491\n",
            "Epoch 58/100\n",
            "13117/13117 [==============================] - 31s 2ms/step - loss: 0.4571 - accuracy: 0.7787 - val_loss: 0.5071 - val_accuracy: 0.7486\n",
            "Epoch 59/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4569 - accuracy: 0.7787 - val_loss: 0.5122 - val_accuracy: 0.7500\n",
            "Epoch 60/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4564 - accuracy: 0.7783 - val_loss: 0.5115 - val_accuracy: 0.7471\n",
            "Epoch 61/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4558 - accuracy: 0.7795 - val_loss: 0.5117 - val_accuracy: 0.7481\n",
            "Epoch 62/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4559 - accuracy: 0.7796 - val_loss: 0.5098 - val_accuracy: 0.7477\n",
            "Epoch 63/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4553 - accuracy: 0.7797 - val_loss: 0.5152 - val_accuracy: 0.7482\n",
            "Epoch 64/100\n",
            "13117/13117 [==============================] - 31s 2ms/step - loss: 0.4549 - accuracy: 0.7798 - val_loss: 0.5091 - val_accuracy: 0.7483\n",
            "Epoch 65/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4542 - accuracy: 0.7797 - val_loss: 0.5133 - val_accuracy: 0.7477\n",
            "Epoch 66/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4543 - accuracy: 0.7803 - val_loss: 0.5089 - val_accuracy: 0.7473\n",
            "Epoch 67/100\n",
            "13117/13117 [==============================] - 31s 2ms/step - loss: 0.4539 - accuracy: 0.7802 - val_loss: 0.5066 - val_accuracy: 0.7486\n",
            "Epoch 68/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4534 - accuracy: 0.7811 - val_loss: 0.5140 - val_accuracy: 0.7484\n",
            "Epoch 69/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4534 - accuracy: 0.7811 - val_loss: 0.5102 - val_accuracy: 0.7470\n",
            "Epoch 70/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4527 - accuracy: 0.7811 - val_loss: 0.5141 - val_accuracy: 0.7470\n",
            "Epoch 71/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4526 - accuracy: 0.7812 - val_loss: 0.5152 - val_accuracy: 0.7479\n",
            "Epoch 72/100\n",
            "13117/13117 [==============================] - 30s 2ms/step - loss: 0.4529 - accuracy: 0.7817 - val_loss: 0.5110 - val_accuracy: 0.7454\n",
            "Epoch 73/100\n",
            "13117/13117 [==============================] - 32s 2ms/step - loss: 0.4523 - accuracy: 0.7818 - val_loss: 0.5126 - val_accuracy: 0.7480\n",
            "Epoch 74/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4517 - accuracy: 0.7818 - val_loss: 0.5101 - val_accuracy: 0.7462\n",
            "Epoch 75/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4517 - accuracy: 0.7819 - val_loss: 0.5106 - val_accuracy: 0.7464\n",
            "Epoch 76/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4513 - accuracy: 0.7822 - val_loss: 0.5094 - val_accuracy: 0.7473\n",
            "Epoch 77/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4508 - accuracy: 0.7827 - val_loss: 0.5110 - val_accuracy: 0.7471\n",
            "Epoch 78/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4501 - accuracy: 0.7826 - val_loss: 0.5106 - val_accuracy: 0.7463\n",
            "Epoch 79/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4502 - accuracy: 0.7833 - val_loss: 0.5178 - val_accuracy: 0.7458\n",
            "Epoch 80/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4503 - accuracy: 0.7829 - val_loss: 0.5135 - val_accuracy: 0.7459\n",
            "Epoch 81/100\n",
            "13117/13117 [==============================] - 31s 2ms/step - loss: 0.4498 - accuracy: 0.7822 - val_loss: 0.5177 - val_accuracy: 0.7463\n",
            "Epoch 82/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4494 - accuracy: 0.7833 - val_loss: 0.5112 - val_accuracy: 0.7469\n",
            "Epoch 83/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4491 - accuracy: 0.7843 - val_loss: 0.5174 - val_accuracy: 0.7451\n",
            "Epoch 84/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4490 - accuracy: 0.7835 - val_loss: 0.5210 - val_accuracy: 0.7459\n",
            "Epoch 85/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4484 - accuracy: 0.7835 - val_loss: 0.5177 - val_accuracy: 0.7453\n",
            "Epoch 86/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4485 - accuracy: 0.7833 - val_loss: 0.5163 - val_accuracy: 0.7466\n",
            "Epoch 87/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4480 - accuracy: 0.7846 - val_loss: 0.5239 - val_accuracy: 0.7473\n",
            "Epoch 88/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4477 - accuracy: 0.7838 - val_loss: 0.5137 - val_accuracy: 0.7463\n",
            "Epoch 89/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4477 - accuracy: 0.7840 - val_loss: 0.5124 - val_accuracy: 0.7467\n",
            "Epoch 90/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4472 - accuracy: 0.7841 - val_loss: 0.5149 - val_accuracy: 0.7458\n",
            "Epoch 91/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4473 - accuracy: 0.7843 - val_loss: 0.5166 - val_accuracy: 0.7464\n",
            "Epoch 92/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4470 - accuracy: 0.7850 - val_loss: 0.5152 - val_accuracy: 0.7469\n",
            "Epoch 93/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4472 - accuracy: 0.7844 - val_loss: 0.5186 - val_accuracy: 0.7456\n",
            "Epoch 94/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4465 - accuracy: 0.7848 - val_loss: 0.5203 - val_accuracy: 0.7468\n",
            "Epoch 95/100\n",
            "13117/13117 [==============================] - 28s 2ms/step - loss: 0.4465 - accuracy: 0.7849 - val_loss: 0.5179 - val_accuracy: 0.7441\n",
            "Epoch 96/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4459 - accuracy: 0.7853 - val_loss: 0.5154 - val_accuracy: 0.7452\n",
            "Epoch 97/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4455 - accuracy: 0.7850 - val_loss: 0.5188 - val_accuracy: 0.7452\n",
            "Epoch 98/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4453 - accuracy: 0.7860 - val_loss: 0.5175 - val_accuracy: 0.7449\n",
            "Epoch 99/100\n",
            "13117/13117 [==============================] - 31s 2ms/step - loss: 0.4462 - accuracy: 0.7850 - val_loss: 0.5147 - val_accuracy: 0.7453\n",
            "Epoch 100/100\n",
            "13117/13117 [==============================] - 29s 2ms/step - loss: 0.4454 - accuracy: 0.7855 - val_loss: 0.5172 - val_accuracy: 0.7465\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f62c132c610>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_features, test_labels)\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "test_pred = model.predict(test_features)\n",
        "test_pred_binary = (test_pred >= 0.5).astype(int)\n",
        "test_auc = roc_auc_score(test_labels, test_pred)\n",
        "test_f1 = f1_score(test_labels, test_pred_binary)\n",
        "\n",
        "print(f\"Test AUC: {test_auc:.4f}\")\n",
        "print(f\"Test F1 score: {test_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7Ywr7een6Ji",
        "outputId": "4db8f87a-3269-4cff-fa76-768d2198fbf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2813/2813 [==============================] - 3s 1ms/step - loss: 0.5172 - accuracy: 0.7453\n",
            "Test loss: 0.5172\n",
            "Test accuracy: 0.7453\n",
            "2813/2813 [==============================] - 3s 1ms/step\n",
            "Test AUC: 0.8263\n",
            "Test F1 score: 0.7622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code, we have used the StandardScaler from the scikit-learn library to normalize the input data. We have added more hidden layers and increased the number of neurons in the hidden layers. We have also added a dropout layer and an L2 regularization to prevent overfitting. Finally, we have monitored the performance of the model on the validation set."
      ],
      "metadata": {
        "id": "_KxmenQPbgUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Normalize the input data\n",
        "scaler = StandardScaler()\n",
        "train_features = scaler.fit_transform(train_features)\n",
        "val_features = scaler.transform(val_features)\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_dim=28, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Early stopping callback\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_features, train_labels, epochs=50, batch_size=64, validation_data=(val_features, val_labels), callbacks=[es])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V8Q8wOAyl60",
        "outputId": "d7bef9ff-1f25-4bbe-f804-e001a2c2f41f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "6559/6559 [==============================] - 50s 7ms/step - loss: 0.6015 - accuracy: 0.6869 - val_loss: 0.5416 - val_accuracy: 0.7261\n",
            "Epoch 2/50\n",
            "6559/6559 [==============================] - 49s 8ms/step - loss: 0.5536 - accuracy: 0.7142 - val_loss: 0.5317 - val_accuracy: 0.7312\n",
            "Epoch 3/50\n",
            "6559/6559 [==============================] - 50s 8ms/step - loss: 0.5423 - accuracy: 0.7225 - val_loss: 0.5208 - val_accuracy: 0.7379\n",
            "Epoch 4/50\n",
            "6559/6559 [==============================] - 49s 7ms/step - loss: 0.5363 - accuracy: 0.7254 - val_loss: 0.5146 - val_accuracy: 0.7418\n",
            "Epoch 5/50\n",
            "6559/6559 [==============================] - 50s 8ms/step - loss: 0.5317 - accuracy: 0.7298 - val_loss: 0.5125 - val_accuracy: 0.7442\n",
            "Epoch 6/50\n",
            "6559/6559 [==============================] - 50s 8ms/step - loss: 0.5274 - accuracy: 0.7325 - val_loss: 0.5083 - val_accuracy: 0.7465\n",
            "Epoch 7/50\n",
            "6559/6559 [==============================] - 49s 8ms/step - loss: 0.5248 - accuracy: 0.7344 - val_loss: 0.5061 - val_accuracy: 0.7480\n",
            "Epoch 8/50\n",
            "6559/6559 [==============================] - 50s 8ms/step - loss: 0.5228 - accuracy: 0.7361 - val_loss: 0.5054 - val_accuracy: 0.7476\n",
            "Epoch 9/50\n",
            "6559/6559 [==============================] - 50s 8ms/step - loss: 0.5206 - accuracy: 0.7368 - val_loss: 0.5038 - val_accuracy: 0.7492\n",
            "Epoch 10/50\n",
            "6559/6559 [==============================] - 50s 8ms/step - loss: 0.5186 - accuracy: 0.7384 - val_loss: 0.5024 - val_accuracy: 0.7504\n",
            "Epoch 11/50\n",
            "6559/6559 [==============================] - 50s 8ms/step - loss: 0.5167 - accuracy: 0.7393 - val_loss: 0.5027 - val_accuracy: 0.7504\n",
            "Epoch 12/50\n",
            "6559/6559 [==============================] - 50s 8ms/step - loss: 0.5159 - accuracy: 0.7399 - val_loss: 0.4987 - val_accuracy: 0.7524\n",
            "Epoch 13/50\n",
            "6559/6559 [==============================] - 50s 8ms/step - loss: 0.5151 - accuracy: 0.7405 - val_loss: 0.4985 - val_accuracy: 0.7526\n",
            "Epoch 14/50\n",
            "6559/6559 [==============================] - 50s 8ms/step - loss: 0.5135 - accuracy: 0.7422 - val_loss: 0.4976 - val_accuracy: 0.7530\n",
            "Epoch 15/50\n",
            "6559/6559 [==============================] - 49s 7ms/step - loss: 0.5128 - accuracy: 0.7416 - val_loss: 0.4979 - val_accuracy: 0.7542\n",
            "Epoch 16/50\n",
            "6559/6559 [==============================] - 49s 7ms/step - loss: 0.5115 - accuracy: 0.7435 - val_loss: 0.4954 - val_accuracy: 0.7538\n",
            "Epoch 17/50\n",
            "6559/6559 [==============================] - 50s 8ms/step - loss: 0.5110 - accuracy: 0.7435 - val_loss: 0.4968 - val_accuracy: 0.7538\n",
            "Epoch 18/50\n",
            "6559/6559 [==============================] - 50s 8ms/step - loss: 0.5100 - accuracy: 0.7442 - val_loss: 0.4949 - val_accuracy: 0.7559\n",
            "Epoch 19/50\n",
            "6559/6559 [==============================] - 49s 7ms/step - loss: 0.5096 - accuracy: 0.7443 - val_loss: 0.4948 - val_accuracy: 0.7548\n",
            "Epoch 20/50\n",
            "6559/6559 [==============================] - 49s 8ms/step - loss: 0.5087 - accuracy: 0.7457 - val_loss: 0.4945 - val_accuracy: 0.7550\n",
            "Epoch 21/50\n",
            "6559/6559 [==============================] - 50s 8ms/step - loss: 0.5076 - accuracy: 0.7453 - val_loss: 0.4934 - val_accuracy: 0.7552\n",
            "Epoch 22/50\n",
            "6559/6559 [==============================] - 50s 8ms/step - loss: 0.5064 - accuracy: 0.7465 - val_loss: 0.4930 - val_accuracy: 0.7551\n",
            "Epoch 23/50\n",
            "6559/6559 [==============================] - 50s 8ms/step - loss: 0.5058 - accuracy: 0.7475 - val_loss: 0.4932 - val_accuracy: 0.7561\n",
            "Epoch 24/50\n",
            "6559/6559 [==============================] - 50s 8ms/step - loss: 0.5050 - accuracy: 0.7466 - val_loss: 0.4922 - val_accuracy: 0.7563\n",
            "Epoch 25/50\n",
            "6559/6559 [==============================] - 49s 8ms/step - loss: 0.5048 - accuracy: 0.7475 - val_loss: 0.4942 - val_accuracy: 0.7564\n",
            "Epoch 26/50\n",
            "6559/6559 [==============================] - 50s 8ms/step - loss: 0.5044 - accuracy: 0.7477 - val_loss: 0.4927 - val_accuracy: 0.7555\n",
            "Epoch 27/50\n",
            "6559/6559 [==============================] - 50s 8ms/step - loss: 0.5038 - accuracy: 0.7480 - val_loss: 0.4916 - val_accuracy: 0.7560\n",
            "Epoch 28/50\n",
            "6559/6559 [==============================] - 50s 8ms/step - loss: 0.5031 - accuracy: 0.7489 - val_loss: 0.4913 - val_accuracy: 0.7573\n",
            "Epoch 29/50\n",
            "6559/6559 [==============================] - 50s 8ms/step - loss: 0.5035 - accuracy: 0.7490 - val_loss: 0.4929 - val_accuracy: 0.7564\n",
            "Epoch 30/50\n",
            "6559/6559 [==============================] - 49s 7ms/step - loss: 0.5034 - accuracy: 0.7490 - val_loss: 0.4908 - val_accuracy: 0.7574\n",
            "Epoch 31/50\n",
            "6559/6559 [==============================] - 49s 7ms/step - loss: 0.5022 - accuracy: 0.7491 - val_loss: 0.4918 - val_accuracy: 0.7567\n",
            "Epoch 32/50\n",
            "6559/6559 [==============================] - 49s 7ms/step - loss: 0.5024 - accuracy: 0.7490 - val_loss: 0.4914 - val_accuracy: 0.7567\n",
            "Epoch 33/50\n",
            "6559/6559 [==============================] - 48s 7ms/step - loss: 0.5014 - accuracy: 0.7499 - val_loss: 0.4909 - val_accuracy: 0.7577\n",
            "Epoch 34/50\n",
            "6559/6559 [==============================] - 48s 7ms/step - loss: 0.5011 - accuracy: 0.7499 - val_loss: 0.4911 - val_accuracy: 0.7573\n",
            "Epoch 35/50\n",
            "6559/6559 [==============================] - 48s 7ms/step - loss: 0.5003 - accuracy: 0.7495 - val_loss: 0.4902 - val_accuracy: 0.7584\n",
            "Epoch 36/50\n",
            "6559/6559 [==============================] - 48s 7ms/step - loss: 0.4998 - accuracy: 0.7505 - val_loss: 0.4906 - val_accuracy: 0.7570\n",
            "Epoch 37/50\n",
            "6559/6559 [==============================] - 49s 7ms/step - loss: 0.5000 - accuracy: 0.7508 - val_loss: 0.4899 - val_accuracy: 0.7591\n",
            "Epoch 38/50\n",
            "6559/6559 [==============================] - 50s 8ms/step - loss: 0.4995 - accuracy: 0.7511 - val_loss: 0.4902 - val_accuracy: 0.7581\n",
            "Epoch 39/50\n",
            "6559/6559 [==============================] - 49s 8ms/step - loss: 0.4994 - accuracy: 0.7513 - val_loss: 0.4890 - val_accuracy: 0.7586\n",
            "Epoch 40/50\n",
            "6559/6559 [==============================] - 50s 8ms/step - loss: 0.4984 - accuracy: 0.7517 - val_loss: 0.4906 - val_accuracy: 0.7581\n",
            "Epoch 41/50\n",
            "6559/6559 [==============================] - 50s 8ms/step - loss: 0.4984 - accuracy: 0.7518 - val_loss: 0.4894 - val_accuracy: 0.7578\n",
            "Epoch 42/50\n",
            "6559/6559 [==============================] - 50s 8ms/step - loss: 0.4980 - accuracy: 0.7520 - val_loss: 0.4894 - val_accuracy: 0.7587\n",
            "Epoch 43/50\n",
            "6559/6559 [==============================] - 49s 7ms/step - loss: 0.4986 - accuracy: 0.7519 - val_loss: 0.4889 - val_accuracy: 0.7592\n",
            "Epoch 44/50\n",
            "6559/6559 [==============================] - 49s 7ms/step - loss: 0.4971 - accuracy: 0.7523 - val_loss: 0.4903 - val_accuracy: 0.7587\n",
            "Epoch 45/50\n",
            "6559/6559 [==============================] - 49s 7ms/step - loss: 0.4970 - accuracy: 0.7528 - val_loss: 0.4894 - val_accuracy: 0.7588\n",
            "Epoch 46/50\n",
            "6559/6559 [==============================] - 49s 7ms/step - loss: 0.4967 - accuracy: 0.7527 - val_loss: 0.4885 - val_accuracy: 0.7591\n",
            "Epoch 47/50\n",
            "6559/6559 [==============================] - 49s 7ms/step - loss: 0.4967 - accuracy: 0.7527 - val_loss: 0.4880 - val_accuracy: 0.7605\n",
            "Epoch 48/50\n",
            "6559/6559 [==============================] - 49s 7ms/step - loss: 0.4960 - accuracy: 0.7537 - val_loss: 0.4887 - val_accuracy: 0.7591\n",
            "Epoch 49/50\n",
            "6559/6559 [==============================] - 49s 7ms/step - loss: 0.4968 - accuracy: 0.7524 - val_loss: 0.4876 - val_accuracy: 0.7597\n",
            "Epoch 50/50\n",
            "6559/6559 [==============================] - 49s 7ms/step - loss: 0.4960 - accuracy: 0.7538 - val_loss: 0.4901 - val_accuracy: 0.7592\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_features, test_labels)\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "test_pred = model.predict(test_features)\n",
        "test_pred_binary = (test_pred >= 0.5).astype(int)\n",
        "test_auc = roc_auc_score(test_labels, test_pred)\n",
        "test_f1 = f1_score(test_labels, test_pred_binary)\n",
        "\n",
        "print(f\"Test AUC: {test_auc:.4f}\")\n",
        "print(f\"Test F1 score: {test_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t18ZGkCMn4y0",
        "outputId": "de79414f-5a0c-43b2-e0a3-1d5a5212b56b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4888 - accuracy: 0.7587\n",
            "Test loss: 0.4888\n",
            "Test accuracy: 0.7587\n",
            "2813/2813 [==============================] - 5s 2ms/step\n",
            "Test AUC: 0.8433\n",
            "Test F1 score: 0.7782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Normalize the input data\n",
        "scaler = StandardScaler()\n",
        "train_features = scaler.fit_transform(train_features)\n",
        "val_features = scaler.transform(val_features)\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_dim=28, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization()) #it normalize the batch\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))#it penalizes the parameter of the model which are baise and weight\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Early stopping callback\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_features, train_labels, epochs=50, batch_size=128, validation_data=(val_features, val_labels), callbacks=[es])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eS7lP8UPB0e",
        "outputId": "8654e021-7324-48ab-8463-adb7afe5a19f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "3280/3280 [==============================] - 57s 17ms/step - loss: 0.6179 - accuracy: 0.6825 - val_loss: 0.5474 - val_accuracy: 0.7189\n",
            "Epoch 2/50\n",
            "3280/3280 [==============================] - 53s 16ms/step - loss: 0.5521 - accuracy: 0.7158 - val_loss: 0.5325 - val_accuracy: 0.7303\n",
            "Epoch 3/50\n",
            "3280/3280 [==============================] - 54s 17ms/step - loss: 0.5408 - accuracy: 0.7229 - val_loss: 0.5212 - val_accuracy: 0.7378\n",
            "Epoch 4/50\n",
            "3280/3280 [==============================] - 52s 16ms/step - loss: 0.5336 - accuracy: 0.7285 - val_loss: 0.5173 - val_accuracy: 0.7406\n",
            "Epoch 5/50\n",
            "3280/3280 [==============================] - 54s 16ms/step - loss: 0.5279 - accuracy: 0.7318 - val_loss: 0.5099 - val_accuracy: 0.7460\n",
            "Epoch 6/50\n",
            "3280/3280 [==============================] - 52s 16ms/step - loss: 0.5242 - accuracy: 0.7350 - val_loss: 0.5100 - val_accuracy: 0.7468\n",
            "Epoch 7/50\n",
            "3280/3280 [==============================] - 54s 17ms/step - loss: 0.5217 - accuracy: 0.7362 - val_loss: 0.5052 - val_accuracy: 0.7485\n",
            "Epoch 8/50\n",
            "3280/3280 [==============================] - 53s 16ms/step - loss: 0.5182 - accuracy: 0.7382 - val_loss: 0.5039 - val_accuracy: 0.7489\n",
            "Epoch 9/50\n",
            "3280/3280 [==============================] - 52s 16ms/step - loss: 0.5166 - accuracy: 0.7399 - val_loss: 0.5020 - val_accuracy: 0.7509\n",
            "Epoch 10/50\n",
            "3280/3280 [==============================] - 56s 17ms/step - loss: 0.5148 - accuracy: 0.7408 - val_loss: 0.5019 - val_accuracy: 0.7510\n",
            "Epoch 11/50\n",
            "3280/3280 [==============================] - 53s 16ms/step - loss: 0.5130 - accuracy: 0.7423 - val_loss: 0.5002 - val_accuracy: 0.7516\n",
            "Epoch 12/50\n",
            "3280/3280 [==============================] - 53s 16ms/step - loss: 0.5116 - accuracy: 0.7433 - val_loss: 0.4993 - val_accuracy: 0.7524\n",
            "Epoch 13/50\n",
            "3280/3280 [==============================] - 54s 16ms/step - loss: 0.5101 - accuracy: 0.7441 - val_loss: 0.4973 - val_accuracy: 0.7545\n",
            "Epoch 14/50\n",
            "3280/3280 [==============================] - 52s 16ms/step - loss: 0.5088 - accuracy: 0.7446 - val_loss: 0.4963 - val_accuracy: 0.7537\n",
            "Epoch 15/50\n",
            "3280/3280 [==============================] - 54s 16ms/step - loss: 0.5073 - accuracy: 0.7462 - val_loss: 0.4953 - val_accuracy: 0.7553\n",
            "Epoch 16/50\n",
            "3280/3280 [==============================] - 52s 16ms/step - loss: 0.5065 - accuracy: 0.7461 - val_loss: 0.4960 - val_accuracy: 0.7550\n",
            "Epoch 17/50\n",
            "3280/3280 [==============================] - 54s 17ms/step - loss: 0.5058 - accuracy: 0.7462 - val_loss: 0.4937 - val_accuracy: 0.7556\n",
            "Epoch 18/50\n",
            "3280/3280 [==============================] - 53s 16ms/step - loss: 0.5052 - accuracy: 0.7472 - val_loss: 0.4939 - val_accuracy: 0.7561\n",
            "Epoch 19/50\n",
            "3280/3280 [==============================] - 53s 16ms/step - loss: 0.5044 - accuracy: 0.7472 - val_loss: 0.4922 - val_accuracy: 0.7565\n",
            "Epoch 20/50\n",
            "3280/3280 [==============================] - 56s 17ms/step - loss: 0.5033 - accuracy: 0.7485 - val_loss: 0.4948 - val_accuracy: 0.7566\n",
            "Epoch 21/50\n",
            "3280/3280 [==============================] - 55s 17ms/step - loss: 0.5019 - accuracy: 0.7495 - val_loss: 0.4925 - val_accuracy: 0.7572\n",
            "Epoch 22/50\n",
            "3280/3280 [==============================] - 53s 16ms/step - loss: 0.5019 - accuracy: 0.7499 - val_loss: 0.4927 - val_accuracy: 0.7573\n",
            "Epoch 23/50\n",
            "3280/3280 [==============================] - 54s 16ms/step - loss: 0.5009 - accuracy: 0.7499 - val_loss: 0.4919 - val_accuracy: 0.7568\n",
            "Epoch 24/50\n",
            "3280/3280 [==============================] - 52s 16ms/step - loss: 0.5007 - accuracy: 0.7501 - val_loss: 0.4913 - val_accuracy: 0.7569\n",
            "Epoch 25/50\n",
            "3280/3280 [==============================] - 53s 16ms/step - loss: 0.4998 - accuracy: 0.7500 - val_loss: 0.4903 - val_accuracy: 0.7596\n",
            "Epoch 26/50\n",
            "3280/3280 [==============================] - 55s 17ms/step - loss: 0.4988 - accuracy: 0.7515 - val_loss: 0.4906 - val_accuracy: 0.7580\n",
            "Epoch 27/50\n",
            "3280/3280 [==============================] - 52s 16ms/step - loss: 0.4989 - accuracy: 0.7517 - val_loss: 0.4905 - val_accuracy: 0.7586\n",
            "Epoch 28/50\n",
            "3280/3280 [==============================] - 54s 17ms/step - loss: 0.4983 - accuracy: 0.7520 - val_loss: 0.4908 - val_accuracy: 0.7583\n",
            "Epoch 29/50\n",
            "3280/3280 [==============================] - 57s 17ms/step - loss: 0.4975 - accuracy: 0.7523 - val_loss: 0.4905 - val_accuracy: 0.7586\n",
            "Epoch 30/50\n",
            "3280/3280 [==============================] - 52s 16ms/step - loss: 0.4969 - accuracy: 0.7529 - val_loss: 0.4894 - val_accuracy: 0.7590\n",
            "Epoch 31/50\n",
            "3280/3280 [==============================] - 54s 16ms/step - loss: 0.4969 - accuracy: 0.7521 - val_loss: 0.4899 - val_accuracy: 0.7586\n",
            "Epoch 32/50\n",
            "3280/3280 [==============================] - 52s 16ms/step - loss: 0.4960 - accuracy: 0.7529 - val_loss: 0.4891 - val_accuracy: 0.7586\n",
            "Epoch 33/50\n",
            "3280/3280 [==============================] - 54s 16ms/step - loss: 0.4959 - accuracy: 0.7533 - val_loss: 0.4887 - val_accuracy: 0.7601\n",
            "Epoch 34/50\n",
            "3280/3280 [==============================] - 53s 16ms/step - loss: 0.4951 - accuracy: 0.7537 - val_loss: 0.4882 - val_accuracy: 0.7594\n",
            "Epoch 35/50\n",
            "3280/3280 [==============================] - 53s 16ms/step - loss: 0.4953 - accuracy: 0.7539 - val_loss: 0.4882 - val_accuracy: 0.7594\n",
            "Epoch 36/50\n",
            "3280/3280 [==============================] - 56s 17ms/step - loss: 0.4943 - accuracy: 0.7540 - val_loss: 0.4884 - val_accuracy: 0.7595\n",
            "Epoch 37/50\n",
            "3280/3280 [==============================] - 55s 17ms/step - loss: 0.4940 - accuracy: 0.7543 - val_loss: 0.4885 - val_accuracy: 0.7595\n",
            "Epoch 38/50\n",
            "3280/3280 [==============================] - 52s 16ms/step - loss: 0.4934 - accuracy: 0.7547 - val_loss: 0.4885 - val_accuracy: 0.7593\n",
            "Epoch 39/50\n",
            "3280/3280 [==============================] - 54s 16ms/step - loss: 0.4935 - accuracy: 0.7552 - val_loss: 0.4886 - val_accuracy: 0.7586\n",
            "Epoch 40/50\n",
            "3280/3280 [==============================] - 56s 17ms/step - loss: 0.4928 - accuracy: 0.7550 - val_loss: 0.4871 - val_accuracy: 0.7606\n",
            "Epoch 41/50\n",
            "3280/3280 [==============================] - 53s 16ms/step - loss: 0.4925 - accuracy: 0.7557 - val_loss: 0.4878 - val_accuracy: 0.7594\n",
            "Epoch 42/50\n",
            "3280/3280 [==============================] - 55s 17ms/step - loss: 0.4923 - accuracy: 0.7560 - val_loss: 0.4879 - val_accuracy: 0.7602\n",
            "Epoch 43/50\n",
            "3280/3280 [==============================] - 55s 17ms/step - loss: 0.4920 - accuracy: 0.7556 - val_loss: 0.4886 - val_accuracy: 0.7598\n",
            "Epoch 44/50\n",
            "3280/3280 [==============================] - 53s 16ms/step - loss: 0.4914 - accuracy: 0.7559 - val_loss: 0.4883 - val_accuracy: 0.7604\n",
            "Epoch 45/50\n",
            "3280/3280 [==============================] - 55s 17ms/step - loss: 0.4911 - accuracy: 0.7564 - val_loss: 0.4870 - val_accuracy: 0.7606\n",
            "Epoch 46/50\n",
            "3280/3280 [==============================] - 55s 17ms/step - loss: 0.4909 - accuracy: 0.7562 - val_loss: 0.4873 - val_accuracy: 0.7616\n",
            "Epoch 47/50\n",
            "3280/3280 [==============================] - 52s 16ms/step - loss: 0.4904 - accuracy: 0.7569 - val_loss: 0.4891 - val_accuracy: 0.7593\n",
            "Epoch 48/50\n",
            "3280/3280 [==============================] - 54s 16ms/step - loss: 0.4902 - accuracy: 0.7576 - val_loss: 0.4860 - val_accuracy: 0.7603\n",
            "Epoch 49/50\n",
            "3280/3280 [==============================] - 52s 16ms/step - loss: 0.4902 - accuracy: 0.7568 - val_loss: 0.4864 - val_accuracy: 0.7601\n",
            "Epoch 50/50\n",
            "3280/3280 [==============================] - 53s 16ms/step - loss: 0.4903 - accuracy: 0.7568 - val_loss: 0.4874 - val_accuracy: 0.7604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_features, test_labels)\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "test_pred = model.predict(test_features)\n",
        "test_pred_binary = (test_pred >= 0.5).astype(int)\n",
        "test_auc = roc_auc_score(test_labels, test_pred)\n",
        "test_f1 = f1_score(test_labels, test_pred_binary)\n",
        "\n",
        "print(f\"Test AUC: {test_auc:.4f}\")\n",
        "print(f\"Test F1 score: {test_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfEJm-ybn3PV",
        "outputId": "edad35d0-6cf6-4f1f-df36-692806afb675"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2813/2813 [==============================] - 9s 3ms/step - loss: 0.4858 - accuracy: 0.7588\n",
            "Test loss: 0.4858\n",
            "Test accuracy: 0.7588\n",
            "2813/2813 [==============================] - 9s 3ms/step\n",
            "Test AUC: 0.8434\n",
            "Test F1 score: 0.7734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Normalize the input data\n",
        "scaler = StandardScaler()\n",
        "train_features = scaler.fit_transform(train_features)\n",
        "val_features = scaler.transform(val_features)\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_dim=28, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization()) #it normalize the batch\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))#it penalizes the parameter of the model which are baise and weight\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Early stopping callback\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_features, train_labels, epochs=100, batch_size=64, validation_data=(val_features, val_labels), callbacks=[es])\n",
        "\n"
      ],
      "metadata": {
        "id": "aehEwZKrvdCg",
        "outputId": "718b6ef7-361b-46b2-c79e-ada455ea8622",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "6559/6559 [==============================] - 88s 13ms/step - loss: 0.6040 - accuracy: 0.6849 - val_loss: 0.5443 - val_accuracy: 0.7226\n",
            "Epoch 2/100\n",
            "6559/6559 [==============================] - 84s 13ms/step - loss: 0.5529 - accuracy: 0.7159 - val_loss: 0.5292 - val_accuracy: 0.7320\n",
            "Epoch 3/100\n",
            "6559/6559 [==============================] - 82s 13ms/step - loss: 0.5424 - accuracy: 0.7226 - val_loss: 0.5216 - val_accuracy: 0.7386\n",
            "Epoch 4/100\n",
            "6559/6559 [==============================] - 80s 12ms/step - loss: 0.5369 - accuracy: 0.7258 - val_loss: 0.5192 - val_accuracy: 0.7396\n",
            "Epoch 5/100\n",
            "6559/6559 [==============================] - 81s 12ms/step - loss: 0.5316 - accuracy: 0.7290 - val_loss: 0.5117 - val_accuracy: 0.7451\n",
            "Epoch 6/100\n",
            "6559/6559 [==============================] - 82s 12ms/step - loss: 0.5288 - accuracy: 0.7313 - val_loss: 0.5086 - val_accuracy: 0.7455\n",
            "Epoch 7/100\n",
            "6559/6559 [==============================] - 82s 13ms/step - loss: 0.5260 - accuracy: 0.7332 - val_loss: 0.5087 - val_accuracy: 0.7459\n",
            "Epoch 8/100\n",
            "6559/6559 [==============================] - 80s 12ms/step - loss: 0.5232 - accuracy: 0.7352 - val_loss: 0.5055 - val_accuracy: 0.7479\n",
            "Epoch 9/100\n",
            "6559/6559 [==============================] - 82s 12ms/step - loss: 0.5215 - accuracy: 0.7365 - val_loss: 0.5068 - val_accuracy: 0.7476\n",
            "Epoch 10/100\n",
            "6559/6559 [==============================] - 81s 12ms/step - loss: 0.5198 - accuracy: 0.7365 - val_loss: 0.5032 - val_accuracy: 0.7493\n",
            "Epoch 11/100\n",
            "6559/6559 [==============================] - 82s 13ms/step - loss: 0.5181 - accuracy: 0.7388 - val_loss: 0.5011 - val_accuracy: 0.7506\n",
            "Epoch 12/100\n",
            "6559/6559 [==============================] - 82s 13ms/step - loss: 0.5168 - accuracy: 0.7394 - val_loss: 0.5001 - val_accuracy: 0.7507\n",
            "Epoch 13/100\n",
            "6559/6559 [==============================] - 84s 13ms/step - loss: 0.5155 - accuracy: 0.7398 - val_loss: 0.4996 - val_accuracy: 0.7510\n",
            "Epoch 14/100\n",
            "6559/6559 [==============================] - 81s 12ms/step - loss: 0.5139 - accuracy: 0.7415 - val_loss: 0.4992 - val_accuracy: 0.7503\n",
            "Epoch 15/100\n",
            "6559/6559 [==============================] - 82s 13ms/step - loss: 0.5131 - accuracy: 0.7420 - val_loss: 0.4975 - val_accuracy: 0.7547\n",
            "Epoch 16/100\n",
            "6559/6559 [==============================] - 81s 12ms/step - loss: 0.5122 - accuracy: 0.7425 - val_loss: 0.4987 - val_accuracy: 0.7532\n",
            "Epoch 17/100\n",
            "6559/6559 [==============================] - 83s 13ms/step - loss: 0.5114 - accuracy: 0.7432 - val_loss: 0.4953 - val_accuracy: 0.7542\n",
            "Epoch 18/100\n",
            "6559/6559 [==============================] - 80s 12ms/step - loss: 0.5104 - accuracy: 0.7441 - val_loss: 0.4957 - val_accuracy: 0.7533\n",
            "Epoch 19/100\n",
            "6559/6559 [==============================] - 83s 13ms/step - loss: 0.5094 - accuracy: 0.7436 - val_loss: 0.4946 - val_accuracy: 0.7547\n",
            "Epoch 20/100\n",
            "6559/6559 [==============================] - 83s 13ms/step - loss: 0.5088 - accuracy: 0.7452 - val_loss: 0.4949 - val_accuracy: 0.7549\n",
            "Epoch 21/100\n",
            "6559/6559 [==============================] - 83s 13ms/step - loss: 0.5079 - accuracy: 0.7460 - val_loss: 0.4949 - val_accuracy: 0.7554\n",
            "Epoch 22/100\n",
            "6559/6559 [==============================] - 83s 13ms/step - loss: 0.5078 - accuracy: 0.7454 - val_loss: 0.4929 - val_accuracy: 0.7573\n",
            "Epoch 23/100\n",
            "6559/6559 [==============================] - 81s 12ms/step - loss: 0.5070 - accuracy: 0.7462 - val_loss: 0.4933 - val_accuracy: 0.7559\n",
            "Epoch 24/100\n",
            "6559/6559 [==============================] - 83s 13ms/step - loss: 0.5064 - accuracy: 0.7472 - val_loss: 0.4943 - val_accuracy: 0.7560\n",
            "Epoch 25/100\n",
            "6559/6559 [==============================] - 81s 12ms/step - loss: 0.5053 - accuracy: 0.7465 - val_loss: 0.4920 - val_accuracy: 0.7567\n",
            "Epoch 26/100\n",
            "6559/6559 [==============================] - 82s 13ms/step - loss: 0.5050 - accuracy: 0.7471 - val_loss: 0.4934 - val_accuracy: 0.7564\n",
            "Epoch 27/100\n",
            "6559/6559 [==============================] - 81s 12ms/step - loss: 0.5042 - accuracy: 0.7481 - val_loss: 0.4935 - val_accuracy: 0.7563\n",
            "Epoch 28/100\n",
            "6559/6559 [==============================] - 87s 13ms/step - loss: 0.5038 - accuracy: 0.7483 - val_loss: 0.4928 - val_accuracy: 0.7572\n",
            "Epoch 29/100\n",
            "6559/6559 [==============================] - 82s 13ms/step - loss: 0.5042 - accuracy: 0.7477 - val_loss: 0.4918 - val_accuracy: 0.7580\n",
            "Epoch 30/100\n",
            "6559/6559 [==============================] - 83s 13ms/step - loss: 0.5028 - accuracy: 0.7490 - val_loss: 0.4913 - val_accuracy: 0.7582\n",
            "Epoch 31/100\n",
            "6559/6559 [==============================] - 83s 13ms/step - loss: 0.5023 - accuracy: 0.7497 - val_loss: 0.4906 - val_accuracy: 0.7580\n",
            "Epoch 32/100\n",
            "6559/6559 [==============================] - 81s 12ms/step - loss: 0.5021 - accuracy: 0.7492 - val_loss: 0.4916 - val_accuracy: 0.7567\n",
            "Epoch 33/100\n",
            "6559/6559 [==============================] - 83s 13ms/step - loss: 0.5016 - accuracy: 0.7501 - val_loss: 0.4907 - val_accuracy: 0.7572\n",
            "Epoch 34/100\n",
            "6559/6559 [==============================] - 82s 13ms/step - loss: 0.5013 - accuracy: 0.7497 - val_loss: 0.4906 - val_accuracy: 0.7576\n",
            "Epoch 35/100\n",
            "6559/6559 [==============================] - 85s 13ms/step - loss: 0.5014 - accuracy: 0.7506 - val_loss: 0.4899 - val_accuracy: 0.7591\n",
            "Epoch 36/100\n",
            "6559/6559 [==============================] - 83s 13ms/step - loss: 0.5006 - accuracy: 0.7504 - val_loss: 0.4906 - val_accuracy: 0.7577\n",
            "Epoch 37/100\n",
            "6559/6559 [==============================] - 83s 13ms/step - loss: 0.5003 - accuracy: 0.7504 - val_loss: 0.4895 - val_accuracy: 0.7582\n",
            "Epoch 38/100\n",
            "6559/6559 [==============================] - 82s 13ms/step - loss: 0.5003 - accuracy: 0.7507 - val_loss: 0.4904 - val_accuracy: 0.7576\n",
            "Epoch 39/100\n",
            "6559/6559 [==============================] - 81s 12ms/step - loss: 0.5001 - accuracy: 0.7505 - val_loss: 0.4908 - val_accuracy: 0.7567\n",
            "Epoch 40/100\n",
            "6559/6559 [==============================] - 82s 13ms/step - loss: 0.4996 - accuracy: 0.7510 - val_loss: 0.4889 - val_accuracy: 0.7587\n",
            "Epoch 41/100\n",
            "6559/6559 [==============================] - 83s 13ms/step - loss: 0.4991 - accuracy: 0.7514 - val_loss: 0.4886 - val_accuracy: 0.7586\n",
            "Epoch 42/100\n",
            "6559/6559 [==============================] - 84s 13ms/step - loss: 0.4991 - accuracy: 0.7513 - val_loss: 0.4886 - val_accuracy: 0.7601\n",
            "Epoch 43/100\n",
            "6559/6559 [==============================] - 83s 13ms/step - loss: 0.4982 - accuracy: 0.7509 - val_loss: 0.4904 - val_accuracy: 0.7590\n",
            "Epoch 44/100\n",
            "6559/6559 [==============================] - 83s 13ms/step - loss: 0.4979 - accuracy: 0.7521 - val_loss: 0.4893 - val_accuracy: 0.7581\n",
            "Epoch 45/100\n",
            "6559/6559 [==============================] - 83s 13ms/step - loss: 0.4979 - accuracy: 0.7524 - val_loss: 0.4889 - val_accuracy: 0.7591\n",
            "Epoch 46/100\n",
            "6559/6559 [==============================] - 83s 13ms/step - loss: 0.4976 - accuracy: 0.7527 - val_loss: 0.4887 - val_accuracy: 0.7597\n",
            "Epoch 47/100\n",
            "6559/6559 [==============================] - 84s 13ms/step - loss: 0.4973 - accuracy: 0.7529 - val_loss: 0.4898 - val_accuracy: 0.7587\n",
            "Epoch 47: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_features, test_labels)\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "test_pred = model.predict(test_features)\n",
        "test_pred_binary = (test_pred >= 0.5).astype(int)\n",
        "test_auc = roc_auc_score(test_labels, test_pred)\n",
        "test_f1 = f1_score(test_labels, test_pred_binary)\n",
        "\n",
        "print(f\"Test AUC: {test_auc:.4f}\")\n",
        "print(f\"Test F1 score: {test_f1:.4f}\")"
      ],
      "metadata": {
        "id": "_0rhiy6wviJc",
        "outputId": "1fd8ed56-92ec-43a6-df38-1951b65ddf90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2813/2813 [==============================] - 8s 3ms/step - loss: 0.4891 - accuracy: 0.7574\n",
            "Test loss: 0.4891\n",
            "Test accuracy: 0.7574\n",
            "2813/2813 [==============================] - 8s 3ms/step\n",
            "Test AUC: 0.8424\n",
            "Test F1 score: 0.7700\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Normalize the input data\n",
        "scaler = StandardScaler()\n",
        "train_features = scaler.fit_transform(train_features)\n",
        "val_features = scaler.transform(val_features)\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(512, input_dim=28, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Early stopping callback\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_features, train_labels, epochs=100, batch_size=128, validation_data=(val_features, val_labels), callbacks=[es])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uTjor0x2GQCM",
        "outputId": "e6f7c015-a930-4f5c-8f89-f253e6bbbcf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3280/3280 [==============================] - 35s 10ms/step - loss: 0.7109 - accuracy: 0.5854 - val_loss: 0.6547 - val_accuracy: 0.6464\n",
            "Epoch 2/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.6559 - accuracy: 0.6390 - val_loss: 0.6237 - val_accuracy: 0.6739\n",
            "Epoch 3/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.6303 - accuracy: 0.6624 - val_loss: 0.6000 - val_accuracy: 0.6923\n",
            "Epoch 4/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.6106 - accuracy: 0.6787 - val_loss: 0.5831 - val_accuracy: 0.7017\n",
            "Epoch 5/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5963 - accuracy: 0.6877 - val_loss: 0.5709 - val_accuracy: 0.7088\n",
            "Epoch 6/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5864 - accuracy: 0.6943 - val_loss: 0.5616 - val_accuracy: 0.7154\n",
            "Epoch 7/100\n",
            "3280/3280 [==============================] - 32s 10ms/step - loss: 0.5777 - accuracy: 0.6993 - val_loss: 0.5534 - val_accuracy: 0.7208\n",
            "Epoch 8/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5715 - accuracy: 0.7044 - val_loss: 0.5471 - val_accuracy: 0.7240\n",
            "Epoch 9/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5662 - accuracy: 0.7068 - val_loss: 0.5421 - val_accuracy: 0.7273\n",
            "Epoch 10/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5621 - accuracy: 0.7098 - val_loss: 0.5390 - val_accuracy: 0.7294\n",
            "Epoch 11/100\n",
            "3280/3280 [==============================] - 34s 10ms/step - loss: 0.5579 - accuracy: 0.7124 - val_loss: 0.5358 - val_accuracy: 0.7301\n",
            "Epoch 12/100\n",
            "3280/3280 [==============================] - 34s 10ms/step - loss: 0.5551 - accuracy: 0.7139 - val_loss: 0.5332 - val_accuracy: 0.7319\n",
            "Epoch 13/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5523 - accuracy: 0.7167 - val_loss: 0.5309 - val_accuracy: 0.7330\n",
            "Epoch 14/100\n",
            "3280/3280 [==============================] - 34s 10ms/step - loss: 0.5503 - accuracy: 0.7171 - val_loss: 0.5295 - val_accuracy: 0.7336\n",
            "Epoch 15/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5481 - accuracy: 0.7190 - val_loss: 0.5283 - val_accuracy: 0.7341\n",
            "Epoch 16/100\n",
            "3280/3280 [==============================] - 32s 10ms/step - loss: 0.5463 - accuracy: 0.7198 - val_loss: 0.5264 - val_accuracy: 0.7346\n",
            "Epoch 17/100\n",
            "3280/3280 [==============================] - 34s 10ms/step - loss: 0.5446 - accuracy: 0.7211 - val_loss: 0.5250 - val_accuracy: 0.7353\n",
            "Epoch 18/100\n",
            "3280/3280 [==============================] - 34s 10ms/step - loss: 0.5430 - accuracy: 0.7215 - val_loss: 0.5227 - val_accuracy: 0.7367\n",
            "Epoch 19/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5411 - accuracy: 0.7233 - val_loss: 0.5212 - val_accuracy: 0.7376\n",
            "Epoch 20/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5400 - accuracy: 0.7239 - val_loss: 0.5199 - val_accuracy: 0.7388\n",
            "Epoch 21/100\n",
            "3280/3280 [==============================] - 34s 10ms/step - loss: 0.5387 - accuracy: 0.7244 - val_loss: 0.5188 - val_accuracy: 0.7389\n",
            "Epoch 22/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5377 - accuracy: 0.7254 - val_loss: 0.5180 - val_accuracy: 0.7398\n",
            "Epoch 23/100\n",
            "3280/3280 [==============================] - 32s 10ms/step - loss: 0.5367 - accuracy: 0.7261 - val_loss: 0.5170 - val_accuracy: 0.7398\n",
            "Epoch 24/100\n",
            "3280/3280 [==============================] - 34s 10ms/step - loss: 0.5356 - accuracy: 0.7268 - val_loss: 0.5167 - val_accuracy: 0.7407\n",
            "Epoch 25/100\n",
            "3280/3280 [==============================] - 34s 10ms/step - loss: 0.5341 - accuracy: 0.7278 - val_loss: 0.5147 - val_accuracy: 0.7404\n",
            "Epoch 26/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5340 - accuracy: 0.7279 - val_loss: 0.5139 - val_accuracy: 0.7420\n",
            "Epoch 27/100\n",
            "3280/3280 [==============================] - 34s 10ms/step - loss: 0.5327 - accuracy: 0.7290 - val_loss: 0.5130 - val_accuracy: 0.7422\n",
            "Epoch 28/100\n",
            "3280/3280 [==============================] - 34s 10ms/step - loss: 0.5314 - accuracy: 0.7301 - val_loss: 0.5123 - val_accuracy: 0.7433\n",
            "Epoch 29/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5307 - accuracy: 0.7302 - val_loss: 0.5110 - val_accuracy: 0.7443\n",
            "Epoch 30/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5296 - accuracy: 0.7304 - val_loss: 0.5106 - val_accuracy: 0.7444\n",
            "Epoch 31/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5295 - accuracy: 0.7310 - val_loss: 0.5095 - val_accuracy: 0.7448\n",
            "Epoch 32/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5290 - accuracy: 0.7312 - val_loss: 0.5100 - val_accuracy: 0.7445\n",
            "Epoch 33/100\n",
            "3280/3280 [==============================] - 32s 10ms/step - loss: 0.5282 - accuracy: 0.7313 - val_loss: 0.5099 - val_accuracy: 0.7445\n",
            "Epoch 34/100\n",
            "3280/3280 [==============================] - 34s 10ms/step - loss: 0.5273 - accuracy: 0.7325 - val_loss: 0.5075 - val_accuracy: 0.7463\n",
            "Epoch 35/100\n",
            "3280/3280 [==============================] - 32s 10ms/step - loss: 0.5268 - accuracy: 0.7331 - val_loss: 0.5087 - val_accuracy: 0.7458\n",
            "Epoch 36/100\n",
            "3280/3280 [==============================] - 34s 10ms/step - loss: 0.5263 - accuracy: 0.7338 - val_loss: 0.5084 - val_accuracy: 0.7459\n",
            "Epoch 37/100\n",
            "3280/3280 [==============================] - 34s 10ms/step - loss: 0.5253 - accuracy: 0.7338 - val_loss: 0.5081 - val_accuracy: 0.7462\n",
            "Epoch 38/100\n",
            "3280/3280 [==============================] - 32s 10ms/step - loss: 0.5256 - accuracy: 0.7343 - val_loss: 0.5060 - val_accuracy: 0.7469\n",
            "Epoch 39/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5246 - accuracy: 0.7344 - val_loss: 0.5065 - val_accuracy: 0.7472\n",
            "Epoch 40/100\n",
            "3280/3280 [==============================] - 34s 10ms/step - loss: 0.5241 - accuracy: 0.7347 - val_loss: 0.5052 - val_accuracy: 0.7480\n",
            "Epoch 41/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5239 - accuracy: 0.7344 - val_loss: 0.5047 - val_accuracy: 0.7482\n",
            "Epoch 42/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5231 - accuracy: 0.7354 - val_loss: 0.5046 - val_accuracy: 0.7488\n",
            "Epoch 43/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5224 - accuracy: 0.7358 - val_loss: 0.5047 - val_accuracy: 0.7487\n",
            "Epoch 44/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5217 - accuracy: 0.7357 - val_loss: 0.5035 - val_accuracy: 0.7487\n",
            "Epoch 45/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5217 - accuracy: 0.7360 - val_loss: 0.5043 - val_accuracy: 0.7496\n",
            "Epoch 46/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5209 - accuracy: 0.7369 - val_loss: 0.5037 - val_accuracy: 0.7494\n",
            "Epoch 47/100\n",
            "3280/3280 [==============================] - 32s 10ms/step - loss: 0.5202 - accuracy: 0.7371 - val_loss: 0.5019 - val_accuracy: 0.7502\n",
            "Epoch 48/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5211 - accuracy: 0.7363 - val_loss: 0.5029 - val_accuracy: 0.7512\n",
            "Epoch 49/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5198 - accuracy: 0.7372 - val_loss: 0.5012 - val_accuracy: 0.7506\n",
            "Epoch 50/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5193 - accuracy: 0.7384 - val_loss: 0.5014 - val_accuracy: 0.7504\n",
            "Epoch 51/100\n",
            "3280/3280 [==============================] - 34s 10ms/step - loss: 0.5198 - accuracy: 0.7375 - val_loss: 0.5017 - val_accuracy: 0.7509\n",
            "Epoch 52/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5187 - accuracy: 0.7373 - val_loss: 0.5020 - val_accuracy: 0.7513\n",
            "Epoch 53/100\n",
            "3280/3280 [==============================] - 34s 10ms/step - loss: 0.5186 - accuracy: 0.7386 - val_loss: 0.5013 - val_accuracy: 0.7502\n",
            "Epoch 54/100\n",
            "3280/3280 [==============================] - 34s 10ms/step - loss: 0.5180 - accuracy: 0.7382 - val_loss: 0.5011 - val_accuracy: 0.7517\n",
            "Epoch 55/100\n",
            "3280/3280 [==============================] - 34s 10ms/step - loss: 0.5181 - accuracy: 0.7387 - val_loss: 0.5004 - val_accuracy: 0.7513\n",
            "Epoch 56/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5172 - accuracy: 0.7391 - val_loss: 0.4997 - val_accuracy: 0.7514\n",
            "Epoch 57/100\n",
            "3280/3280 [==============================] - 34s 10ms/step - loss: 0.5178 - accuracy: 0.7389 - val_loss: 0.5006 - val_accuracy: 0.7512\n",
            "Epoch 58/100\n",
            "3280/3280 [==============================] - 34s 10ms/step - loss: 0.5172 - accuracy: 0.7387 - val_loss: 0.5002 - val_accuracy: 0.7515\n",
            "Epoch 59/100\n",
            "3280/3280 [==============================] - 34s 10ms/step - loss: 0.5166 - accuracy: 0.7397 - val_loss: 0.5005 - val_accuracy: 0.7513\n",
            "Epoch 60/100\n",
            "3280/3280 [==============================] - 32s 10ms/step - loss: 0.5165 - accuracy: 0.7397 - val_loss: 0.5002 - val_accuracy: 0.7516\n",
            "Epoch 61/100\n",
            "3280/3280 [==============================] - 34s 11ms/step - loss: 0.5167 - accuracy: 0.7397 - val_loss: 0.4992 - val_accuracy: 0.7520\n",
            "Epoch 62/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5161 - accuracy: 0.7398 - val_loss: 0.4986 - val_accuracy: 0.7523\n",
            "Epoch 63/100\n",
            "3280/3280 [==============================] - 34s 10ms/step - loss: 0.5162 - accuracy: 0.7402 - val_loss: 0.4979 - val_accuracy: 0.7520\n",
            "Epoch 64/100\n",
            "3280/3280 [==============================] - 35s 11ms/step - loss: 0.5153 - accuracy: 0.7411 - val_loss: 0.4988 - val_accuracy: 0.7516\n",
            "Epoch 65/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5151 - accuracy: 0.7405 - val_loss: 0.4992 - val_accuracy: 0.7521\n",
            "Epoch 66/100\n",
            "3280/3280 [==============================] - 34s 10ms/step - loss: 0.5151 - accuracy: 0.7408 - val_loss: 0.4995 - val_accuracy: 0.7522\n",
            "Epoch 67/100\n",
            "3280/3280 [==============================] - 33s 10ms/step - loss: 0.5143 - accuracy: 0.7408 - val_loss: 0.4980 - val_accuracy: 0.7531\n",
            "Epoch 68/100\n",
            "3280/3280 [==============================] - 35s 11ms/step - loss: 0.5145 - accuracy: 0.7414 - val_loss: 0.4991 - val_accuracy: 0.7530\n",
            "Epoch 68: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_features, test_labels)\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "test_pred = model.predict(test_features)\n",
        "test_pred_binary = (test_pred >= 0.5).astype(int)\n",
        "test_auc = roc_auc_score(test_labels, test_pred)\n",
        "test_f1 = f1_score(test_labels, test_pred_binary)\n",
        "\n",
        "print(f\"Test AUC: {test_auc:.4f}\")\n",
        "print(f\"Test F1 score: {test_f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifzZ4ZlXn1m_",
        "outputId": "73a221ea-8d7a-4a8e-8af1-4b400ff7456b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4986 - accuracy: 0.7522\n",
            "Test loss: 0.4986\n",
            "Test accuracy: 0.7522\n",
            "2813/2813 [==============================] - 4s 2ms/step\n",
            "Test AUC: 0.8359\n",
            "Test F1 score: 0.7699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "from tensorflow.keras.initializers import GlorotUniform\n",
        "\n",
        "# Define a learning rate schedule\n",
        "def lr_schedule(epoch):\n",
        "    if epoch < 10:\n",
        "        return 0.001\n",
        "    else:\n",
        "        return 0.001 * np.exp(0.1 * (10 - epoch))\n",
        "\n",
        "# Normalize the input data\n",
        "scaler = StandardScaler()\n",
        "train_features = scaler.fit_transform(train_features)\n",
        "val_features = scaler.transform(val_features)\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_dim=28, activation='relu', kernel_initializer=GlorotUniform()))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(512, activation='relu', kernel_initializer=GlorotUniform()))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(256, activation='relu', kernel_initializer=GlorotUniform()))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(128, activation='relu', kernel_initializer=GlorotUniform()))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(64, activation='relu', kernel_initializer=GlorotUniform()))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Learning rate schedule callback\n",
        "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "# Early stopping callback\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(train_features, train_labels, epochs=50, batch_size=128, validation_data=(val_features, val_labels), callbacks=[lr_scheduler, es])\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_features, test_labels)\n",
        "print(f\"Test loss: {test_loss:.4f}\")\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "test_pred = model.predict(test_features)\n",
        "test_pred_binary = (test_pred >= 0.5).astype(int)\n",
        "test_auc = roc_auc_score(test_labels, test_pred)\n",
        "test_f1 = f1_score(test_labels, test_pred_binary)\n",
        "\n",
        "print(f\"Test AUC: {test_auc:.4f}\")\n",
        "print(f\"Test F1 score: {test_f1:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e3Gg9gaAGI7",
        "outputId": "8a0e3e16-0c0b-4871-b73c-c8ea4b01e576"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "3280/3280 [==============================] - 132s 38ms/step - loss: 0.5887 - accuracy: 0.6850 - val_loss: 0.5411 - val_accuracy: 0.7241 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "3280/3280 [==============================] - 130s 40ms/step - loss: 0.5491 - accuracy: 0.7171 - val_loss: 0.5293 - val_accuracy: 0.7320 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "3280/3280 [==============================] - 124s 38ms/step - loss: 0.5373 - accuracy: 0.7255 - val_loss: 0.5187 - val_accuracy: 0.7382 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "3280/3280 [==============================] - 125s 38ms/step - loss: 0.5291 - accuracy: 0.7309 - val_loss: 0.5119 - val_accuracy: 0.7435 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "3280/3280 [==============================] - 124s 38ms/step - loss: 0.5224 - accuracy: 0.7351 - val_loss: 0.5069 - val_accuracy: 0.7464 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "3280/3280 [==============================] - 125s 38ms/step - loss: 0.5180 - accuracy: 0.7388 - val_loss: 0.5022 - val_accuracy: 0.7500 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "3280/3280 [==============================] - 129s 39ms/step - loss: 0.5142 - accuracy: 0.7418 - val_loss: 0.4997 - val_accuracy: 0.7511 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "3280/3280 [==============================] - 124s 38ms/step - loss: 0.5110 - accuracy: 0.7426 - val_loss: 0.5000 - val_accuracy: 0.7501 - lr: 0.0010\n",
            "Epoch 9/50\n",
            "3280/3280 [==============================] - 129s 39ms/step - loss: 0.5081 - accuracy: 0.7450 - val_loss: 0.4998 - val_accuracy: 0.7525 - lr: 0.0010\n",
            "Epoch 10/50\n",
            "3280/3280 [==============================] - 124s 38ms/step - loss: 0.5057 - accuracy: 0.7461 - val_loss: 0.4957 - val_accuracy: 0.7537 - lr: 0.0010\n",
            "Epoch 11/50\n",
            "3280/3280 [==============================] - 124s 38ms/step - loss: 0.5036 - accuracy: 0.7479 - val_loss: 0.4930 - val_accuracy: 0.7550 - lr: 0.0010\n",
            "Epoch 12/50\n",
            "3280/3280 [==============================] - 124s 38ms/step - loss: 0.5001 - accuracy: 0.7507 - val_loss: 0.4920 - val_accuracy: 0.7565 - lr: 9.0484e-04\n",
            "Epoch 13/50\n",
            "3280/3280 [==============================] - 129s 39ms/step - loss: 0.4976 - accuracy: 0.7525 - val_loss: 0.4914 - val_accuracy: 0.7570 - lr: 8.1873e-04\n",
            "Epoch 14/50\n",
            "3280/3280 [==============================] - 124s 38ms/step - loss: 0.4952 - accuracy: 0.7532 - val_loss: 0.4894 - val_accuracy: 0.7575 - lr: 7.4082e-04\n",
            "Epoch 15/50\n",
            "3280/3280 [==============================] - 128s 39ms/step - loss: 0.4921 - accuracy: 0.7556 - val_loss: 0.4892 - val_accuracy: 0.7572 - lr: 6.7032e-04\n",
            "Epoch 16/50\n",
            "3280/3280 [==============================] - 129s 39ms/step - loss: 0.4901 - accuracy: 0.7568 - val_loss: 0.4895 - val_accuracy: 0.7580 - lr: 6.0653e-04\n",
            "Epoch 17/50\n",
            "3280/3280 [==============================] - 124s 38ms/step - loss: 0.4871 - accuracy: 0.7583 - val_loss: 0.4870 - val_accuracy: 0.7586 - lr: 5.4881e-04\n",
            "Epoch 18/50\n",
            "3280/3280 [==============================] - 125s 38ms/step - loss: 0.4847 - accuracy: 0.7607 - val_loss: 0.4872 - val_accuracy: 0.7577 - lr: 4.9659e-04\n",
            "Epoch 19/50\n",
            "3280/3280 [==============================] - 125s 38ms/step - loss: 0.4833 - accuracy: 0.7613 - val_loss: 0.4863 - val_accuracy: 0.7585 - lr: 4.4933e-04\n",
            "Epoch 20/50\n",
            "3280/3280 [==============================] - 124s 38ms/step - loss: 0.4813 - accuracy: 0.7623 - val_loss: 0.4864 - val_accuracy: 0.7604 - lr: 4.0657e-04\n",
            "Epoch 21/50\n",
            "3280/3280 [==============================] - 130s 40ms/step - loss: 0.4794 - accuracy: 0.7633 - val_loss: 0.4856 - val_accuracy: 0.7597 - lr: 3.6788e-04\n",
            "Epoch 22/50\n",
            "3280/3280 [==============================] - 124s 38ms/step - loss: 0.4780 - accuracy: 0.7654 - val_loss: 0.4857 - val_accuracy: 0.7604 - lr: 3.3287e-04\n",
            "Epoch 23/50\n",
            "3280/3280 [==============================] - 126s 38ms/step - loss: 0.4765 - accuracy: 0.7653 - val_loss: 0.4863 - val_accuracy: 0.7602 - lr: 3.0119e-04\n",
            "Epoch 24/50\n",
            "3280/3280 [==============================] - 124s 38ms/step - loss: 0.4756 - accuracy: 0.7656 - val_loss: 0.4859 - val_accuracy: 0.7598 - lr: 2.7253e-04\n",
            "Epoch 25/50\n",
            "3280/3280 [==============================] - 125s 38ms/step - loss: 0.4738 - accuracy: 0.7670 - val_loss: 0.4862 - val_accuracy: 0.7602 - lr: 2.4660e-04\n",
            "Epoch 26/50\n",
            "3280/3280 [==============================] - 124s 38ms/step - loss: 0.4723 - accuracy: 0.7684 - val_loss: 0.4851 - val_accuracy: 0.7604 - lr: 2.2313e-04\n",
            "Epoch 27/50\n",
            "3280/3280 [==============================] - 124s 38ms/step - loss: 0.4714 - accuracy: 0.7687 - val_loss: 0.4850 - val_accuracy: 0.7610 - lr: 2.0190e-04\n",
            "Epoch 28/50\n",
            "3280/3280 [==============================] - 129s 39ms/step - loss: 0.4704 - accuracy: 0.7692 - val_loss: 0.4852 - val_accuracy: 0.7603 - lr: 1.8268e-04\n",
            "Epoch 29/50\n",
            "3280/3280 [==============================] - 124s 38ms/step - loss: 0.4697 - accuracy: 0.7693 - val_loss: 0.4860 - val_accuracy: 0.7599 - lr: 1.6530e-04\n",
            "Epoch 30/50\n",
            "3280/3280 [==============================] - 125s 38ms/step - loss: 0.4687 - accuracy: 0.7699 - val_loss: 0.4856 - val_accuracy: 0.7606 - lr: 1.4957e-04\n",
            "Epoch 31/50\n",
            "3280/3280 [==============================] - 124s 38ms/step - loss: 0.4687 - accuracy: 0.7702 - val_loss: 0.4855 - val_accuracy: 0.7608 - lr: 1.3534e-04\n",
            "Epoch 32/50\n",
            "3280/3280 [==============================] - 124s 38ms/step - loss: 0.4676 - accuracy: 0.7714 - val_loss: 0.4856 - val_accuracy: 0.7604 - lr: 1.2246e-04\n",
            "Epoch 33/50\n",
            "3280/3280 [==============================] - 129s 39ms/step - loss: 0.4663 - accuracy: 0.7718 - val_loss: 0.4857 - val_accuracy: 0.7609 - lr: 1.1080e-04\n",
            "Epoch 34/50\n",
            "3280/3280 [==============================] - 125s 38ms/step - loss: 0.4661 - accuracy: 0.7718 - val_loss: 0.4855 - val_accuracy: 0.7606 - lr: 1.0026e-04\n",
            "Epoch 35/50\n",
            "3280/3280 [==============================] - 123s 38ms/step - loss: 0.4661 - accuracy: 0.7718 - val_loss: 0.4856 - val_accuracy: 0.7606 - lr: 9.0718e-05\n",
            "Epoch 36/50\n",
            "3280/3280 [==============================] - 124s 38ms/step - loss: 0.4657 - accuracy: 0.7721 - val_loss: 0.4853 - val_accuracy: 0.7611 - lr: 8.2085e-05\n",
            "Epoch 37/50\n",
            "3280/3280 [==============================] - 124s 38ms/step - loss: 0.4652 - accuracy: 0.7722 - val_loss: 0.4856 - val_accuracy: 0.7606 - lr: 7.4274e-05\n",
            "Epoch 37: early stopping\n",
            "2813/2813 [==============================] - 14s 5ms/step - loss: 0.4839 - accuracy: 0.7609\n",
            "Test loss: 0.4839\n",
            "Test accuracy: 0.7609\n",
            "2813/2813 [==============================] - 13s 5ms/step\n",
            "Test AUC: 0.8454\n",
            "Test F1 score: 0.7783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code uses a larger model with 5 hidden layers, increasing the number of neurons in each successive layer. It also uses Glorot initialization for the weights of each layer, which can help improve the performance of deep neural networks.\n",
        "\n",
        "Additionally, the code defines a custom learning rate schedule that decreases the learning rate exponentially after the first 10 epochs. This can help the model to converge more effectively.\n",
        "\n",
        "Finally, the code includes the LearningRateScheduler callback, which applies the custom learning rate schedule during training, and the EarlyStopping callback, which stops the training early if the validation loss does not improve for 10 epochs."
      ],
      "metadata": {
        "id": "3jF2iAodeQAU"
      }
    }
  ]
}