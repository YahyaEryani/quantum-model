{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPQ0G12ajmOuDAEQjTsuxpg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YahyaEryani/quantum-model/blob/main/notebooks/03_HGB_Training_and_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training, Tuning, and Evaluation\n",
        "\n",
        " In this notebook, we will train an histogram gradient boosted classifier model on the Higgs boson dataset we have preprocessed in the `01_data_exploration` notebook. We will perform the model training and tuning process to obtain the best model with the highest accuracy possible."
      ],
      "metadata": {
        "id": "rCCacfQOdovS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Libraries\n",
        "In this section, we will import the necessary libraries and packages that will be used throughout the notebook."
      ],
      "metadata": {
        "id": "80xGfi4qeX_R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qtnhwOT2btA4",
        "outputId": "935fee82-aea2-4573-9ac8-a8234f0f2c40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/experimental/enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Data\n",
        "\n",
        "This code cell loads the training, validation, and test datasets that were saved in pickle format to the local directory."
      ],
      "metadata": {
        "id": "ypcKz82Rezcf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from local files\n",
        "data_directory = '../Higgs_dataset/processed/'\n",
        "train_path = data_directory + 'training_data.pkl'\n",
        "val_path   = data_directory + 'validation_data.pkl'\n",
        "test_path  = data_directory + 'testing_data.pkl'\n",
        "\n",
        "train_data = pd.read_pickle(train_path)\n",
        "val_data = pd.read_pickle(val_path)\n",
        "test_data = pd.read_pickle(test_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U5KGIile0KZ",
        "outputId": "3be624c6-b3b0-45d2-bda1-0d18c36b6533"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare the data for training\n",
        "This code separates the features and class labels from the train, validation, and test datasets."
      ],
      "metadata": {
        "id": "xzlLL4XtuAhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate features and labels\n",
        "y_train = train_data['class_label']\n",
        "X_train = train_data.drop('class_label', axis=1)\n",
        "y_val = val_data['class_label']\n",
        "X_val = val_data.drop('class_label', axis=1)\n",
        "y_test = test_data['class_label']\n",
        "X_test = test_data.drop('class_label', axis=1)\n"
      ],
      "metadata": {
        "id": "pLL8bBeUuBFs"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train the Histogram Gradient Boosting Classifier model\n",
        "This code sets the hyperparameters for a Histogram Gradient Boosting Classifier model, including the maximum depth of trees, learning rate, maximum number of leaf nodes, and loss function. It then trains the Histogram Gradient Boosting Classifier model using early stopping and a specified number of iterations."
      ],
      "metadata": {
        "id": "C1-zcJsAgAUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the hyperparameters for the Histogram Gradient Boosting Classifier model\n",
        "hist_gradient_boosting = HistGradientBoostingClassifier(\n",
        "    loss='log_loss',\n",
        "    learning_rate=0.05,  # Lower learning rate for more stable convergence\n",
        "    max_iter=200,  # Increase the number of iterations for improved performance\n",
        "    max_leaf_nodes=31,  # Keep the same\n",
        "    max_depth=None,  # Keep the same\n",
        "    min_samples_leaf=30,  # Slightly increase to reduce overfitting\n",
        "    l2_regularization=0.1,  # Add a small amount of regularization to prevent overfitting\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "\n",
        "# Train the model\n",
        "hist_gradient_boosting.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the model on the training set\n",
        "y_train_pred = hist_gradient_boosting.predict(X_train)\n",
        "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Evaluate the model on the validation set (optional)\n",
        "y_val_pred = hist_gradient_boosting.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYuEodJigA0C",
        "outputId": "93068d84-310d-4d8b-f523-394967b3ba96"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 73.66%\n",
            "Validation Accuracy: 73.11%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Evaluation"
      ],
      "metadata": {
        "id": "4yvrPk6PwUkB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make predictions on the test data and evaluate the model performance\n",
        "This code uses the Histogram Gradient Boosting Classifier model that was previously trained to make predictions on the test data."
      ],
      "metadata": {
        "id": "js36VHnOw_UQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on the test set\n",
        "y_pred = hist_gradient_boosting.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZJ8xaVcwVGO",
        "outputId": "44b5f881-460e-4173-b389-13c02effc847"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 73.10%\n"
          ]
        }
      ]
    }
  ]
}